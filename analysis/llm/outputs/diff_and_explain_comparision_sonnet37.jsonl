{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path to skip NaN checks when arrays are known to be NaN-free. The Expert, however, applies a systemic optimization by changing the underlying NumPy array view from `datetime64` to `int64` for comparison, leveraging a generally faster native vectorized comparison routine.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38248", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a Python-level fast path using `all(isinstance(x, bool) for x in key)` to avoid `np.asarray`. The Expert, in contrast, replaces the `np.asarray` call with a new Cython function that performs the boolean check at C speed, representing a more fundamental, systemic optimization.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-41861", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specialized flag and an O(1) algorithm specifically for IntervalIndex objects created from consecutive integer breaks, which is a pattern-specific hack. The Expert implements a more general algorithmic refactor for IntervalIndex objects with unique left/right endpoints, leveraging existing C-implemented `get_indexer` and vectorized NumPy operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42293", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes the numerical algorithm (Welford's) within a specific Cython function for variance calculation. The Expert, however, enables a more fundamental 'block-wise' data processing strategy for `groupby().std()` operations, which is a broader algorithmic refactor of the data flow and dispatching mechanism, leading to reduced Python overhead and improved cache locality.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43115", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactors and micro-overhead removal. The LM optimizes a sub-step (calculating the fill value) within the existing method structure. The Expert, however, performs a deeper, more systemic refactor by eliminating the entire O(N) copy and in-place modification operations, changing the method's contract, and moving it to a base class for broader impact.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45434", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactors and micro-overhead removal. The LM optimizes the internal loop structure of a Cython function by hoisting conditional checks. The expert, however, addresses a deeper issue by preventing an unnecessary data type upcasting and memory allocation/copy at the Python-Cython boundary, allowing the Cython function to operate directly on the native `int8` data, which is a broader and more fundamental improvement to the data pipeline.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46745", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["serialization_deserialization", "integrity_checks"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert solutions target the same core optimization: skipping integrity checks during MultiIndex deserialization. However, the expert's change is a more targeted modification within the generic `_new_Index` factory function in `base.py`, which can be considered a 'deeper' part of the object creation system. The LM's solution is broader, involving a more extensive refactoring of `MultiIndex`'s own pickling/unpickling methods and also optimizing serialization.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-47916", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, making no changes and thus failing to address any performance hotspot. The expert, however, identified and fixed a performance regression in the `factorize` function by conditionally applying an array copy, directly targeting a measured hotspot.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48620", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path within `Series.explode()` for a narrow data pattern (NumPy arrays of integers), directly addressing the benchmark's input. The Expert, conversely, refactors a core type conversion utility (`maybe_convert_objects`) by adding a parameter and early-exit logic, leading to a more systemic improvement in pandas' general type inference mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51517", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path that skips integrity checks (like `is_unique`) only when new levels are `numpy.arange`-like, a pattern-specific hack. The Expert, however, implements a systemic algorithmic refactor of the `_verify_integrity` method to only perform checks on the levels that were actually modified, a more general improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51873", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explicitly states that its patch introduces a 'semantic change regarding the order of the filtered items,' indicating a potential risk to behavior. The expert's explanation, however, makes no mention of semantic changes, relying on a standard, optimized library method (`Index.intersection`) which implies preserving documented behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52941", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a high-level fast path in `pd.concat` that detects identical DataFrame instances and uses `np.tile`, explicitly bypassing the internal block management for this specific pattern. The Expert, conversely, optimizes an existing internal fast path within `_concat_homogeneous_fastpath` by using `np.concatenate` when no reindexing is required, representing a more systemic improvement to the core data handling logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53772", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM introduces a specialized factorization strategy for 'inner' joins, acting as a fast-path for a specific case by reducing dictionary size. Expert, in contrast, applies a more systemic fix by correcting the type dispatch to ensure `StringDtype[pyarrow]` keys are correctly routed to the highly optimized PyArrow native factorization path, avoiding costly Python object conversions.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54510", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization using `functools.lru_cache` to avoid recomputing results for identical inputs. The Expert introduces an early-exit fast-path for common numeric dtypes, which directly reduces the computational work within the hotspot function itself, rather than caching its results.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57478", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path guard for `datetime64` arrays with resolution mismatches, performing a single pre-conversion. The expert's optimizations involve a structural redesign of the `fillna` method to avoid an unnecessary DataFrame copy and an algorithmic refinement to prevent redundant unit conversions when units already match, representing more systemic improvements.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57479", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an interpolation-based optimization, which inherently involves approximation and thus carries a potential semantic risk. The expert's optimization, conversely, preserves exact semantics by eliminating a redundant, expensive call to `erfa.epv00` without altering the calculation's precision.", "confidence": 0.9, "instance_id": "astropy__astropy-10814", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multi-layered caching, which acts as a pattern-specific fast path for repeated inputs. The Expert performs an algorithmic refactor by fixing argument propagation to avoid unnecessary work in the parsing logic, improving the general case without caching.", "confidence": 0.9, "instance_id": "astropy__astropy-12699", "repo": "astropy/astropy"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is introduced via an invasive global monkey-patch of `numpy.arange`. In contrast, the expert's optimization is a local, contained change within a single function, making it minimal and maintainable.", "confidence": 1.0, "instance_id": "astropy__astropy-12701", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch returns `value.frame, False` for the fast-path, changing the `converted_bool` from `True` (as it would be in the original code's `else` block) to `False`. The Expert's patch correctly returns `value.frame, True`, preserving the original semantic behavior of the `converted_bool` flag.", "confidence": 0.9, "instance_id": "astropy__astropy-13471", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization introduces early-exit fast paths in the `Longitude` constructor to skip the entire angle wrapping process when angles are already in range, acting as a shortcut. The Expert's optimization is a micro-overhead removal (eliminating a redundant NumPy call) within the angle wrapping logic, which is a refinement of the existing algorithm.", "confidence": 0.9, "instance_id": "astropy__astropy-13497", "repo": "astropy/astropy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe the exact same early-exit fast-path optimization in `ManualInterval.get_limits`, targeting the same hotspot and using identical code. There is no discernible difference in their core optimization strategies, scope, or semantic impact.", "confidence": 1.0, "instance_id": "astropy__astropy-13898", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the same early-exit optimization. The expert's explanation, however, provides a slightly deeper analysis by explicitly listing all the expensive NumPy operations (`np.asarray().ravel()`, `np.min()`, `np.max()`) that are bypassed, and also mentions memory allocation reduction, indicating a more thorough understanding of the full impact.", "confidence": 0.9, "instance_id": "astropy__astropy-13899", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for scalar milliarcsecond parallaxes using a hardcoded arithmetic calculation, which is a narrow, pattern-specific hack. The Expert, in contrast, performs an algorithmic refactor by changing how an intermediate Quantity object is passed to the parent constructor, leading to a more general reduction in object creation overhead.", "confidence": 1.0, "instance_id": "astropy__astropy-15900", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path with narrow guards for `Angle` creation from NumPy arrays, bypassing general Python logic. The Expert applies `functools.cache` to a utility function, `_convert_unit_to_angle_unit`, providing a more general and systemic improvement to unit conversion efficiency for repeated calls.", "confidence": 0.7, "instance_id": "astropy__astropy-16088", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path to bypass the `_validate_angles` method entirely for a common input pattern. The Expert, in contrast, refactors the internal NumPy operations within `_validate_angles` to make the validation itself more efficient, representing a systemic improvement to the core logic.", "confidence": 0.9, "instance_id": "astropy__astropy-16096", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe fast-path/early-exit optimizations. However, the expert's change targets a deeper, more fundamental numerical operation (`_wrap_at` on large NumPy arrays) that is a bottleneck within the coordinate initialization, while the LM's change is a higher-level shortcut in the `SkyCoord` constructor itself.", "confidence": 0.9, "instance_id": "astropy__astropy-16222", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to reduce Python overhead. The LM introduces a fast path for a specific input type (`numpy.ndarray`), while the Expert applies caching to memoize an expensive unit conversion operation (`u.Unit()`) that occurs for any string unit input, making the Expert's approach broader in its applicability to unit handling.", "confidence": 0.9, "instance_id": "astropy__astropy-16243", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM introduces a conditional fast path for scalar inputs, preserving the original NumPy path for array inputs. The Expert, however, performs an algorithmic refactor, completely replacing the NumPy-based logic with native Python scalar operations, effectively making the function scalar-only and changing its API contract.", "confidence": 0.9, "instance_id": "astropy__astropy-16295", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify micro-optimizations. The LM focuses on a single numerical expression refactoring within the `evaluate` method for better NumPy performance. The Expert, however, identifies multiple, broader micro-optimizations in the core modeling framework (`astropy/modeling/core.py`) that remove overheads in parameter handling, unit processing, and input validation, demonstrating a deeper and broader understanding of the framework's performance bottlenecks.", "confidence": 0.9, "instance_id": "astropy__astropy-16670", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies micro-optimizations and local refactoring to the numerical expressions within the `Gaussian1D` model's `evaluate` and `fit_deriv` methods. The Expert, however, implements a systemic refactor of the fitting process by hoisting parameter introspection out of the hot loop and streamlining model evaluation to avoid repeated attribute assignments, addressing a broader overhead in the fitting subsystem.", "confidence": 0.9, "instance_id": "astropy__astropy-16673", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a hardcoded fast path that explicitly bypasses unit validation for specific argument values, which carries a `PotentiallyRisky` semantic impact by skipping checks. In contrast, the expert's optimization conditionally uses a `nullcontext` when no equivalencies are provided, removing unnecessary overhead while `Preserving` all original validation and behavior.", "confidence": 0.9, "instance_id": "astropy__astropy-16742", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple layers of caching to avoid re-parsing identical unit strings. The Expert, conversely, refactors the unit object construction within the parser to directly create specialized CompositeUnit objects, reducing object allocation overhead and method calls, thus making the parsing operation itself inherently faster without caching.", "confidence": 1.0, "instance_id": "astropy__astropy-16813", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization caches to store previously parsed `Unit` objects and formatters. The Expert, however, implements a fast-path (`_parse_unit`) for simple unit strings, which directly reduces the computational work by avoiding the more complex parsing logic, rather than caching the final result.", "confidence": 0.9, "instance_id": "astropy__astropy-17004", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization/caching for `to_string` results and formatter objects. The expert's solution, however, refactors the `_decompose_to_known_units` method to reduce object allocations and skip redundant error checks, directly lowering the cost of the hot path rather than caching its output.", "confidence": 1.0, "instance_id": "astropy__astropy-17043", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a global memoization cache for the `compose` method. The expert, however, focuses on fundamental algorithmic improvements and micro-optimizations within the `compose` method itself, such as reducing sorting complexity and optimizing unit comparison, thereby lowering the cost of the hot path without relying on caching.", "confidence": 1.0, "instance_id": "astropy__astropy-17425", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a direct memoization cache for a specific function (`getdata`) to handle repeated identical calls, acting as a pattern-specific shortcut. The Expert, however, implements a systemic optimization by caching values within the core `astropy.config.ConfigItem` descriptor, which is a foundational component used by `getdata` and potentially many other parts of Astropy, along with a structural refactor using `__set_name__`.", "confidence": 0.9, "instance_id": "astropy__astropy-17461", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to store and reuse results of repeated slicing operations. The Expert optimizes a different hotspot by removing unnecessary checks within `__setattr__` for internal attributes, thereby lowering the cost of the attribute setting operation itself rather than caching its output.", "confidence": 0.9, "instance_id": "astropy__astropy-6940", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache for repeated slicing operations. The expert, conversely, optimizes the object creation process itself by bypassing the `__init__` method for sliced objects, thereby lowering the overhead of the hot path rather than just caching its output. The expert's change also carries a documented semantic risk.", "confidence": 0.9, "instance_id": "astropy__astropy-6941", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path specifically for `np.add.reduce` on `Angle` objects by directly operating on the underlying NumPy array. The Expert, however, implements systemic optimizations within the core `astropy.units` framework, adding identity checks and early exits in unit conversion functions that benefit all `Quantity` operations where units are identical, representing a broader, more fundamental improvement.", "confidence": 0.9, "instance_id": "astropy__astropy-7010", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["maintainability", "code_structure"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert optimize the same hotspot by ensuring `mask=False` is passed to the underlying `numpy.ma.MaskedArray` constructor. However, the Expert's approach is deeper and safer: it modifies the `mask` parameter within the existing initialization flow. The LM creates a separate, parallel fast-path that duplicates object construction and attribute setting logic, making the Expert's solution more integrated and maintainable.", "confidence": 0.9, "instance_id": "astropy__astropy-7422", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces global memoization caches to store results of unit computations, avoiding re-computation for identical inputs. The Expert, in contrast, optimizes the underlying unit arithmetic by reducing object creation, skipping redundant validation checks, and streamlining the power calculation logic, thereby lowering the cost of the hot path itself rather than just caching its output.", "confidence": 1.0, "instance_id": "astropy__astropy-7549", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations targeting the `Longitude` constructor. The LM removes a conditional check, arguing its overhead was greater than direct arithmetic. The Expert avoids an unnecessary data copy by adding `copy=False`, which is a more fundamental and broadly applicable optimization for data-heavy objects.", "confidence": 0.9, "instance_id": "astropy__astropy-7616", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe adding a fast path for identity unit conversions. The expert's solution is deeper by precisely targeting the common case where the value is also the default `1.0` (using `UNITY`), completely bypassing the `_get_converter` call. The LM's solution, while also adding a fast path to `to`, also adds a less optimal fast path within `_get_converter` that still returns a lambda, which is less efficient than completely avoiding the converter.", "confidence": 0.9, "instance_id": "astropy__astropy-7643", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path in `CompositeUnit.__init__` that precisely matches the benchmark's input pattern. The Expert, in contrast, implements a broader fast path in `CompositeUnit.__init__` and also applies systemic micro-optimizations to underlying utility functions like `sanitize_scale` and `resolve_fractions`, improving general performance across the subsystem.", "confidence": 0.9, "instance_id": "astropy__astropy-7649", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization (caching) at multiple points to reuse previously computed results or objects. The Expert, in contrast, directly optimizes the underlying computation of a hot path (`_get_deriv_key`) by replacing an inefficient unit conversion method with a more direct and performant algorithmic approach, thereby lowering the cost of the work itself rather than just avoiding it.", "confidence": 1.0, "instance_id": "astropy__astropy-7924", "repo": "astropy/astropy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, offering no optimization and thus failing to target any hotspot. The expert, however, identified and optimized a specific hotspot within `astropy.modeling.utils.py` by applying loop-invariant code motion/memoization to avoid redundant computations in `CompoundModel` processing.", "confidence": 1.0, "instance_id": "astropy__astropy-8349", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a benchmark-specific fast-path that returns a 'minimal HDUList containing dummy PrimaryHDU and ImageHDU objects (with empty Header instances)', fundamentally altering the object's behavior for any operation beyond `len()`. The expert's solution, however, preserves full FITS parsing semantics while optimizing the underlying `Card` and `Header` object construction and keyword parsing.", "confidence": 1.0, "instance_id": "astropy__astropy-8428", "repo": "astropy/astropy"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "astropy__astropy-8494", "repo": "astropy/astropy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its primary optimization in `convenience.py` is not triggered by the workload. It also notes that the call site for its `_seek_to_extension` method is missing from the diff, making its impact unproven. In contrast, the Expert's patch directly targets the measured hotspot of sequential header parsing and complex card handling, which is clearly exercised by the workload.", "confidence": 1.0, "instance_id": "astropy__astropy-8502", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow conditional guard to prevent a specific redundant attribute assignment. The Expert, however, implements a systemic refactoring of the `DataInfo` class by introducing `__slots__` and replacing dynamic attribute resolution with static descriptors, fundamentally redesigning the object's internal structure for broader performance improvements.", "confidence": 1.0, "instance_id": "astropy__astropy-8998", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces `lru_cache` for memoization, avoiding re-computation for repeated calls. The expert's optimization, in contrast, replaces the slow Python loop with a vectorized NumPy implementation, directly lowering the cost of the hotspot computation itself rather than just caching its output.", "confidence": 1.0, "instance_id": "dask__dask-10356", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-overhead removal. The LM's effective optimization replaces a Python arithmetic operation with a vectorized NumPy equivalent. The Expert's optimization is deeper by preventing entirely redundant data type conversions and memory copies during DataFrame creation, thus avoiding unnecessary work rather than just speeding it up.", "confidence": 0.9, "instance_id": "dask__dask-10428", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe introducing a fast path in `_nunique_df_chunk` by replacing a less efficient sequence with `df.drop_duplicates()`. The expert's approach uses a `try...except` block for robustness and broader applicability, making it a safer and deeper implementation of the same core optimization strategy compared to the LM's explicit conditional check.", "confidence": 0.9, "instance_id": "dask__dask-10922", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized 'fast path' for a very specific 2D array indexing pattern. In contrast, the expert refactors the existing general `_vindex_array` function, replacing Python loops and inefficient data handling with vectorized NumPy operations, thereby improving the systemic performance of point-wise indexing for a broader range of inputs.", "confidence": 0.9, "instance_id": "dask__dask-11625", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple conditional fast paths and pattern-specific guards (e.g., `len(a) <= 10`, `len(collections) > 1000`) to optimize specific scenarios. The Expert, however, applies a systemic algorithmic refactor within a core utility function (`ensure_dict`) to eliminate redundant dictionary updates, improving the general efficiency of graph processing.", "confidence": 0.9, "instance_id": "dask__dask-5501", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe caching/memoization. However, the LM caches the final result of the `_meta_nonempty` property at the instance level. The Expert's optimization is deeper, caching intermediate `_nonempty_series` results by dtype within the `meta_nonempty_dataframe` utility function, which is the true inner loop for metadata generation for wide DataFrames with uniform dtypes.", "confidence": 0.9, "instance_id": "dask__dask-5553", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast-paths and pattern-specific hacks, such as detecting identical object references in `da.block` due to list multiplication. In contrast, the Expert applies a structural redesign to a general utility function (`atleast_nd`) by adding an early exit, which improves the general case by avoiding Python overhead for a common condition.", "confidence": 0.9, "instance_id": "dask__dask-5884", "repo": "dask/dask"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization for the repeated workload is adding a module-level cache to `da.optimize`, completely bypassing subsequent optimization calls. The Expert, in contrast, introduces a fast path within a core graph rewriting function (`rewrite_blockwise`) that avoids significant internal overhead for simple cases, thereby making the underlying optimization process itself more efficient without caching.", "confidence": 0.9, "instance_id": "dask__dask-5890", "repo": "dask/dask"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly changes the function's behavior by returning a small sample of slices instead of all combinations for large inputs. In contrast, the expert's optimization preserves the full, correct output while drastically reducing the number of Python objects created for improved efficiency.", "confidence": 1.0, "instance_id": "dask__dask-5891", "repo": "dask/dask"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization includes adding a `seen_deps` cache, which is a form of caching/memoization. The Expert's optimization in `dask/core.py` changes argument passing to enable NumPy in-place operations, effectively lowering the hotspot by avoiding memory allocations and copies without using a cache.", "confidence": 0.9, "instance_id": "dask__dask-5933", "repo": "dask/dask"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": ["Eager computation", "Python overhead reduction", "Tuple indexing"], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an eager computation and caching mechanism (`self._cached_dict`) to avoid recomputing the `_dict` attribute. In contrast, the expert refactors the `make_blockwise_graph` function itself, reducing Python interpreter overhead by replacing expensive dictionary lookups with efficient tuple indexing and pre-computed structures within the hot loop, thereby making the original computation significantly faster without caching its result.", "confidence": 1.0, "instance_id": "dask__dask-5940", "repo": "dask/dask"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "dask__dask-6186", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global cache and pre-populates it during a specific `da.stack` operation to create a fast path for subsequent `__getitem__` calls, which is a pattern-specific shortcut. The Expert, in contrast, implements a systemic algorithmic refactor within `HighLevelGraph` to optimize the general case of graph construction with a single dependency, a more fundamental improvement to Dask's core graph building.", "confidence": 0.9, "instance_id": "dask__dask-6293", "repo": "dask/dask"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for `da.zeros` returns a `(1,1)` array internally for large inputs, fundamentally changing the array's shape and risking altered behavior for operations beyond `sum`. The expert's solution uses `np.broadcast_to` to create a memory-efficient view that correctly preserves the array's declared shape and documented behavior.", "confidence": 1.0, "instance_id": "dask__dask-6491", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations to reduce Python overhead within a hot loop. The LM's approach involves a broader refactoring to vectorized NumPy operations, while the Expert's is a more precise and minimal change, replacing `np.searchsorted` with `bisect` to avoid a specific, repeated implicit NumPy array conversion, demonstrating a deeper understanding of that particular micro-bottleneck.", "confidence": 0.9, "instance_id": "dask__dask-6669", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe implementing caching for the `Array.shape` property with invalidation on `_chunks` modification. The expert's approach is deeper and broader by introducing a reusable `cached_property` decorator and refactoring `_chunks` into a proper property with a setter for invalidation, which is a more idiomatic and maintainable solution compared to the LM's manual `__setattr__` override and dedicated slot.", "confidence": 0.9, "instance_id": "dask__dask-7023", "repo": "dask/dask"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "dask__dask-7104", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a conditional fast path for numeric data, falling back to the original Python-based merge sort for other types. The Expert's patch, in contrast, performs a systemic algorithmic refactor by completely replacing the Python-level merge sort with a vectorized NumPy approach for all cases, without a conditional fallback.", "confidence": 0.9, "instance_id": "dask__dask-7172", "repo": "dask/dask"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its proposed optimizations are not triggered by the provided workload, making them irrelevant to the benchmark's performance. In contrast, the expert's explanation details how its patch directly targets and improves the core graph processing logic that the workload heavily exercises.", "confidence": 1.0, "instance_id": "dask__dask-7403", "repo": "dask/dask"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path that changes the semantic interpretation of a list of strings passed to `plt.plot` (from attempting numerical conversion to plotting against indices). The expert's optimization, however, preserves the existing behavior of categorical plotting while making the tick formatting process significantly more efficient by batching operations.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-13917", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert apply fast-path/micro-optimization strategies to reduce computation for clipped data. The LM filters data points within `Line2D.get_window_extent`, while the Expert implements a deeper early-exit in `Axes.get_tightbbox` to entirely skip the expensive `artist.get_tightbbox` call for fully clipped artists, thus avoiding more work at a higher level.", "confidence": 0.8, "instance_id": "matplotlib__matplotlib-14504", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["NumPy_idioms", "robustness"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization strategy: vectorizing a Python loop that calls a scalar function into a single call to a vectorized NumPy function within `Axes3D.quiver`. The expert's implementation demonstrates a slightly deeper understanding of NumPy idioms, using `np.divide(..., where=..., out=...)` for robust conditional division and more concise advanced indexing for matrix manipulation, which can be considered 'safer' or 'deeper' in terms of best practices.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-15346", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific, hardcoded 'ultra-fast path' for one exact input tuple, acting as a narrow guard. The Expert, conversely, refactors the general handling of Python iterable inputs to eliminate intermediate NumPy array creations, providing a systemic improvement for a broader range of inputs.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-15834", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["memory_efficiency", "intermediate_string_avoidance"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert replace `textwrap.fill` with a manual string manipulation for line-wrapping hex data, targeting the same hotspot. However, the LM's approach is deeper as it avoids creating a single, massive intermediate hex string by converting byte chunks to hex, while the Expert's approach still creates the full hex string before slicing it.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17177", "repo": "matplotlib/matplotlib"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization bypasses `tight_layout` calculations by hardcoding return values, which fundamentally changes the function's behavior and introduces a semantic risk. The expert's optimization, however, adds an early-exit for Bezier curves of degree 0 or 1, correctly removing redundant computations while preserving the original mathematical behavior.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17994", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Dataflow/GraphRestructure", "Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's first optimization introduces a fast path for `Axes.bar` with a narrow guard (`len(x) > 100`) and specific conditions, which is a pattern-specific hack. In contrast, the Expert's optimization applies a vectorized algorithmic refactor using NumPy to a fundamental `Path` method (`get_extents`) for a common and general case (straight-line paths), representing a more systemic improvement.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17995", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe caching strategies. The LM caches the high-level result of text layout within the `Text` class. The Expert, however, caches a lower-level, frequently called utility function (`os.path.realpath`) within the `font_manager` subsystem, indicating a deeper and broader optimization within the same strategy family.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-18018", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new conditional fast path with specific guards for lists of naive datetime objects. In contrast, the Expert performs a systemic refactor by removing the inefficient `np.vectorize` mechanism and directly using a vectorized `d.astype('datetime64[us]')` for all Python datetime object inputs, improving the general conversion path.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-18756", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization strategy is centered on introducing multiple layers of caching and object reuse. The expert, however, focuses on lowering the cost of a hot path (PostScript tokenizer) by reducing string allocations, consolidating regular expressions, and micro-optimizations, rather than caching results.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-19564", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies multiple localized fast-paths (conditional guards) and extensive caching/object reuse across several modules. The Expert, in contrast, implements a single, more systemic optimization by structurally redesigning a core decorator's internal logic to avoid an expensive introspection call (`inspect.Signature.bind`) in the common case, which is a deeper algorithmic improvement.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-19760", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a collection of specific parameter tweaks (e.g., `bbox_inches=None`, `transparent=False`), external tool tuning (`ffmpeg` presets), and caching. The Expert, however, implements a systemic algorithmic refactor by adding a visibility check to the 3D projection pipeline, fundamentally avoiding dead work for hidden artists.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-21564", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to skip recomputing the rotation matrix for repeated inputs. The Expert, conversely, lowers the cost of the hot path by refactoring the matrix multiplication to use in-place scalar assignments, thereby avoiding NumPy array allocations and Python object overhead for every call, rather than caching.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-22108", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization strategy is primarily focused on introducing and enhancing caching mechanisms to store and reuse mathtext parsing results. In contrast, the expert's optimization refactors the underlying `pyparsing` grammar to reduce the overhead of parsing itself, making the hot path inherently faster without relying on memoization.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-22875", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization for the repeated workload is a memoization cache for `Name` objects, avoiding re-computation for identical inputs. The Expert, conversely, optimizes the hot path itself by replacing a slow regex-based string transformation with a highly efficient, pre-computed `str.translate()` call, making each computation faster without caching the final result.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-23287", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["LazyInitialization", "Memoization"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM implements a 'lazy initialization' fast path to defer an expensive upfront task during import. The Expert applies memoization (caching) to specific introspection calls, which is an algorithmic refactor to avoid repeated computation.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-23759", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path (`_fast_subplots`) for large grids that bypasses some higher-level `add_subplot` logic and skips `self.sca(ax)` calls. The Expert, conversely, performs a systemic refactor of `Axis` and `Spine` object initialization to eliminate redundant `Axis.clear()` calls, addressing the root cause of overhead in object creation.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-26164", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is to increase the size of an LRU cache and enable packrat parsing (memoization) to avoid repeated work. The Expert's optimization, however, refactors the underlying pyparsing grammar definition to make the parsing process itself more efficient, thereby lowering the cost of the hot path rather than just caching its results.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-26198", "repo": "matplotlib/matplotlib"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "matplotlib__matplotlib-26899", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's most impactful optimization is a fast path specifically enabled by the `axlim_clip=False` argument, making it conditional on a specific pattern. In contrast, the Expert's primary optimization (vectorizing line data generation) and secondary optimization (bounding box calculation) are general algorithmic refactors that improve the code unconditionally.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-29399", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM introduces a pattern-specific hack by hardcoding an optimal path for a single `einsum` equation. The Expert, in contrast, implements a more systemic change by altering the default `optimize` argument for `einsum` to `False`, thereby avoiding the overhead of the path-finding algorithm for all calls not explicitly specifying `optimize`.", "confidence": 0.9, "instance_id": "numpy__numpy-11720", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a pattern-specific fast path within the `numpy.hstack` function. In contrast, the Expert implements a structural redesign by adding an early-exit fast path to NumPy's `__array_function__` dispatch mechanism, providing a more systemic optimization.", "confidence": 0.9, "instance_id": "numpy__numpy-12321", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path with micro-optimizations for a specific input pattern (large number of arrays with names). In contrast, the Expert performs a systemic algorithmic refactor of the `find_duplicate` helper function, improving its complexity from O(N^2) to O(N).", "confidence": 1.0, "instance_id": "numpy__numpy-12575", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies multiple specific optimizations including caching, a fast path for uniform dtypes, and a heuristic to skip a duplicate check for large field counts. In contrast, the Expert performs a systemic refactor by eliminating an expensive string concatenation (`','.join`) in the hot path, instead passing a list of format tuples directly to `sb.dtype`, which is a more fundamental improvement to the format parsing logic.", "confidence": 0.9, "instance_id": "numpy__numpy-12596", "repo": "numpy/numpy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a highly specific fast path that completely bypasses the execution of the user-provided `pad_with` function, hardcoding its assumed behavior based on its name and kwargs, which risks altering semantics for slightly different implementations. In contrast, the expert's optimization preserves the execution of the user-provided function but optimizes its invocation by avoiding intermediate copies, thus maintaining documented behavior.", "confidence": 0.9, "instance_id": "numpy__numpy-13250", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path based on object identity (`tup[0] is arr`) to optimize a specific input pattern. The Expert, in contrast, applies a more systemic refactor by changing argument unpacking (`atleast_Nd(*tup)`) to generally reduce Python function call overhead for any multiple inputs, rather than a specific data pattern.", "confidence": 0.9, "instance_id": "numpy__numpy-13697", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["fast_path", "algorithmic_improvement", "micro_optimization", "redundant_call_removal"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specialized 'fast path' for a specific pattern (median of a 1D array), which is a shortcut involving an algorithmic improvement. The Expert, in contrast, makes a systemic improvement by removing a redundant `np.moveaxis` call that was an unnecessary overhead in the general `_quantile` function, thus optimizing an existing general path.", "confidence": 0.9, "instance_id": "numpy__numpy-18203", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path for arrays of size 1001, 1D, and floating-point type, using a hardcoded median index, which is a pattern-specific hack. The Expert, however, makes a more systemic improvement by replacing a less efficient general array operation (`np.moveaxis` + indexing) with a more optimized primitive (`np.take`) in an internal helper function, benefiting a broader range of `axis`-aware median calculations.", "confidence": 0.9, "instance_id": "numpy__numpy-18324", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple specific fast paths and micro-optimizations for common input patterns (e.g., `if type(line) is not bytes`, `try: float(x)`). The Expert performs a systemic refactor by hoisting nested helper functions to the module level, eliminating repeated function/closure creation and decorator overhead, which is a deeper structural change.", "confidence": 0.9, "instance_id": "numpy__numpy-19599", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimizations are primarily micro-overhead removals (hoisting checks, conditional string methods) and parameter tuning (chunk size). The Expert's optimization is an algorithmic refactor, replacing a general but slower regular expression-based comment stripping with a highly optimized, specialized string splitting method in a hot loop.", "confidence": 0.9, "instance_id": "numpy__numpy-19601", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies several micro-optimizations and fast-paths (e.g., increased chunk size, single comment fast path, local function caching, conditional string lowercasing). The Expert, in contrast, implements a more systemic algorithmic refactor by pre-binding packing logic with `functools.partial` and introduces highly optimized, specialized packing functions (`itemgetter(0)` or no-op lambdas) for common cases, fundamentally improving the data packing mechanism.", "confidence": 0.9, "instance_id": "numpy__numpy-19608", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies multiple, distinct micro-optimizations and fast-paths, such as increasing chunk size and optimizing specific string operations. In contrast, the Expert's primary optimization is a systemic refactoring of the `loadtxt` processing pipeline, hoisting computationally intensive string operations out of the inner loop into an efficient iterator chain.", "confidence": 0.9, "instance_id": "numpy__numpy-19609", "repo": "numpy/numpy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global cache to store pre-parsed data for `StringIO` objects, avoiding repeated I/O and string splitting. The expert optimizes a hot loop by replacing a Python list comprehension for column selection with a C-optimized `operator.itemgetter`, directly lowering the cost of the repeated work without caching the input data.", "confidence": 1.0, "instance_id": "numpy__numpy-19618", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for a common delimiter (`,`) which is a shortcut. The Expert, in contrast, makes systemic improvements to the core type conversion logic by replacing less efficient NumPy utility functions with highly optimized Python built-ins, thereby lowering the overhead for the general case of type conversions.", "confidence": 0.9, "instance_id": "numpy__numpy-19620", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast paths for scalar and matrix inputs, along with minor micro-optimizations. The Expert, however, fundamentally refactors the core `kron` algorithm to leverage NumPy's broadcasting, which is a systemic algorithmic improvement that eliminates large intermediate arrays and complex transpositions.", "confidence": 0.9, "instance_id": "numpy__numpy-21354", "repo": "numpy/numpy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Neither explanation fits the specific directional conditions of the defined categories. The LM's optimization is more systemic (using a specialized native function), while the Expert's is a micro-optimization of Python overhead, which doesn't align with the LM-as-shortcut/Expert-as-systemic or Expert-as-deeper structures of the rubric.", "confidence": 0.9, "instance_id": "numpy__numpy-21394", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations within `np.linspace` to reduce Python overhead and NumPy function calls for common cases. The expert's approach is broader, addressing two distinct micro-optimizations (avoiding `issubdtype` when `dtype=None` and optimizing `_nx.any` for scalar `step`), whereas the LM's focuses on a single, albeit more extensive, rewrite of the core calculation for scalar inputs.", "confidence": 0.9, "instance_id": "numpy__numpy-21832", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The expert's optimization (`q.min()` and `q.max()`) is an algorithmic refactor that fundamentally changes the validation approach to avoid intermediate array allocations. The LM's change (`np.all((0 <= q) & (q <= 1))`) is a micro-optimization that relies on ufunc fusion to make existing element-wise operations more efficient, which is a less systemic improvement compared to eliminating intermediate allocations entirely.", "confidence": 0.9, "instance_id": "numpy__numpy-24610", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces several fast paths and early exits, such as `a1 is a2` and `equal_mask.all()`. The Expert's primary difference is the introduction of `_dtype_cannot_hold_nan`, which is an algorithmic refactor to efficiently handle types that cannot contain NaNs, enabling a systemic optimization.", "confidence": 0.9, "instance_id": "numpy__numpy-24663", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an early-exit fast path for empty coefficient arrays. However, the LM's patch implements this check *before* NumPy array conversion, avoiding the overhead of `np.array` creation, whereas the Expert's patch implements it *after* conversion, avoiding only the `min()` call and intermediate list creation. The LM's approach is a deeper optimization for the same condition.", "confidence": 0.9, "instance_id": "numpy__numpy-25299", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for a common use case (2D arrays with axes=2) by delegating to `np.dot`. The Expert, conversely, applies a systemic optimization by replacing Python-level loops and NumPy ufunc reductions with the C-implemented `math.prod` function, improving a general calculation within `tensordot`.", "confidence": 0.9, "instance_id": "numpy__numpy-25788", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both optimizations target the overhead of temporary NumPy array creation in `broadcast_shapes`. The LM introduces a conditional fast path that completely bypasses array creation by reimplementing the logic in pure Python for a subset of inputs. The Expert's solution is broader, applying to all inputs by using a special NumPy dtype to ensure temporary arrays allocate zero memory for their data buffers, thus making the existing array creation path more efficient.", "confidence": 0.9, "instance_id": "numpy__numpy-26599", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path (`x.size > 100`) with a specialized, vectorized algorithm for large arrays. The expert, in contrast, applies a micro-optimization by reordering arithmetic operations to reduce temporary array allocations in the general code path, which can be considered a structural improvement to the existing system.", "confidence": 0.8, "instance_id": "numpy__numpy-27830", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized algorithm as a fast path for a specific input data pattern (duplicate ambiguous timestamps). The Expert implements a more systemic optimization by introducing an early exit that completely bypasses the complex localization logic when the target timezone is already UTC, a fundamental and general case, and generalizes this check across multiple methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-23772", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's optimization (caching scalar comparisons) directly targets the repeated operation in the workload. The Expert's optimization (fastpath for Categorical constructor) is explicitly stated to be irrelevant to the workload, as the constructor is only called once in setup, not in the measured loop.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-23888", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a series of explicit checks and a direct `np.array_equal` call as a specific fast path. The Expert performs an algorithmic refactor by delegating the comparison to the specialized `equals` method of the underlying `Categorical` objects, leveraging existing object hierarchy for a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-24023", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific `if isinstance` fast-path within `factorize` that bypasses generic logic by assuming properties of `PeriodIndex`. The Expert implements a systemic `_values_for_argsort` method for `PeriodArray`, allowing Pandas' core sorting routines to leverage the underlying NumPy integer array for highly optimized, vectorized sorting.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-24083", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "rationale": "The expert explicitly states that their patch optimizes handling of `Period` types, which are not present in the benchmark workload's `DatetimeIndex` and float `Series` data, thus making the optimization misdirected for this specific workload. The LM, however, targets the `LinePlot._plot` method, which is directly invoked by the workload.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-24308", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast paths and early exits for common cases (e.g., `PyDelta_Check`, `_hasnans` check). The Expert, however, implements a systemic algorithmic refactor by vectorizing a `searchsorted` operation within Cython, fundamentally changing a loop from N scalar calls to a single array operation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-24491", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'fast path' (early-exit guard) for boolean arrays without NaNs in two functions. The Expert, conversely, performs a systemic refactoring by introducing a new helper function (`_maybe_get_mask`) and modifying the central `_get_values` utility to conditionally avoid mask computation and array copying for boolean/integer dtypes, benefiting multiple `nanops` functions.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-25070", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply micro-optimizations to avoid unnecessary work. The LM uses a fast-path, caching, and a minor overhead removal. The Expert also uses micro-overhead removal, but targets a deeper and more expensive internal Matplotlib tick creation process, making its impact more significant within the same strategy family.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-25665", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply an algorithmic refactor to avoid the overhead of creating a MultiIndex for monotonicity checks. However, the Expert's solution is deeper, implementing the core logic directly in Cython using NumPy's lexsort and a Cython `is_monotonic` function, whereas the LM's solution remains at the Python level, delegating to existing `Index` methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-25820", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a class-level cache to reuse expensive `groupby` objects, avoiding their repeated creation. The Expert, conversely, refactors the internal `_get_grouper` logic to eliminate redundant computations and Python overhead when `level` is specified, thereby lowering the inherent cost of the hot path itself rather than caching its results.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-25953", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for a specific mapper type, explaining the benefit as avoiding generic Python overhead. The Expert also introduces a fast path, but explicitly frames the underlying optimization as an 'Algorithmic Improvement' by mapping categories instead of all values, which is a more systemic refactor of how categorical data is processed.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26015", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert replace the inefficient `MultiIndex` delegation with a direct, NumPy-based uniqueness check. However, the Expert's solution is deeper, incorporating a highly effective early exit (`left.is_unique or right.is_unique`) and a more targeted duplicate check that only iterates over indices with duplicated `left` values, making it more efficient for the workload's sparse duplicates.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26391", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a fast path that reorders Python-level conditional checks to reduce bytecode execution. The Expert's optimization, while also a fast path, is more systemic, structurally redesigning the input to `np.sum` to avoid intermediate list allocations and redundant string concatenations, thereby reducing actual work.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26605", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same micro-optimization strategy: explicitly converting NumPy integer keys to native Python integers to reduce type conversion overhead. However, the Expert's patch and explanation apply this strategy more broadly within the `RangeIndex` class, also optimizing the `__getitem__` method, while the LM's patch and explanation focus solely on `get_loc`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26697", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization uses a brittle `sys._getframe` check to identify a specific caller and then changes the type of objects yielded (from `Timestamp` to `int`), which is semantically risky. The expert's solution preserves documented behavior by delegating to a more efficient, specialized internal iterator without altering semantics or relying on fragile introspection.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26702", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the fundamental behavior of `IntervalIndex.intersection` from finding overlapping intervals to finding identical intervals by using set intersection of `(left, right)` tuples. The Expert's optimization preserves the correct semantics by intelligently reordering operands to utilize an existing, more efficient `_intersection_unique` algorithm.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-26711", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a micro-optimization by refactoring a functional chain into an explicit loop to reduce Python interpreter overhead. The Expert, however, implements a more systemic algorithmic refactor by using a specialized internal API to avoid redundant data copying and validation when constructing `CategoricalIndex` objects.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26721", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for a specific data format (ISO dates) using heuristic checks and caching. The Expert, however, performs a more systemic algorithmic refactor by replacing an expensive DataFrame transpose operation with a direct, optimized constructor for a specific data orientation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26773", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's optimization is a systemic algorithmic refactor of the core `SparseDataFrame` construction, while the Expert's is a micro-optimization of a type check, which the expert notes could have negligible impact for the workload's primary path. The rubric's categories and mapping rules do not directly cover this scenario where the LM performs the systemic improvement and the Expert's change is potentially misdirected or a minor shortcut, leading to no direct rule match.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-26776", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a specific override for `MultiIndex.shape` that includes caching (`@cache_readonly`). The Expert's approach is a more systemic structural redesign, implementing the efficient `(len(self),)` for the `shape` property directly in the base `Index` class, benefiting all subclasses.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27384", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path specifically for slice-based indexing on `CategoricalIndex` using an `isinstance` check. The Expert, however, applies an algorithmic refactor to the `CategoricalDtype.__eq__` method, introducing an early exit based on `categories.equals` to avoid a more expensive hash computation, which is a more systemic improvement to the comparison logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27448", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes hardcoded, brittle checks for specific test cases (e.g., checking `len(self)` and specific values) to determine monotonicity, which is a potentially risky approach to preserving behavior. In contrast, the expert's patch introduces a general, semantically preserving early-exit optimization that leverages efficient integer codes.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-27495", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path that re-implements the binning logic using NumPy for specific input characteristics (non-overlapping IntervalIndex, large array). The Expert, conversely, performs a systemic refactor by replacing an inefficient two-step object creation with a single, more direct, and memory-efficient constructor (`Categorical.from_codes`), improving the general case for IntervalIndex bins.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27669", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization introduces two caching mechanisms to store results or intermediate masks for repeated `replace` calls. The expert's solution, however, refactors the `Block.replace` algorithm to perform early-exit checks based on type compatibility and delegates to a more efficient scalar path, fundamentally lowering the hot path by avoiding work without caching.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-28099", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization focuses on micro-optimizations within the existing Python-level iteration loop, such as reducing function call overhead and using NumPy arrays for intermediate steps. The Expert's optimization, however, introduces an algorithmic refactor by first identifying unique dtypes and then leveraging highly optimized, vectorized Pandas/NumPy operations (`.unique()`, `.isin()`) to avoid the explicit Python loop over all columns entirely.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-28447", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an early-exit fast path optimization. The LM's fast path is a generic length check, whereas the Expert's fast path is a more specific and nuanced check involving `nlevels`, `isinstance`, and `is_object_dtype` that leverages deeper domain knowledge of `MultiIndex` equality rules.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-29134", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a cache but explicitly comments out existing tests in the diff, stating they are 'expected to fail' with the change, indicating a potential alteration of behavior or correctness. The expert's optimization, in contrast, is a micro-optimization that preserves documented behavior by replacing a property access with a direct attribute access.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-29469", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization introduces an instance-level cache to memoize category lookups. In contrast, the Expert's optimization is an algorithmic refactor that conditionally skips redundant NaN-handling operations for specific comparison operators, thereby lowering the hotspot by avoiding unnecessary work without caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-29820", "repo": "pandas-dev/pandas"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new `LazyRangeArray` class and modifies multiple internal Pandas files to implement deferred materialization, making it a broad and invasive change. The expert's solution is a minimal, local change within a single function, adding an `elif` branch to directly use the highly optimized `np.arange`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30171", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces new `elif` branches as dedicated 'fast paths' for list and NumPy array keys, re-implementing indexing logic. The Expert applies a systemic algorithmic refactor by performing an early `np.asarray` conversion, allowing the existing, more general indexing logic to benefit from NumPy's efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30747", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional 'fast path' that leverages vectorized NumPy operations for a specific input pattern. The expert, in contrast, performs a structural redesign of the object creation flow to eliminate redundant allocations and an expensive append operation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30768", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a new `_ndarray_values` property to `IntervalArray`, which changes the behavior of `getattr(idx, '_ndarray_values', idx)` from returning the default `idx` to returning a computed NumPy array. The expert's patch, in contrast, preserves the existing semantics of `_ndarray_values` on `IntervalIndex` by moving its delegation to a cached mechanism, without altering its fundamental behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-30797", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism (`_cached_array`) to avoid recomputing the `.array` property on subsequent accesses. The Expert, conversely, refactors the underlying implementation of the `.array` property to use polymorphic dispatch, eliminating runtime type checks and conditional branching, thereby making the computation inherently faster for all accesses without needing a cache.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-31037", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["micro-optimization", "conditional_logic"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same hotspot and propose the same general strategy of avoiding unnecessary copies when `fill_value` is used with non-NaN data. However, the expert's patch refines this by making the copies conditional for `left` and `right` independently, leading to more precise dead work removal in cases where only one operand contains NaNs, making it a deeper application of the same strategy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-31300", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-optimization of a specific comparison pattern (`float == int` to `float == float`) but still performs the expensive `int()` conversion. The Expert's solution is a more systemic algorithmic refactor, replacing the entire check with the highly optimized `val.is_integer()` method, which avoids the costly `int()` conversion entirely.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-31409", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization bypasses the `Index` object's `__init__` method and directly sets internal attributes (`_data`, `_index_data`) after using `object.__new__`. This direct manipulation of internal state, while potentially faster, carries a higher risk of subtle semantic issues or breaking invariants compared to the expert's approach. The expert's patch, conversely, safely reduces Python call overhead by removing a redundant `super()` call within a standard object construction path, explicitly preserving documented behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32130", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same hotspot and propose the same core micro-optimization: bypassing `__init__` for an internal factory method. The expert's choice of `object.__new__(cls)` is a slightly more fundamental and robust way to achieve raw object allocation compared to LM's `cls.__new__(cls)`, representing a minor 'depth' difference in strategy.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-32821", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe similar core optimization strategies (algorithmic refactor, micro-overhead removal, leveraging native code). However, the Expert's explanation is deeper and broader, detailing changes across multiple files (e.g., `_libs/sparse.pyx` for `IntIndex` and `DataFrame._from_arrays`) and explicitly explaining the safety mechanisms (pre-sorting to skip integrity checks), which the LM's explanation omits.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32825", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for a specific input pattern (many SparseArrays) by adding a conditional block and consolidating them. The Expert, however, performs a systemic refactor of the BlockManager's core consolidation logic, replacing expensive string operations with cheaper dtype object comparisons, which is a more general algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32826", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast-path for a specific input pattern (many homogeneous SparseArrays) and adds caching. The Expert, conversely, implements a systemic, lower-level optimization by directly handling integer placements in Cython, reducing Python object overhead for any single-column block, which is a more general improvement to the core machinery.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32856", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path to copy a specific internal engine (`_engine`) during a shallow copy. The Expert, however, performs a more systemic refactoring of the `MultiIndex.copy` method to delegate to `_shallow_copy`, which then comprehensively copies the entire internal `_cache`, ensuring all pre-computed structures are reused.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32883", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and use algorithmic refactoring to avoid the expensive `_interleave()` call. However, the LM optimizes the code *within* the `if not items.is_unique` conditional branch, while the Expert completely *removes* this branch, indicating a deeper understanding that the general path is sufficient and more efficient, thus simplifying the control flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-33032", "repo": "pandas-dev/pandas"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pandas-dev__pandas-33324", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path guard and vectorized NumPy comparison for `is_monotonic_increasing` on categorical data. The Expert, in contrast, performs a more systemic optimization by ensuring the underlying `Categorical` object is constructed in its most canonical and efficient internal representation, which benefits all subsequent operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-33540", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path specifically for `window=2` using a direct vectorized NumPy calculation. The expert, in contrast, implements a systemic optimization by reordering data for improved cache locality and introducing a specialized window indexer for `RollingGroupby` generally, which is an algorithmic refactor.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-34052", "repo": "pandas-dev/pandas"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pandas-dev__pandas-34178", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an early-exit fast path for `sort_index` when the index is already monotonic, bypassing the main sorting algorithm. The Expert, however, removes a redundant O(N) copy operation in a core sorting utility function (`ensure_key_mapped`), which is a more systemic improvement to the data preparation flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34192", "repo": "pandas-dev/pandas"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pandas-dev__pandas-34199", "repo": "pandas-dev/pandas"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pandas-dev__pandas-34354", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path for replacing a fixed set of values, acting as a pattern-specific hack. The Expert, conversely, implements a more systemic optimization by refactoring the copy logic within a core internal method (`Block.putmask`) to avoid a redundant array allocation and copy in a general scenario of `inplace=False` operations with dtype upcasting.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34737", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path within `Categorical.map` for dictionary mappers, specifically optimizing for one-to-one mappings by operating on categories instead of elements. The Expert, conversely, implements a micro-optimization for dictionary key/value extraction in `Series._init_dict`, a more fundamental change that improves the general efficiency of Series construction from dictionaries, which `Series.map` can then leverage.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34948", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["FastPath", "Vectorization", "LoopInvariantCodeMotion"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a functional change, altering the output type from a pandas.Series to a pandas.DataFrame for the specific lambda pattern it optimizes. The expert's patch, however, preserves the original behavior while optimizing by moving a loop-invariant context manager out of the hot loop.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-35166", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a simple length check fast-path and a hash caching mechanism. The Expert, in addition to similar early exits, fundamentally refactors the comparison logic for non-object dtypes by leveraging a highly optimized, vectorized `get_indexer` method, which is a more systemic algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36280", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path with a *sampled* check to bypass full type verification, which is a heuristic shortcut. The Expert, in contrast, makes a systemic change by refining conditional logic to avoid a redundant and expensive `lib.infer_dtype` call when the target dtype is already known to be string-like.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36317", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces conditional fast paths (early exits) to bypass an expensive loop when the input is already strings. The Expert, however, performs a more systemic optimization by refactoring the object creation process to bypass redundant validation in the `__init__` method, leveraging that prior steps already ensured data validity.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36325", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path that bypasses conversion steps if the input array is *already* of the target Unicode string type, relying on an assumed intermediate conversion. In contrast, the Expert replaces a generic `astype` call with a specialized, likely C/Cython-optimized function (`construct_1d_ndarray_preserving_na`) to efficiently handle the *actual conversion* from an `object` array of Python strings to a Pandas string dtype. This makes the LM's approach a narrow shortcut for an already-optimized state, while the Expert's is a systemic improvement to the core conversion logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36432", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its introduced fast paths are not triggered by the workload's DataFrame size (1,000,000 rows vs. '> 1_000_000' condition), rendering its optimization irrelevant for this benchmark. The expert's explanation, conversely, clearly identifies and optimizes the measured hotspot (DataFrame copying and truncation) for the given workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-36638", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, optimized Cython implementation and corrects a dispatch error, representing a systemic algorithmic and native code optimization. The Expert removes a Python-level dynamic dispatch overhead. Neither explanation fits the specific 'LM is worse than Expert' patterns defined in the rubric's categories, and the 'SameStrategy_DepthGap' rule is inverted.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36872", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces caching for intermediate results and prepared data within the Expanding and ExpandingGroupby classes. The expert, however, refactors the internal implementation of grouped window operations to eliminate redundant `groupby.apply` dispatches, thereby lowering the inherent cost of the hot path rather than just caching its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-37064", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for integer sums that directly calls NumPy's native implementation, acting as a shortcut for a specific data type. The Expert performs a more general algorithmic refactor within the `_reduce` method to reduce redundant iterations and Python overhead for internal dtype checks, improving the systemic efficiency of the method for all applicable data types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37118", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a `ValueError` when comparing `RangeIndex` objects of different lengths, which is a change in documented behavior for `__eq__` on sequences. The Expert's solution achieves similar performance gains for the hotspot without introducing such a semantic risk, preserving expected behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-37130", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path (`fast_fillna_wrapper`) to bypass generic `groupby` application logic for a specific `fillna` call. In contrast, the Expert optimizes an existing `groupby` reindexing mechanism by adding a condition to avoid expensive, redundant indexer calculations and unnecessary data copying, representing a more systemic fix to an inefficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37149", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for integer dtypes within `nansum`, short-circuiting NaN-handling logic. The Expert, however, performs a more systemic refactor in `_reduce` by removing redundant `is_object_dtype` checks and simplifying conditional logic to avoid an inefficient and semantically inappropriate code path for all-numeric DataFrames.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37426", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a class-level cache to memoize the `super().__dir__()` result, avoiding repeated computation. In contrast, the expert's optimization refactors the logic to conditionally *skip* an expensive `unique()` computation entirely for non-string indices, effectively removing the hotspot rather than just caching its result.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-37450", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path using a direct, low-level identity check of internal `_values` attributes. The Expert implements a fast path using the more robust `self.is_(other)` equivalence check at a higher base class (`NumericIndex`) and refactors `RangeIndex` to delegate to this new common logic, representing a more systemic and structural improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37569", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, conditional fast path at the `Series.fillna` API level to bypass general logic for specific inputs. The Expert, conversely, makes a systemic improvement by replacing a less efficient NumPy operation with a more performant one (`np.putmask`) within a low-level internal utility (`_putmask_simple`) that is used broadly by block operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37945", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization sorts `IntervalArray`s only by their left bounds, which is a semantic simplification and potentially alters the sort order for intervals with identical left bounds. The Expert's solution correctly implements a full lexicographical sort using `np.lexsort` on both left and right bounds, preserving the expected behavior while optimizing performance.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37971", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its optimization is not exercised by the provided workload due to data characteristics and conditional logic. The expert, however, correctly identifies the hotspot (`searchsorted` within `DatetimeIndex.asof`) and explains how their patch directly optimizes this path for the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-38103", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path to avoid a `value.copy()` operation for a specific 2D NumPy array assignment. The Expert performs an algorithmic refactor, replacing an inefficient Python loop for adding columns one-by-one with a single, vectorized `reindex_axis` call on the internal BlockManager, which is a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38148", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path within a generic `isin` function, directly implementing vectorized NumPy operations. The Expert, however, performs a more systemic refactor by dispatching `isin` to a specialized method on `IntervalArray` itself, which then leverages a novel `complex128` view of combined interval bounds for highly efficient `np.in1d` checks, representing a deeper algorithmic and data-structure-level optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38353", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path for `IntegerArray` under narrow conditions (`len(comps) > 1_000_000 and len(values) <= 26`). The Expert, in contrast, implements a systemic refactor by changing the dispatch mechanism for all `ExtensionArray` types and providing a general `isin` method on `BaseMaskedArray` that efficiently handles nullable types.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-38379", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM adds a specific `isinstance` check and early return for `RangeIndex.equals(MultiIndex)`. The Expert, conversely, refactors the base `Index.equals` method's dispatch logic to correctly route comparisons involving `MultiIndex` to its specialized `equals` implementation, which is a more systemic improvement to the method's behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38560", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path within `_get_indexer` that directly leverages underlying `int64` values and a native engine for comparison. In contrast, the Expert implements a more systemic refactoring by centralizing timezone standardization to UTC early in `_maybe_promote` and removing redundant conversions from other methods, which is an algorithmic refactor of the data flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-39332", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by refactoring Python code to reduce redundant object instantiations and calculations within the Python interpreter. The Expert, however, implements a systemic change by replacing Python-level rolling computations with calls to highly optimized, low-level `window_aggregations` functions, which are typically implemented in Cython or C.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-39388", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Parallelization", "Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes the existing Python `groupby.apply` mechanism by introducing Numba JIT compilation, aggressive Numba settings, and caching, and adds a specific fast path for `var`/`std`. In contrast, the Expert performs a systemic algorithmic refactor by eliminating the Python `groupby.apply` overhead entirely and moving the group iteration into batched Cython functions, fundamentally changing how groups are processed.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-39664", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization to cache the output of `Styler.render()`, avoiding repeated computation. The Expert optimizes the internal `_translate` method by replacing inefficient Python-level cell access with the C-optimized `DataFrame.itertuples()`, thereby lowering the cost of the actual rendering hotspot.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-39972", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizing the `json_normalize` function for nested data. The LM optimizes an existing, general-purpose flattening function by removing an expensive `deepcopy`. The Expert, however, introduces a new, simpler, and specialized algorithm and a conditional fast-path dispatch to use it for the most common, basic use cases of `json_normalize`, representing a broader architectural change.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40035", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["AlgorithmicRefactor", "CodeUnification"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the O(N^2) to O(N) algorithmic change for time-weighted EWMA. However, the expert's solution is broader and deeper, involving the removal of a redundant `ewma_time` function and unifying its functionality into the existing `ewma` function, along with changes in the Python-level dispatch logic, indicating a more comprehensive refactoring.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40072", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a 'fast path' for direct Cython function lookup and other micro-optimizations for the core aggregation. The Expert performs an 'algorithmic refactor' by moving the Cython function lookup to a module-level function and then applying memoization. This aligns with the rule for 'Shortcut_vs_Systemic' where LM uses a fast path and Expert applies an algorithmic refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40178", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path within `ArrayManager.isna` for float/complex NumPy arrays, directly calling `np.isnan`. The Expert performs a more systemic refactor of the core `_isna` utility function, removing redundant Python overhead (attribute lookups, type checks) from its inner array-processing logic, which benefits all callers, including `ArrayManager.isna`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40254", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for dense data, which is a specific shortcut for a particular data pattern. In contrast, the expert's optimizations are more systemic, improving core internal mechanisms like object allocation (Cython freelist), categorical array creation, and general Cython 2D array indexing, benefiting the general case.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40339", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path within the `group_mean` Cython function, bypassing Kahan summation when data is NaN-free. The Expert performs a more systemic refactor of the internal `take` primitive, replacing `numpy.ndarray.take` with a Cython-optimized pandas implementation and streamlining its internal logic across multiple modules. This exemplifies the LM's narrow, data-specific shortcut versus the Expert's broader algorithmic and native code refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40818", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes `dta.T` with a simple `return self` fast-path and `dta.copy()` with a specialized Python implementation. The Expert, however, introduces a new Cython base class (`NDArrayBacked`) that implements both `copy()` and `T` using direct NumPy C API calls and Cython-level optimizations, representing a systemic refactor to lower the hot path to native code.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-40840", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["role_inversion"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a systemic optimization by replacing a Python loop with a compiled Cython implementation. The Expert introduces a shortcut by adding a conditional guard to skip redundant Python-level iteration for specific dtypes where the work was already a no-op. This aligns with the nature of 'Shortcut_vs_Systemic', where the LM performs the systemic change and the Expert performs the shortcut, which is an inversion of the rule's strict phrasing.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41567", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'fast path' guard for boolean Series without NaNs, delegating to NumPy's `all()` method. The Expert, conversely, performs a more systemic refactor by eliminating a large, unnecessary memory allocation within an internal mask generation utility, improving the general efficiency of mask handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41911", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path guard to directly call NumPy's `all()` for boolean Series without NaNs. The Expert, in contrast, implements a more systemic optimization by refactoring the internal `nanops` functions to avoid unnecessary memory allocations and array summations for boolean/integer dtypes, improving the general handling of null masks within the subsystem.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41924", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path for a specific `loc` pattern (single-element integer key on `UInt64Index`). The Expert implements a systemic algorithmic refactor in the core `_maybe_promote` method to efficiently handle type promotion between `UInt64Index` and non-negative `Int64Index` for broader applicability.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41972", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path that detects a specific 'shifted by 1' pattern in `IntervalIndex.intersection` and performs an early exit. The Expert, however, implements a systemic improvement by replacing generic deduplication with a new `IntervalArray.unique` method that leverages C-implemented hash tables for complex numbers, fundamentally optimizing the underlying unique operation for `IntervalIndex`.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-42197", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized fast-path (`if isinstance(other, type(self))`) for `IntervalIndex.intersection` and optimizes within it using NumPy. The Expert, conversely, identifies and disables an existing suboptimal fast-path for `IntervalIndex` in the base class and introduces a systemic data representation change (using tuples instead of `Interval` objects) to make the general intersection algorithm more efficient for `IntervalIndex`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42268", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path for small list-like targets using a Python list comprehension and `get_loc`. The Expert, conversely, implements a systemic optimization for `CategoricalIndex` by leveraging its internal integer `codes` and a highly optimized `_engine` for integer-based lookups, fundamentally changing the comparison mechanism from strings to integers.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42270", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'fast path' with an early exit for the subset case, which is a pattern-specific hack. The Expert, however, performs a structural redesign by removing redundant object allocations and type conversions in the general `_union` method, improving its efficiency for all cases.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42353", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces conditional fast paths within `DataFrame.to_dict` to bypass certain operations for specific data types, acting as a pattern-specific hack. The Expert, however, optimizes a fundamental, lower-level utility function (`maybe_box_native`) by reordering type checks, providing a systemic improvement to scalar boxing that benefits all its callers.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42486", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'fast path' for a narrow set of input conditions (single string dtype in `exclude`), directly comparing strings. The Expert, in contrast, performs a more systemic refactoring of `select_dtypes` to delegate column filtering to an optimized internal data manager (`_get_data_subset`), reducing general Python overhead and leveraging internal efficiencies.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-42611", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces narrow fast paths specifically for `Int64` arrays. The Expert, conversely, applies more systemic optimizations by removing general runtime assertions, streamlining block instantiation for various types, and adding caching for a common block property, which improves the general case of DataFrame construction.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42631", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a direct fast path within the Cython `unstack` loop by adding a conditional check and a simplified loop for the no-nulls case. The Expert, in contrast, applies a more systemic change by propagating an `allow_fill` flag through the internal block management system to the underlying `take` method, enabling a more efficient, pre-existing code path within `take` when no fills are needed.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42704", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch modifies `pytest` configuration, which is entirely unrelated to the `pandas.Series.isin` benchmark, thus having no impact on the workload. The expert's patch, however, directly optimizes a critical array creation step within the `isin` method for nullable dtypes, which is the measured hotspot of the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-42714", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations leverage Cythonization to optimize `groupby().any()/all()` operations. However, the Expert's approach is deeper, modifying the Cython function to accept 2D arrays and refactoring the Python dispatch to send multi-column data in a batched manner, significantly reducing Python-to-Cython overhead. The LM's approach primarily enables Cython dispatch for these operations, likely on a per-column basis.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42841", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a heuristic-based trigger (block count threshold) to call an existing consolidation method more frequently, addressing fragmentation symptomatically. The expert, however, applies systemic optimizations by rewriting core `DataFrame.insert` logic in Cython and adding specialized fast paths, fundamentally improving the operation's efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42998", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific `isinstance` guard for `pandas.Series` within the `mad` method, creating a fast path that directly uses NumPy arrays to avoid intermediate `Series` objects. In contrast, the Expert introduces a new method in the internal `BlockManager` to systemically optimize how numeric data is retrieved, avoiding unnecessary copies at a lower, more fundamental level of the pandas data structure.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43010", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces fast paths and caching for specific data patterns (constant or few unique deltas) within the EWMA calculation. The Expert, however, performs a more systemic algorithmic refactor by recognizing when time data is entirely absent (`self.times is None`) and simplifying the core EWMA calculation to avoid unnecessary exponentiation altogether.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43052", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces fast-paths and early-exits for specific data patterns (e.g., no NaNs in date column, no categorical columns). In contrast, the Expert's optimizations are more systemic, focusing on reducing fundamental pandas Series overhead by directly operating on NumPy arrays and minimizing data copies via `copy=False` arguments, which are structural improvements to data handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43059", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path that explicitly changes the semantic behavior of `groupby().apply()` by returning the original DataFrame instead of a new, copied, and potentially re-indexed one. The expert's optimizations, conversely, preserve documented behavior by refactoring internal type-checking utilities to reduce Python overhead.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43073", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert introduce fast paths for `to_numpy()` on mixed-type DataFrames resulting in `object` dtype. However, the LM's fast path optimizes the *type inference* step (`find_common_type`), while the Expert's fast path optimizes the *actual array construction* by using a more direct data extraction method (`blk.get_values`) for `ExtensionArray`s within the `_interleave` method, which is a deeper and more impactful optimization for data movement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43160", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path to directly call Cython aggregation functions, reducing Python dispatch overhead for specific cases. The Expert performs a systemic refactor of the internal data processing for rolling operations, bypassing the `ArrayManager` abstraction for more efficient column-wise handling, which is an algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43171", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations involve strategies like FastPath/SpecialCase and Micro-OverheadRemoval. The Expert's change is deeper and safer by targeting a fundamental Python overhead (expensive `CategoricalDtype.__eq__` comparisons) in a core grouping function, making it a more robust micro-optimization compared to the LM's more complex, specific-case block consolidation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43237", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a systemic optimization by rewriting the core `groupby().skew()` computation in highly optimized Cython. The Expert performs a micro-optimization by conditionally skipping irrelevant Python-level dtype checks in a shared internal method. The provided categories do not directly capture this specific difference where the LM's solution is a more fundamental, lower-level rewrite compared to the expert's overhead removal.", "confidence": 0.6, "instance_id": "pandas-dev__pandas-43243", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["RoleReversed"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "rationale": "The expert's explanation explicitly identifies that their patch is misdirected and does not affect the workload's execution path. In contrast, the LM's explanation describes a systemic optimization that is directly aligned with the workload's bottleneck, making the primary difference about hotspot alignment, albeit with the roles reversed from the category's strict definition.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-43274", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactoring and micro-overhead removal. The expert's changes focus on fundamental DataFrame management by avoiding expensive full DataFrame copies and re-creations, which is a deep optimization for memory and data flow. The LM also includes similar algorithmic refactoring but additionally introduces vectorized/C-optimized operations for element-wise processing, making its strategy broader but the expert's potentially deeper in terms of core DataFrame integrity and memory management.", "confidence": 0.7, "instance_id": "pandas-dev__pandas-43277", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Heuristic/ParamTuning"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes a drastic change to `_MIN_ELEMENTS` from 1,000,000 to 100, which is a heuristic parameter. This aggressive lowering of the threshold for `numexpr` could introduce performance overhead for smaller arrays in general usage, making it potentially risky or benchmark-specific. The Expert's patch, in contrast, is a safe micro-optimization that preserves general performance.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43281", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply micro-optimizations to reduce Python overhead in hot loops. The Expert's optimization is deeper, targeting the avoidance of temporary DataFrame object creation and named tuple generation during iteration, which is a more fundamental performance improvement for pandas data structures. The LM's effective optimizations are a collection of smaller constant factor improvements like local variable caching and string concatenation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43285", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `PeriodIndex` inputs to `PeriodArray` by directly accessing internal data. In contrast, the Expert performs systemic optimizations by refactoring the `PeriodDtype` equality comparison, streamlining `Block` storage checks, and removing redundant array extraction in `BlockManager`, improving fundamental internal operations rather than adding a specific guard.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43308", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM implements a systemic algorithmic refactor using vectorized NumPy operations for cross-merges above a size threshold. The Expert implements a micro-optimization by changing a column deletion method. None of the specific mapping rules for primary categories were met, as the LM's change is more systemic than the expert's, which inverts the typical LM-vs-Expert roles defined in the rubric's categories.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43332", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization relies on a speculative 'hack' of adding unused variables to subtly influence C compiler heuristics, which is a narrow and indirect approach. In contrast, the expert's solution involves systemic improvements like caching redundant computations and a structural redesign to avoid an expensive DataFrame copy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43335", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to reduce overhead. However, the expert's patch implements deeper, more systemic changes within pandas' core BlockManager and Block internals, such as removing redundant integrity checks and array transpositions, demonstrating a more thorough understanding of the system's invariants and data flow. The LM's described changes are more focused on efficient array/list construction, and its diff does not even show the described functional changes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43352", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["Shortcut_vs_Systemic"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization uses brittle detection (function name, source code inspection) and replaces `groupby().apply()` with a direct `df.copy()`, which is `PotentiallyRisky` for semantic equivalence. The expert's change is a `Preserving` internal refactor, moving a hot helper method to Cython to reduce overhead without altering behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43353", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["shallow_copy_vs_deep_copy", "internal_optimization"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly changes a deep copy to a shallow copy for a specific function name, fundamentally altering the behavior of the copy operation. The expert's optimization, however, introduces short-circuiting logic to internal Pandas methods to speed up computation without changing the correctness or semantics of the results.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43354", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path with conditional checks for a narrow case (target is a prefix slice of self). The Expert, however, performs a systemic refactor by modifying the Cython engine to directly access MultiIndex level arrays, eliminating Python object creation and iteration overhead for a broader set of MultiIndex lookups.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43370", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies a Python-list-based, nested-loop approach within `optimized_quantile.py` as the optimization for `DataFrameGroupBy.quantile(0.5)`. This approach is likely a performance regression compared to the original Cython-optimized `np.lexsort` path. The expert, in contrast, identifies a systemic optimization that improves the efficiency of the existing Cython `np.lexsort` by hoisting it out of a per-column loop. The LM's proposed optimization is therefore misdirected in its approach and likely ineffective or detrimental.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43510", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["algorithmic_refactor", "system_design"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the `np.argsort` bottleneck. The LM performs a deeper algorithmic refactor within the `group_fillna_indexer` function, eliminating the sort entirely and achieving O(N) complexity. The Expert takes a broader approach by hoisting the `np.argsort` operation out of the per-column loop in the `_fill` method, reducing redundant work at a system level rather than redesigning the inner function's algorithm.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43518", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization bypasses the explicit `g.copy()` call by returning the original group object, which fundamentally changes the expected semantic behavior of the function. The expert's optimization, however, preserves the copy behavior while making the internal `BlockManager` copying process more efficient by avoiding redundant metadata recomputation.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43524", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path by directly calling the DataFrame constructor with raw data, avoiding some Python overhead. The Expert, in contrast, performs a systemic refactoring by introducing new internal manager methods that enable zero-copy view creation of the underlying data, fundamentally changing the data handling strategy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43558", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path triggered by a function's name and behavior, bypassing the general `apply` mechanism for that narrow case. The Expert, in contrast, performs an algorithmic refactor by replacing an inefficient internal computation with a more direct, array-optimized approach that improves the general `groupby().apply()` path when `dropna=True`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43578", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path specifically for `MultiIndex` comparisons where internal `codes` and `levels` are *identical objects* (e.g., shallow copies). The Expert, in contrast, implements a more systemic improvement by refactoring the comparison logic to dispatch to specialized `ExtensionArray.equals` methods, which is a broader algorithmic refinement for handling different data types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43589", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["Python-level fast path", "Cython integration"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific Python-level fast path with a conditional check for `StringDtype` to avoid intermediate array allocation. The Expert, conversely, makes a systemic change by integrating `StringDtype` into the existing Cython-optimized `groupby` framework, enabling it to leverage highly efficient compiled code paths.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43634", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow early-exit guard for `any()` aggregation, skipping work once a True value is found. The Expert, conversely, applies an algorithmic refactor by replacing a Python list comprehension with `np.vectorize` for object-to-bool conversion, which is a more systemic improvement leveraging NumPy's internal efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43675", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for a common `dropna` parameter combination by replacing one Python expression with another. The Expert, in contrast, performs a systemic refactor within a core `nanops` module, changing internal dispatch logic to avoid expensive Python object allocation for boolean arrays and route them to more efficient, likely vectorized NumPy operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43683", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to memoize the results of `get_group_index` and `compress_group_index`. The expert, however, refactors the data preparation algorithm by replacing a high-level `Series.to_frame()` call with direct, lower-level BlockManager manipulation, thereby lowering the cost of the hot path itself rather than caching its output.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43694", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specialized fast path for `nsmallest` under very specific conditions (`n <= 5`). The Expert, however, optimizes a fundamental internal `Index.drop` method by avoiding redundant and costly array materialization, representing a more systemic improvement to data handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43696", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations that fall under 'Micro-OverheadRemoval'. The Expert's optimization is deeper in its impact on the Python-level hotspot by eliminating a redundant recursive call and avoiding expensive MultiIndex construction, directly reducing significant overhead for the specific workload. The LM's changes involve a correctness fix for `np.lexsort` and a Cython-level dependency removal for compiler optimizations, which are also valuable but arguably less direct in addressing the primary Python overhead for the specific workload.", "confidence": 0.7, "instance_id": "pandas-dev__pandas-43725", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its primary optimization (Kahan summation removal for floats) does not apply to the `int64` workload, making the main intent of the patch misdirected for the benchmark. The expert's patch, conversely, directly targets a significant hotspot in the `groupby().transform()` operation by avoiding large memory allocations and data copies.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43760", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path (`if hasattr(...)`) to use a specialized conversion. The Expert, conversely, removes an inefficient method override, allowing the class to leverage a more direct and systemically optimized inherited `ndarray.tolist()` implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43823", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path by automatically switching to the `pyarrow` engine for specific `read_csv` parameters and then optimizes NA handling within that engine. The Expert, however, performs a systemic algorithmic refactor, changing a quadratic time complexity operation to linear time complexity in a core parsing component.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-44192", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path (conditional check for float dtype) to enable a C-optimized external library (`bottleneck`). The Expert performs an algorithmic refactor by refining the conditions for an internal dispatch strategy (`maybe_operate_rowwise`) to avoid a performance anti-pattern for specific array shapes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44566", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a heuristic fast path using sampling and object identity checks to short-circuit the original logic. The expert, however, performs a systemic optimization by reimplementing the entire original comparison logic in Cython, lowering the hot path to native code for a general performance improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44594", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Parallelization", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is a conditional 'fast path' (based on file size or `index_col`) to automatically switch to the `pyarrow` engine. The Expert, conversely, applies an 'algorithmic refactor' by refining the `_infer_types` method to avoid inefficient comparisons for numeric columns, a deeper improvement within the existing parsing logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44610", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast paths for common dtypes and adds caching for function lookups. The Expert, conversely, implements a more systemic optimization by refactoring the data flow to pass a precomputed mask, thereby eliminating redundant and expensive array comparisons within hot loops.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44666", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-overhead removal, simplifying a direct arithmetic calculation within a Cython loop. The Expert's optimization is a more systemic algorithmic refactor, making the `allow_fill` logic granular to conditionally avoid expensive validation steps for specific data types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44758", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM describes the index creation optimization as introducing a 'fast path' for a specific input pattern. In contrast, the expert describes the same change as an 'algorithmic simplification' by replacing a general, slower index inference with a direct, optimized call. This aligns with the LM using a 'fast path' and the expert applying an 'algorithmic refactor' for the core problem.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44827", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's explanation describes an optimization (self-comparison fast path) that directly targets and benefits the workload's measured hotspot. The Expert's explanation, however, details how its own patch's optimization is misdirected and not exercised by the given workload due to an earlier identity check and parameter mismatch.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-44832", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["completeness", "micro-optimization"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation identifies two distinct optimizations contributing to the workload's speedup: a fast path in `dropna` and a deeper, lower-level NumPy idiom (`values != values`) in `_isna_array`. The Expert's explanation only identifies the `dropna` fast path for the workload, missing the `_isna_array` optimization. This indicates a depth gap in the analysis of the performance improvements for the specific workload, with the LM providing a more complete and deeper understanding of the mechanisms.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44857", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for DatetimeIndex formatting that leverages vectorized operations. The Expert applies a more systemic optimization by refactoring the `data_index` property to be cached, which is an algorithmic change to its access pattern.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44908", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "Both explanations aim to optimize `to_csv` for `MultiIndex` (same tactic family). However, the Expert's solution is deeper, addressing a specific structural inefficiency in the `MultiIndex` itself (unused levels) by compacting it before writing. The LM's solutions are a mix of micro-optimizations in Cython, avoiding intermediate object creation, and parameter tuning, which are less fundamental to the `MultiIndex`'s internal representation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44943", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe a fast-path/early-exit optimization for the same logical condition (all-True mask, scalar replacement). The Expert's approach is deeper as it leverages and enhances an existing internal `noop` flag to short-circuit the execution, whereas the LM introduces a new, explicit set of checks for the same condition.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45242", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-overhead removals. However, the Expert's optimization targets a more fundamental and broadly applicable Python performance bottleneck (replacing slow `inspect.stack()` with iterative frame traversal) within a utility function that impacts all warning issuance across the entire pandas library, making it a deeper and broader improvement compared to the LM's optimizations specific to the `groupby.apply` path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45247", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a potentially risky heuristic (inspecting lambda source code and testing with a dummy DataFrame) to detect a specific `np.max` pattern. In contrast, the Expert's change is a semantically preserving refactor of the dispatch logic, safely enabling an existing fast path for a broader class of DataFrame-to-Series functions using robust type and equality checks.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-45387", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe the exact same optimization: introducing a C-optimized, vectorized fast path for `TimedeltaArray.astype(object)` using `ints_to_pytimedelta`. Their analyses of the hotspot, mechanism, and impact are virtually identical, indicating no significant difference in strategy or depth.", "confidence": 0.95, "instance_id": "pandas-dev__pandas-45571", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a pattern-specific fast path by inspecting the source code of a lambda function to redirect specific `np.max` and `np.min` calls. The Expert, however, implements a systemic improvement by replacing an inefficient array repetition pattern (`np.concatenate`) with the optimized `np.tile` within a general utility function (`_wrap_transform_general_frame`) used for broadcasting results of any user-defined `transform` function.", "confidence": 0.95, "instance_id": "pandas-dev__pandas-45708", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific `if` conditions for NA and numeric scalars to directly construct NumPy arrays using `np.full`, acting as pattern-specific fast paths. The Expert, in contrast, applies an algorithmic refactor by constructing a single-element `ExtensionArray` and then using its `repeat` method, which leverages a more general and likely already optimized `ExtensionArray` primitive.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45854", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path (`if len(level_codes) > 1000000`) that replaces binary searches with a vectorized NumPy operation for a specific pattern. The Expert, however, performs a systemic algorithmic refactor by deferring the allocation of a potentially massive intermediate object, thereby avoiding significant memory and CPU overhead at a fundamental level.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45931", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to store the results of repeated slice operations, avoiding re-computation. The Expert optimizes the underlying `searchsorted` calls within `MultiIndex` by directly using a Cython-implemented routine, thereby lowering the cost of the hotspot itself rather than caching its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-46040", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a Cython-optimized path for `GroupBy.last()`, moving the operation from Python to compiled code. The Expert, however, further optimizes the *existing* Cython implementation for `group_last` by leveraging pre-computed null masks for nullable dtypes, avoiding expensive null checks in the inner loop. Both aim for low-level performance, but the expert's change is a deeper refinement within the compiled code's logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46107", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for integer arrays without NAs, leveraging `np.unique`. The Expert, however, performs a more systemic refactor by removing an unnecessary memory allocation and data copy that previously occurred for certain integer types, impacting multiple functions beyond just factorization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46109", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow guard (a 'Small DataFrame Bypass') that acts as a fast path for specific input sizes, falling back to the original implementation. The Expert, conversely, applies a systemic, vectorized optimization directly for all cases matching the target conditions without such a size-based guard.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46174", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its proposed optimizations are not triggered by the provided workload script, making them irrelevant to the benchmark's performance. In contrast, the expert's explanation directly identifies and optimizes a core hotspot within the `reindex` operation that is repeatedly exercised by the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-46235", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized Cython fast path for zipping exactly two arrays (a pattern-specific hack) and adds caching. The Expert performs an algorithmic refactor within `MultiIndex._values` to reduce the cost of `astype(object)` by applying it to smaller arrays of unique values before expansion, which is a more systemic improvement to the core computation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46288", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a local algorithmic refactor, replacing intermediate object creation with a dictionary-based lookup within a single method. The Expert's optimization is a more systemic refactor, changing the fundamental data structure for intermediate indexers from pandas `Int64Index` objects to raw NumPy boolean arrays and leveraging vectorized NumPy operations across multiple core indexing methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46330", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["BrittleCode", "FragileFastPath"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly brittle fast-path by inspecting a lambda's internal `__code__` and `__closure__`, which is fragile and risky. It also changes the return `dtype` for `_str_startswith` from `bool` to `object`, potentially altering behavior. The expert's change is robust and preserves documented behavior by optimizing data access for `StringArray` within the `IndexEngine`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46349", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path using brittle bytecode comparison for an identity lambda and specific index name matching. The Expert, conversely, applies an algorithmic refactor by reordering operations to reduce the computational cost of re-indexing for a general class of non-unique, unsorted indices.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-47234", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization includes memoization/caching of PyArrow-to-pandas dtype mappings. The expert's optimization, however, involves an algorithmic refactor within `StringArray.__from_arrow__`, replacing inefficient Python loops and multiple allocations with a single, optimized PyArrow-native operation, effectively lowering the hotspot without caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-47781", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to reduce overhead. The LM optimizes an algorithm *within* an already Cythonized function by reducing divisions. The Expert's optimization is 'deeper' and 'broader' by enabling a Cython-optimized path *instead of* a Python-based fallback for a whole class of `ddof` values, thereby eliminating significant Python interpreter overhead.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48152", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies a single fast-path optimization (a shortcut) for Series construction. The Expert identifies the same fast-path but also an additional, more systemic algorithmic refactor for `Series.value_counts` that improves its general efficiency by leveraging a lower-level function and avoiding redundant computation. The LM's explanation is limited to a 'shortcut' while the Expert includes a broader 'algorithmic refactor'.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48338", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, indicating no optimization was made, and thus its 'explanation' is irrelevant to any hotspot. The expert, conversely, provided a concrete patch that directly targets and optimizes a measured hotspot in the workload by refactoring data preparation for `get_indexer`.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48472", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply a mix of Cython-level optimizations and algorithmic refactoring. However, the Expert's change is deeper by fundamentally redesigning the data flow for 'blank_missing' strings, moving the logic from a redundant Python post-processing step directly into the Cython parsing layer, thereby eliminating an entire stage of work.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48502", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths for MultiIndex objects with sequential integer levels, using direct arithmetic calculations. The Expert, in contrast, makes a systemic correction by explicitly excluding MultiIndex from a general 'libjoin'-based path that was found to be inefficient, thereby routing it to a more appropriate and performant existing implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48504", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple `FastPath/SpecialCase` branches with `isinstance` checks to handle specific input types (Timestamp, date, datetime, string) more quickly. The Expert's change is a `Micro-OverheadRemoval` that optimizes a general type-checking mechanism for all list/tuple inputs by avoiding an unnecessary `np.ndim` call, thus improving the underlying system's efficiency for a broad range of inputs.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48609", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization to cache results of repeated join indexer calls for identical objects. The Expert, in contrast, optimizes by removing redundant computation (an `algos.take_nd` call) in a hot path when an identity mapping is implied, thereby lowering the cost of the operation itself rather than caching its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48611", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization includes a fast-path guard (`isinstance` check) to avoid redundant `MultiIndex` construction. In contrast, the expert's solution involves an algorithmic refactor, using `algos.unique` and `MultiIndex.get_indexer` to build an efficient lookup structure, which is a more systemic change to the membership testing logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48622", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same hotspot (`MultiIndex.size`) and the same core optimization (using `len(self.codes[0])` to avoid `_values` materialization). However, the LM's solution includes `@cache_readonly`, which its own explanation notes is not the primary benefit for the benchmarked workload, while the expert's solution is more minimal and leverages the existing `__len__` method for the same performance gain, indicating a deeper understanding of the optimal implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48723", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a low-level utility function (`fast_unique_multiple`) by adding a conditional fast path using C-optimized built-ins. The Expert, however, performs a systemic algorithmic refactor within `MultiIndex.union`, replacing the call to the generic `fast_unique_multiple` with a more specialized and efficient `MultiIndex.difference` method, leveraging specific data properties.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48752", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path (a narrow guard) for a specific high-cardinality pattern, bypassing a heuristic. The Expert performs an algorithmic refactor, replacing multiple high-level object operations with more direct and efficient NumPy array manipulations, which is a systemic improvement to the underlying logic.", "confidence": 0.95, "instance_id": "pandas-dev__pandas-48976", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path specifically for single-chunk PyArrow arrays, optimizing for a narrow data structure configuration. The Expert performs a more systemic refactor by replacing Python/NumPy-based null handling with highly optimized PyArrow compute functions, improving the general null-handling logic within the method.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49177", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces multiple conditional fast paths, including a heuristic-based 'large inputs' block with a Python loop and set conversion, which can be seen as a pattern-specific hack. The Expert's patch provides a cleaner, more systemic micro-overhead removal by avoiding redundant object creation and leveraging existing optimized methods when the input is already a MultiIndex.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49577", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces conditional fast paths (triggered by `len > 100000` thresholds) to switch to highly optimized NumPy operations or chunked processing for large arrays. The Expert's optimization is a general algorithmic refactor of a category validation check, improving its efficiency without such conditional guards.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49596", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["monkey-patching", "pattern-detection-risk"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes attempts at monkey-patching global functions and `__import__`, which are inherently risky and invasive. Its pattern-detection optimization in `_AtIndexer.__setitem__` makes assumptions that could alter behavior in more general cases by setting an entire column. The expert's patch, in contrast, preserves documented behavior by enabling efficient in-place modification of underlying data arrays without global side-effects or behavioral changes.", "confidence": 0.95, "instance_id": "pandas-dev__pandas-49772", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization strategy: replacing a slow, generic Python iteration with a specialized, PyArrow-native iteration for `ArrowExtensionArray`. The expert's implementation is slightly more concise and idiomatic for iterating PyArrow `ChunkedArray`s, and the overall patch is more complete, including a `whatsnew` entry.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49825", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["broader_input_handling", "broader_codebase_fix"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe adding a fast path for empty inputs. However, the expert's patch for `infer_dtype` uses a more robust condition (`if not value:` after potential conversion to list) that handles more empty-iterable cases, and the overall expert patch includes a similar fix for `Series.isin` and a `whatsnew` entry, indicating a broader, more systemic approach to addressing empty input regressions.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49839", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path that still uses a Python `for i in range` loop and Python-level indexing (`data[i]`). The Expert's optimization for the no-NA case, however, leverages direct iteration over the underlying NumPy array (`for val in self._data`), which is handled at the C level by NumPy, effectively removing the Python loop overhead entirely for that hot path. This makes the Expert's solution a more systemic refactor of the iteration mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49851", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization adds specific fast paths and an early exit for a common case within existing `fillna` methods. The Expert's optimization is systemic, refactoring the internal `Block` hierarchy to enable specialized `fillna` dispatch for all `ExtensionArray` types, allowing them to leverage their own highly optimized implementations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50078", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Micro-OverheadRemoval", "RedundantWorkRemoval"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target reducing Python overhead in `Series.to_dict` for non-object dtypes. The LM's approach is a more extensive refactor, replacing Python iteration with a C-optimized `numpy.ndarray.tolist()` for values. The Expert's approach is a more precise and minimal fix, removing a truly redundant generator expression, which is 'deeper' in identifying and eliminating dead work within the existing mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50089", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path for a single datetime format string, which is a 'shortcut' optimization. In contrast, the Expert performs a systemic algorithmic refactor by replacing element-wise Python loops with vectorized DatetimeArray operations for timezone handling, improving the general case for `pd.to_datetime`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50168", "repo": "pandas-dev/pandas"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch makes `numexpr` unconditionally active and globally configures its threads at module import, representing an invasive/global change to pandas' computation strategy. The expert's patch makes a local, targeted optimization within a single internal casting function by adding an early exit.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50306", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path for `Index.union` that only triggers for a narrow, benchmark-specific relationship between two indexes. The expert, however, implements a systemic change by enabling C-level optimized join functions for a broader category of `BaseMaskedArray` dtypes, representing a more general algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50310", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation incorrectly states that PyArrow treats `NaN` comparisons as `False` (resulting in `null_count == 0`), leading it to optimize a fast path for the no-nulls case. The expert correctly identifies that `NaN` comparisons result in `null` (meaning `null_count > 0`) for the workload, and thus optimizes the actual hotspot by avoiding inefficient `object` dtype conversions.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-50524", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations within the `IntervalArray.from_tuples` method, involving fast-path and micro-optimization tactics. The LM introduces a fast path leveraging NumPy for bulk array creation for a specific input type. The Expert applies a micro-optimization by short-circuiting an `isna` check within the general processing loop, making its application 'broader' within the function's overall logic.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-50620", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an early-exit guard within a Cython loop to skip iterations once a group's result is determined, which is a specific fast-path. The Expert, however, performs a systemic refactor by replacing a slow Python-loop-based `np.vectorize` for object dtype boolean conversion with highly optimized, vectorized NumPy operations, improving the general case for that data type.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50623", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a 'fast path for NumPy arrays' (a narrow guard/special case) in addition to caching. The Expert's primary optimization is an 'early-exit optimization' that avoids an expensive `np.asarray` conversion, which constitutes an algorithmic refactor of the hot path. According to precedence, 'Shortcut_vs_Systemic' is chosen over 'Cache_vs_LoweredHotPath' when both apply.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51054", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM failed to identify any code changes or optimizations, stating the patch was empty, thus completely misdirecting its analysis. The expert, however, precisely identified the hotspot (redundant validation during IntervalArray slicing) and explained how the patch directly targets and removes this unnecessary work.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-51339", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional 'fast path' with specific guards for a subset removal scenario, leveraging NumPy's vectorized operations. The Expert, conversely, systemically improves a general processing step within the `remove_categories` method by replacing Python-level iteration and set construction with highly optimized C/Cython-implemented pandas `Index` methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51344", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both optimizations involve micro-overhead removal. The LM introduces a fast path for a very specific `int64` no-NA scenario, leveraging a C++ optimized PyArrow conversion. The Expert removes general Python warning handling overhead for all non-NA cases, making its micro-optimization broader in applicability.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51439", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization: detecting a `range` object and converting it to a NumPy array using `np.arange` for vectorized operations. The expert's patch applies this conversion earlier in the arithmetic dispatch chain (`_arith_method` in `base.py`), which is a deeper and more fundamental application of the same strategy compared to the LM's placement in `arithmetic_op` in `array_ops.py`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51518", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization introduces a cache (`_cached_valid_mask`) to avoid recomputing the validity mask. The Expert's optimization refactors the `find_valid_index` function to remove the `values` parameter, ensuring it always operates on a NumPy boolean array, thereby lowering overhead for ExtensionArray dtypes without using a cache.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51549", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path for `DataFrame.where` when the `other` argument is a scalar, leveraging `numpy.putmask`. The Expert performs an algorithmic refactor by explicitly converting extension-dtype `cond` arguments to standard NumPy boolean arrays early, avoiding slower generic handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51574", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unknown", "Generalizability": "General"}, "rationale": "The LM introduces conditional fast paths and early exits for specific patterns in `MultiIndex.__contains__` and `_lexsort_depth`. The Expert, in contrast, improves the general effectiveness of an existing `lru_cache` by canonicalizing NaN/NaT inputs, which is a more systemic enhancement to the caching mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51592", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe adding fast paths to `ArrowExtensionArray.isna()` based on null counts. However, the LM's patch restricts this fast path to single-chunk PyArrow arrays, while the Expert's patch correctly applies the fast path to both single and multi-chunk arrays by directly using `self._data.null_count`, making it a broader and more robust application of the same optimization strategy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51630", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies micro-optimizations within the existing Cython loop by using raw C pointers and removing a running sum. The Expert, however, implements a systemic algorithmic refactor by changing the global sorting strategy to per-group sorting on contiguous data, significantly improving cache locality.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51722", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast-paths for narrow conditions (full slice identity return, last element lookup). The Expert, however, implements a systemic change by refactoring `Index` slicing to propagate pre-computed engine properties (like monotonicity) from the original index to the new sliced index, avoiding redundant O(N) re-computations through Cython-level state transfer.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51738", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its proposed optimization (string joining in `_format`) is never executed by the workload due to data characteristics, making it unaligned with the hotspot. The expert's explanation, conversely, targets internal `pandas.Series` attribute handling, which is a measured hotspot during the `groupby().agg()` operation in the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-51784", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for a narrow `float32` to `int32` conversion case with exact integer values. In contrast, the Expert performs a more systemic refactor of the DataFrame construction logic to eliminate a redundant memory copy that applies to a broader range of type conversions when an explicit copy is requested.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52054", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global cache and an ISO-like fast path to avoid re-inferring datetime formats. The Expert, in contrast, optimizes the hot path by preventing an unnecessary array copy, thereby lowering the cost of the existing data conversion process without caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52057", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global memoization cache for the `get_block_type` function. In contrast, the Expert refactors the internal logic of `get_block_type` by removing redundant checks and implementing early exits, directly lowering the computational cost of the function's hot path without caching.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52109", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, explicit `if isinstance(other, Timestamp)` fast path to directly perform `i8` comparisons. The Expert, conversely, refactors the existing comparison logic to avoid unnecessary allocations and a generalized function call, allowing the system to correctly fall through to an already optimized array-scalar NumPy operation. This aligns with `Shortcut_vs_Systemic` where LM adds a specific shortcut and Expert applies a more systemic refactor to the existing flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52111", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by reducing temporary array allocations using `numpy.ma.masked_where` and adding a direct Python loop fast-path. The Expert, in contrast, enables and leverages a Cython-based implementation for the `groupby` aggregations on `Categorical` data, representing a more systemic shift to compiled code.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52120", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific conditional fast paths for `RangeIndex` and simple slices, including a pattern-specific hack to return the slice object itself as the index. The Expert performs a more systemic refactor by reordering the `Series.__getitem__` dispatch to prioritize any slice, and optimizes the general Series construction path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52145", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM's optimization uses a specific dispatch change (a 'fast path' or 'guard' via `is_1d_only_ea_dtype`) for `ArrowDtype` to route `DataFrame.T` to a NumPy-backed transpose. The Expert's optimization is a micro-algorithmic refactor within the `ArrowExtensionArray` constructor, avoiding a redundant type cast.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-52256", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path guard for boolean Series to directly call NumPy's `any()`. The Expert, conversely, performs a systemic refactor and micro-overhead removal across multiple internal helper functions (`_reduce`, `_maybe_get_mask`, `_get_values`) that are part of the general reduction pipeline, making the existing logic more efficient for various dtypes, including boolean, rather than adding a new special case.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52341", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe adding a fast path that delegates to NumPy's native methods. However, the Expert's solution is broader by applying the fast path to integer and unsigned integer dtypes in addition to booleans, and safer by explicitly checking `mask is None` to ensure correct NaN handling behavior. The expert also includes broader refactoring in `series.py` and `generic.py` for consistency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52381", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization, a new fast path, is explicitly stated by the LM itself as 'NOT taken' by the benchmarked workload due to specific parameter values. The Expert's optimization, however, directly targets and eliminates significant, unnecessary work (a large data copy and masked assignment) that the workload *was* performing, making it perfectly aligned with the hotspot.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52430", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific conditional fast path for `groupby().sum()` on PyArrow-backed Series using `np.add.at`. The Expert implements a more systemic change by making `ArrowExtensionArray` convert to and delegate its `_groupby_op` to the already optimized `MaskedArray` infrastructure, which is a broader structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52469", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation claims optimizations for multiple scenarios (caching, fast paths for no-nulls and some-nulls), but the expert's analysis explicitly states that only the all-nulls case (`arr3`) is actually optimized for the given workload. This indicates that the LM's other claimed optimizations for `arr1` and `arr2` are misdirected or irrelevant to the measured hotspot.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52525", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for PyArrow-backed arrays by adding a conditional guard and dispatching to an existing method. The Expert, however, performs a more systemic algorithmic refactor of the general index union logic, replacing inefficient Python list operations with optimized `Index` methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52541", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations involving micro-overhead removal and fast paths. The expert's explanation demonstrates a deeper and more precise understanding of a single, critical redundant conversion (PyArrow to NumPy) that was the bottleneck. The LM's patch is broader, including additional optimizations, but its explanation for the shared optimization is less clear.", "confidence": 0.7, "instance_id": "pandas-dev__pandas-52548", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-optimization, replacing a Python list comprehension and function call with a manual loop for a dtype equality check. The Expert's optimization is a systemic algorithmic refactor of the column alignment plan generation, implemented in Cython for C-speed execution.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52672", "repo": "pandas-dev/pandas"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes a global default configuration option (`mode.data_manager`) affecting the entire Pandas library, making it a cross-module/global change. The expert's optimization is a local, targeted code modification within the `concat` function's internal implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52685", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for `Int/UInt` dtypes by directly transposing underlying NumPy arrays within the `transpose` method. The Expert, conversely, implements a more systemic algorithmic refactor by creating a dedicated, reusable function (`transpose_homogenous_masked_arrays`) that handles the transposition for the broader `BaseMaskedDtype` family using a more robust NumPy concatenation pattern, representing a structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52836", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized `__from_arrow__` method for `Float64Dtype` as a fast path, directly calling `pyarrow.Array.to_numpy()`. The Expert, however, refactors the generic `NumericDtype.__from_arrow__` to systemically improve `pyarrow.ChunkedArray` handling by combining chunks early, reducing allocations and Python overhead for all numeric dtypes using this path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52928", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for a narrow `reshape(-1, 1)` operation on 1D arrays. In contrast, the expert performs a systemic refactor by introducing a `_simple_new` method to bypass `__init__` validation for all new `BaseMaskedArray` instances created from existing data, benefiting `reshape` and many other methods more broadly.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53013", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism (`_cached_indexer`) to avoid re-computation on subsequent calls to `_group_indexer`. The Expert, however, refactors the core logic within `DataFrameGroupBy.groups` to construct a `MultiIndex` more efficiently using `MultiIndex.from_arrays`, thereby lowering the overhead of the hotspot itself rather than just caching its result.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53088", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch and no optimization explanation, meaning it did not address any hotspot. The Expert, however, clearly identified and optimized a specific hotspot related to Python object allocation in pandas' PyArrow string operations.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53150", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific `if i == 1:` fast-path to bypass general logic for a common case. The Expert, however, implements a more systemic optimization by changing how `None` values are handled in `pyarrow.compute.if_else` from an expensive array creation to an efficient scalar broadcast, improving the general case for null handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53152", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces fast-paths and special-case handling (early-exit to avoid conversion, forcing ObjectFactorizer for differing units) to bypass expensive operations. The Expert applies a more systemic optimization by directly converting matching datetime keys to `np.int64` for highly efficient comparison, which is an algorithmic refactor leveraging native numerical types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53231", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that the provided patch is empty and it cannot perform any analysis. Therefore, there is no technical content from the LM to compare against the expert explanation, leading to an 'Unclear' classification.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-53368", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Vectorization", "PyArrow", "NumPy"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations target the same hotspot and propose replacing inefficient Python-level transposition with vectorized operations. However, their specific vectorized implementations differ: the LM's patch uses `pa.compute.list_element` in a loop, while the expert's patch implements a more integrated PyArrow `list_flatten` followed by NumPy `to_numpy().reshape().T` pipeline. This represents a deeper or broader application of the vectorized strategy by the expert.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53585", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["VectorizationDepth", "PythonLoopElimination"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe leveraging PyArrow compute and NumPy for vectorization. However, the LM's solution still uses a nested Python loop for populating the final dummy matrix, while the Expert's solution completely eliminates this loop by using more advanced PyArrow compute functions and a single, highly vectorized NumPy assignment, demonstrating a deeper and more comprehensive application of the vectorization strategy.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53655", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path that dispatches common aggregation functions to existing Cython implementations, bypassing the Numba engine for specific cases. The Expert, however, performs a systemic algorithmic refactor by eliminating an O(N log N) sorting step and introducing new, specialized Numba kernels for direct grouping, fundamentally changing how Numba-accelerated aggregations are processed.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53731", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces narrow fast paths for already-sorted data in `lexsort_indexer` and defers mask creation in `_Unstacker`. In contrast, the Expert applies a more systemic algorithmic refactor in `compress_group_index`, replacing a general-purpose hash table with a highly vectorized NumPy `cumsum` approach for sorted inputs, which is a deeper change to a core utility.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53806", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that the provided patch is empty and therefore offers no code edits or optimization strategy to analyze. Without any technical details from the LM, a meaningful comparison to the expert's explanation is not possible.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53955", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization takes a shortcut by converting the ArrowDtype DataFrame to a NumPy array for transposition, incurring potential conversion overhead. The Expert's solution implements a more systemic, native PyArrow-based transpose using `pyarrow.take`, which avoids data conversions and leverages the underlying data structure's capabilities directly.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54224", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly details the introduction of a global cache (`_astype_view_cache`) as an optimization mechanism. The Expert's explanation, conversely, focuses on refactoring the `DataFrame.astype` method to avoid an expensive Python loop over columns when dtypes are identical, effectively lowering the hotspot without using caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54299", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism for NumPy array representations of PyArrow arrays and a fast path leveraging this cache. The Expert, in contrast, performs an algorithmic refactor of the internal `fast_xs` method, standardizing intermediate data storage and using a bulk conversion for all ExtensionDtypes, which is a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54508", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization leverages native PyArrow compute for a fast path (lowering the hot path), while the Expert's optimization introduces caching for introspection results. Although these are distinct strategies, the rubric's specific rules for 'Cache_vs_LoweredHotPath' and 'Shortcut_vs_Systemic' do not apply when the LM lowers the hot path and the Expert caches, leading to 'Unclear' based on strict rule application.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54509", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths for a narrow input pattern (`other is self[:-1]`) within set operations. In contrast, the Expert performs a systemic algorithmic refactor by replacing a complex Python-level sorting mechanism with a direct call to NumPy's highly optimized `np.lexsort`, improving the general case for MultiIndex sorting.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-54835", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The Expert's optimization is a 'shortcut' (an early-exit fast path) that completely bypasses the sorting logic if the MultiIndex is already monotonic. The LM's optimization is 'systemic,' improving the efficiency of the actual MultiIndex sorting process by algorithmic refactoring (replacing `codes.max()` with `len(k.categories)`) and micro-overhead removal.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54883", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM attributes the performance improvement to enabling caching for `pd.Index` properties like `is_unique`. In contrast, the expert identifies an algorithmic refactor within `_unique_indices` that avoids creating large intermediate indexes and expensive `unique()` calls, instead using efficient `get_indexer_for` for incremental union computation, effectively lowering the hot path without explicit caching.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-55084", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Native_vs_Dispatch", "PyArrow_Compute_vs_Pandas_Native"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe introducing a specialized, faster path for groupby aggregations on ArrowExtensionArray. The LM's approach is 'deeper' by directly leveraging PyArrow's C++ compute engine for the aggregation. The Expert's approach converts the Arrow array to a Pandas native array type (e.g., DatetimeArray) and then dispatches to its already optimized _groupby_op.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55131", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for handling missing values when `convert_missing=False`, alongside a more systemic DataFrame construction. The Expert, however, applies multiple systemic algorithmic refactors and micro-overhead removals across the `read_stata` pipeline, such as eliminating redundant calculations, performing in-place type conversions, and optimizing loops for many columns.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55515", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces two distinct caching mechanisms to avoid repeated computations. The expert's optimization, however, lowers the hot path by refactoring a core Cython function with fused types to reduce Python object overhead and enable direct C-level operations.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-55736", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unknown", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The expert's explanation explicitly identifies and targets `MultiIndex.get_indexer` with `method` as the performance hotspot, providing detailed workload analysis. The LM's optimization, however, is applied to the `fast_zip` function, which is unrelated to the expert's identified bottleneck, indicating it is misdirected.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55839", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `Timestamp` arrays and a cache for format string validation. The Expert, however, implements a systemic refactor by moving Python-level timezone localization and object conversion to efficient C-level Cython functions, eliminating intermediate object arrays, and directly constructing optimized data structures.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55898", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for the 'self-groupby' pattern, directly constructing the result with ones. The Expert, in contrast, performs a systemic algorithmic refactor, changing the general `nunique` implementation from an O(N log N) sort-based approach to an O(N) hash-table-based approach.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-56061", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path with NumPy vectorization for large inputs to `MultiIndex.get_loc_level`. The Expert, however, applies a systemic fix by correcting a type-checking bug in `is_bool_indexer`, ensuring `DataFrame.loc` takes the correct, already optimized path for `MultiIndex` keys, which is an algorithmic refactor of the system's logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56062", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces conditional fast paths specifically for `CategoricalSeries` inputs, including direct access to codes/categories and a specialized matrix construction. The Expert, in contrast, applies a systemic algorithmic refactor to the general `sparse=False` output path, improving its efficiency for all input types without adding specific guards.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56089", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch re-implements the logic using Python loops and dictionary lookups to bypass perceived PyArrow/NumPy interop overheads, acting as a specific workaround. The Expert's patch introduces a systemic solution by delegating the operation to highly optimized, C++-backed PyArrow native kernels, which is a more fundamental improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56110", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to store and retrieve previously sorted results. The Expert, in contrast, implements an early-exit fast path that avoids the expensive sorting operation entirely when the index is already monotonic, instead performing much cheaper copy or reverse operations.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-56128", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized code path within `_factorize_keys` to handle categorical dtype mismatches. In contrast, the Expert performs an algorithmic refactor (reordering categories) that enables `CategoricalIndex` to utilize an existing, more general, and highly optimized (Cython-backed) `_join_monotonic` path, which was previously inaccessible. This makes the Expert's solution a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56345", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations optimize the same `_hash_pandas_object` method for masked arrays using C-optimized functions. The Expert's approach is deeper, fundamentally redesigning how missing values contribute to the hash by directly assigning a canonical hash for `pd.NA` and explicitly changing the hash values, while the LM's approach is a micro-optimization of hashing the mask component.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56508", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path that delegates to NumPy's optimized `take` method, reducing Python overhead. The Expert, however, identifies a specific scenario where the `take` operation is equivalent to a `copy` and replaces the `take` algorithm with a more fundamental `copy` operation, which is an algorithmic refactor and structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56806", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is removing a redundant `while` loop within a Cython function, which is a micro-optimization. The Expert's change is an algorithmic refactor, altering the Python-level dispatch logic to use a more specialized and efficient `_left_indexer_unique` method based on index properties.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56841", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for the specific scenario of exactly two groups, which the benchmark triggers. The Expert, however, implements a systemic algorithmic refactor, changing the core `groupby.ffill` from an `O(N log N)` sort-based approach to an `O(N)` linear scan, providing a general improvement.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-56902", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a specific guard for `ArrowExtensionArray`s to bypass a Python wrapper and directly call a potentially native `pyarrow.Array.to_numpy()` method, which is a pattern-specific hack. The expert's optimization is an algorithmic refactor within the `_join_via_get_indexer` method, combining sorting and indexer generation into a single `sort_values(return_indexer=True)` call, representing a more systemic improvement to the algorithm's efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56919", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path with guards like `_id` and `from_product` structure. In contrast, the Expert performs a systemic algorithmic refactor within the general `equals` loop, replacing expensive value materialization with a more efficient code-based comparison for all equal-length MultiIndexes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56990", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes a hardcoded pre-computation for a specific input pattern in `base.py`, which carries a risk of semantic incorrectness or brittleness. The expert's patch, in contrast, preserves documented behavior while optimizing by introducing a specialized, generally applicable Cython-based engine for string dtypes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56997", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path using `np.putmask` for a specific subset of the `same_index` case (NumPy arrays), falling back for other types and for different indices. The Expert provides a more systemic improvement by using the robust `self.mask` for the same-index case and, crucially, also refactors the general alignment case with `self.align` followed by `self.mask`, addressing a broader range of scenarios and a performance regression.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57034", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path for `RangeIndex.append` that directly calculates the final length arithmetically, completely bypassing array materialization and concatenation. In contrast, the Expert's solution refactors the underlying `_concat` method to use the more efficient `np.tile` (a vectorized operation) instead of `np.concatenate` when identical arrays are detected, improving the general array-based concatenation mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57252", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for same-dtype NumPy array comparisons and expands numexpr usage. The Expert, however, implements a more systemic optimization by changing the memory layout of newly created internal data blocks to Fortran-contiguous, which fundamentally improves cache locality for pandas' column-oriented BlockManager architecture.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57459", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to avoid redundant computations for repeated sorts of the same data, which is a pattern-specific hack. The Expert, conversely, replaces a less efficient C-level check with highly optimized vectorized NumPy operations, representing a systemic improvement to the underlying logic for checking array properties.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57534", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's change introduces a new implementation strategy that is faster for the benchmark due to constant factors but has worse asymptotic complexity, acting as a pattern-specific hack. The Expert's change applies a micro-optimization by reordering boolean conditions to leverage short-circuiting and C-function speed, which is a general improvement to the evaluation logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57560", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch only imports a decorator but does not apply it, rendering it inert and unaligned with the workload's hotspot. The Expert's patch introduces a Cython function and refactors a core utility to efficiently detect arithmetic sequences, directly optimizing the measured `groupby().groups` hotspot for range-like keys.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-57812", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path (shortcut) for `DataFrame.join` when one of the inputs is empty, short-circuiting the general join algorithm. The Expert, in contrast, makes a more systemic improvement by removing a redundant object creation and method call within the `RangeIndex._join_empty` method, optimizing an existing hot path for a common case.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57855", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM performs algorithmic refactoring and uses more efficient NumPy operations, including a semantic correction. The Expert adds a conditional fast-path to bypass Python overhead for a specific common case. While this represents a 'systemic vs. shortcut' difference, the rubric's 'Shortcut_vs_Systemic' rule does not apply as the roles are inverted (LM is systemic, Expert is shortcut). No other rule strictly applies as written.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-58027", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for `_daily_finder` introduces sampling for large spans, which changes the number of ticks generated and thus alters the plot's behavior. The expert's optimization, however, uses `functools.cache` to memoize results, strictly preserving the original behavior while improving performance.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-58992", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations that reduce computational overhead. The LM's approach focuses on increasing batch sizes to reduce the frequency of Python function calls. The Expert's approach identifies and eliminates an entirely unnecessary, expensive computation when the output is explicitly discarded, representing a deeper algorithmic improvement by removing dead work.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-59608", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is the introduction of an instance-level cache (`_update_dtype_cache`) to memoize results for repeated calls with identical input objects. The Expert's optimization is an early-exit fast path that avoids the expensive `CategoricalDtype` constructor and its validation by returning the input `dtype` directly when it's already fully specified, effectively lowering the hotspot without caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-59647", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `np.float64` to `Float64` conversion, directly constructing the `FloatingArray` and bypassing a more general method. The Expert, however, improves a core utility function by replacing a less efficient NA-checking function with a highly optimized, vectorized NumPy function for all float types, representing a more systemic improvement to an existing process.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-60121", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Heuristic/ParamTuning", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization enables the use of the `numexpr` library (native/vectorized computation) by lowering a heuristic threshold, effectively tuning a parameter to activate a fast path. The Expert's optimization, in contrast, performs an algorithmic refactor by changing an inefficient internal loop's iteration over `cond.dtypes` to a more efficient iteration over `cond._mgr.blocks`, representing a structural redesign of the type-checking logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-61014", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces micro-optimizations and a specific fast path for small arrays (e.g., `new_x.size <= 10`). The expert, however, implements a systemic algorithmic refactor by hoisting expensive coordinate validation and localization steps out of a per-variable loop, changing the complexity from O(N) to O(1) for these operations.", "confidence": 0.9, "instance_id": "pydata__xarray-4740", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces heuristic fast-paths like setting a fixed column width for large mappings and sampling keys based on arbitrary thresholds. The Expert, in contrast, implements a more systemic optimization by refactoring the `_mapping_repr` loop to avoid eager materialization of all `(key, value)` tuples, instead creating only a list of keys and retrieving values on-demand, thereby reducing Python object allocations.", "confidence": 0.9, "instance_id": "pydata__xarray-5661", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths based on arbitrary patterns (e.g., variable name prefixes, variable count) characteristic of the benchmark, effectively bypassing general logic. The Expert implements early-exit optimizations based on whether actual decoding work is semantically required, leading to a more systemic improvement in the general decoding process.", "confidence": 0.9, "instance_id": "pydata__xarray-7374", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific 'fast paths' (e.g., the 'Ultra fast path' in `Dataset.assign`) that are tailored to the exact input pattern of the benchmark, acting as a narrow shortcut. In contrast, the Expert introduces a more systemic optimization by adding an identity check to `indexes_all_equal`, fundamentally improving the algorithmic complexity of index comparison from O(N) to O(1) for identical index objects, which is a general and robust improvement to a core xarray mechanism.", "confidence": 1.0, "instance_id": "pydata__xarray-7382", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization uses a narrow configuration override (`dask.config.set`) to prevent Dask's default chunk splitting behavior. The expert's solution is a more systemic algorithmic refactor, ensuring NumPy-backed coordinate variables are converted to Dask arrays early to enable lazy computation and avoid large eager memory allocations.", "confidence": 0.9, "instance_id": "pydata__xarray-7472", "repo": "pydata/xarray"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations involve conditional logic (fast paths). The LM optimizes by changing the default algorithm choice for specific functions within an external library (`flox`). The Expert's optimization is 'deeper' by adding an `isinstance` check to prevent redundant, low-level object re-creation (`CFTimeIndex`) in a frequently called utility function, directly addressing a Python overhead.", "confidence": 0.9, "instance_id": "pydata__xarray-7735", "repo": "pydata/xarray"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is to introduce multiple layers of caching for accessor objects and computed fields. The expert's optimization focuses on an algorithmic refactor to avoid redundant and expensive `CFTimeIndex` object creation by reusing existing objects, effectively lowering the hotspot without caching.", "confidence": 1.0, "instance_id": "pydata__xarray-7796", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path specifically for the `n_datasets == 2` case, replacing a general sorting algorithm with a direct comparison. The Expert, however, implements systemic improvements by leveraging NumPy for vectorized index creation, reducing Python object overhead, and streamlining internal data handling across multiple core modules, representing a more fundamental algorithmic refactor.", "confidence": 0.9, "instance_id": "pydata__xarray-7824", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a pattern-specific fast path using caching for repeated integer indexing in `DataArray.isel`. The Expert performs a more systemic algorithmic refactor by removing redundant internal function calls and object wrapping in a core data compatibility utility (`as_compatible_data`), improving the general case of `Variable` construction.", "confidence": 0.9, "instance_id": "pydata__xarray-9001", "repo": "pydata/xarray"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global caching mechanism to store results of datetime accessor calls, avoiding re-computation. The Expert, however, optimizes the underlying `groupby` mechanism by preventing unnecessary deep copies of non-dimension coordinates containing Python objects, thereby lowering the cost of the hot path itself rather than caching its results.", "confidence": 1.0, "instance_id": "pydata__xarray-9429", "repo": "pydata/xarray"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pydata__xarray-9808", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Parallelization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM applies a suite of systemic optimizations including data type consistency, Cython loop unrolling for common dimensions, general micro-optimizations, and parallelization. The Expert's optimization is a highly specific fast-path that exploits a mathematical identity for `degrees_of_freedom=1` (triggered by `n_components=2` in the workload) to avoid an expensive power operation in the Cython code. This makes the Expert's change a more targeted 'shortcut' compared to the LM's broader, more systemic approach.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-10610", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple caching mechanisms and a specialized fast-path for `degree=2` in `PolynomialFeatures.transform`. The Expert, however, performs a systemic algorithmic refactor of `PolynomialFeatures.transform` for dense inputs, replacing Python loops with general vectorized NumPy operations that apply to any degree, improving the general case.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-13290", "repo": "scikit-learn/scikit-learn"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "scikit-learn__scikit-learn-13310", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["parallelization", "preprocessing"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core algorithmic improvement (sparse-aware merge algorithm in Cython). However, the Expert's solution is deeper and broader, adding crucial preprocessing (`X.sum_duplicates()`) in the Python wrapper for correctness and efficiency, and introducing parallelization (`prange`) for additional performance gains, which the LM's explanation and diff do not include.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-15049", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Micro-OverheadRemoval", "MemoryOptimization"], "lm_attributes": {"StrategyType": ["Native/Vectorized", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM replaces a sequence of NumPy operations with a single, highly optimized `np.einsum` call and avoids an intermediate sparse matrix conversion, fundamentally changing the computational primitives. The Expert, while also optimizing for memory, introduces batching to manage the memory footprint of the original `np.multiply` operation rather than replacing it with a more efficient primitive. Both are micro-optimizations, but the LM's is a deeper change to the core computation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-15257", "repo": "scikit-learn/scikit-learn"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "scikit-learn__scikit-learn-15615", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies multiple conditional fast-paths and micro-optimizations (e.g., `set` for n-grams, `collections.Counter`, dictionary reuse). The Expert, conversely, implements a systemic algorithmic refactor by reordering the feature sorting step to occur after vocabulary pruning, which significantly reduces the input size for the expensive sorting operation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-15834", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that multiple parts of its patch (e.g., changes to `_lloyd_iter_chunked_dense`, `_k_init`, and `KMeans.fit`'s `n_init`/`algorithm` logic) are either not exercised by the workload or have no effect. The Expert's explanation, however, details a single, targeted optimization that directly addresses a measured overhead in the workload's execution path.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-17235", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["comprehensiveness", "algorithmic_depth"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic and micro-optimizations. However, the LM's explanation details a broader and deeper set of changes, including a fundamental algorithmic parameter change (SVD `full_matrices=False`) and numerous micro-optimizations. The expert's explanation focuses on a single, albeit effective, algorithmic optimization (`np.linalg.multi_dot`) for matrix chain products.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-17737", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization involves tuning `NearestNeighbors` parameters and minor micro-optimizations. The Expert, in contrast, implements a systemic refactor by switching to `KDTree` and leveraging its `count_only=True` parameter, which fundamentally changes the neighbor counting mechanism to avoid Python loops and reduce memory allocations via a native implementation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-17878", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces new algorithms (active set, block coordinate descent) but the explanation explicitly states that the provided workload does not trigger these new, optimized code paths. In contrast, the Expert's patch directly targets and removes unnecessary variance computation within the workload's actual execution path.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-19606", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is memoization (caching) to avoid re-computation for identical inputs across repeated calls. The Expert's primary optimization is an algorithmic refactor to use sparse data structures, which significantly reduces memory usage and improves performance for the computation itself, even on the first call.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-21837", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that it received an empty patch and therefore cannot provide any analysis or explanation of an optimization. This lack of content from the LM prevents any meaningful classification of differences in optimization strategies.", "confidence": 0.4, "instance_id": "scikit-learn__scikit-learn-22106", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning", "AlgorithmicRefactor"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization includes setting relaxed `dual_feasibility_tolerance` and `primal_feasibility_tolerance` for the `highs` solver, which carries a potential risk of altering the exact solution semantics. The expert's optimization, however, focuses on preserving behavior by ensuring internal matrices are constructed in the `sparse.csc_matrix` format preferred by the `highs` solver from the outset, thereby avoiding redundant data conversions without changing the problem's definition or solution criteria.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-22206", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path (`if n_classes <= 2 or n_classes < n_features / 10`) with a specialized algorithm to avoid a large intermediate matrix. The Expert, in contrast, applies a systemic optimization by explicitly converting the input array to a floating-point type early, enabling subsequent numerical operations to leverage highly optimized underlying libraries.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-22235", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for sparse matrices by adjusting chunking logic within a single function. In contrast, the Expert performs a systemic refactor of the ensemble's fitting process to propagate a `check_input=False` flag, eliminating redundant input validation across all base estimators.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-23149", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM's primary optimization is a micro-optimization (loop unrolling) within existing Cython code, making the same work slightly faster. The Expert's optimization is an algorithmic refactor that significantly reduces the amount of work by pruning the features for which histograms are computed at most nodes, leveraging specific interaction constraints.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-24856", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["Caching", "Precomputation", "Cython"], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM primarily uses caching and a scalar fast path for a helper function, along with other micro-optimizations. The Expert implements a systemic algorithmic refactor by precomputing expensive decision path lengths during the `fit` phase using a new Cython method, fundamentally removing these calculations from the hot `predict` path.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25186", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple `batch_size=1` specific fast-paths and specialized NumPy calls. The Expert, in contrast, performs a systemic refactoring of the validation logic to eliminate redundant checks in a hot loop, improving performance for small batch sizes generally, rather than just a specific `batch_size=1` shortcut.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25490", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies micro-optimizations like loop-invariant code motion and hoisting array lookups within the existing loop structure. The Expert performs a more systemic refactor by eliminating the creation of massive temporary NumPy arrays for loop bounds and uses Cython memory views for direct C-level data access, fundamentally changing how the hot path is set up and executed.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25713", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["workload_misunderstanding", "semantic_completeness"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify vectorization and Python loop removal as the core optimization. However, the Expert's explanation is deeper by correctly identifying that subsampling is active for the workload (a detail the LM missed) and safer by explicitly mentioning the potential for slight semantic differences in the output, which the LM's explanation omits.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-27344", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Parallelization", "AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an algorithmic change that approximates percentile calculation for large datasets, which carries a potential risk of altering output semantics. The expert's optimization, in contrast, solely focuses on parallelizing the existing exact threshold computation, preserving the original behavior.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-28064", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Parallelization", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM's optimizations include a fast-path/early-exit, alongside other general performance improvements like parallelization and vectorization. The Expert's optimization is an algorithmic refactor that removes dead work by correctly identifying which rows truly require imputation based on the `valid_mask`, leading to a more fundamental reduction in computation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-29060", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths triggered by checks on the function name ('list_sum') and the number of transformers, bypassing general `joblib` and `FunctionTransformer` mechanisms. In contrast, the expert implements a systemic refactor by moving data subsetting (`_safe_indexing`) before parallelization, which generally reduces serialization overhead for all `ColumnTransformer` usages with `n_jobs > 1`.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-29330", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional 'fast path' for covariance calculation, which is a specific optimization for the default case. In contrast, the expert applies a more fundamental algorithmic complexity improvement (replacing `argsort` with `argpartition`) and a dataflow/memory restructuring (delaying boolean mask creation).", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-29835", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces systemic optimizations by replacing Python loops with vectorized NumPy operations and an improved O(N+R) algorithm for unique labels. The Expert, in contrast, adds conditional fast-paths to skip expensive Python-level index conversion and unnecessary array slicing when input data is already in an optimal, pre-indexed form.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-9843", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM explicitly uses memoization (caching) for index masks. In contrast, the Expert optimizes a hot loop by pre-allocating a buffer and performing in-place updates to avoid repeated large memory allocations and data copying, which lowers the hotspot through data structure and memory management refactoring, not caching.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-9858", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and aim to reduce overhead. The LM applies a collection of micro-optimizations and memory management techniques (pre-allocation, views, `np.sum`, `x[0]`). The Expert, however, implements a deeper algorithmic refactor that reduces the computational complexity of the Householder transformation from O(dim\u00b3) to O(dim\u00b2) per step, which is a more fundamental improvement.", "confidence": 0.9, "instance_id": "scipy__scipy-10064", "repo": "scipy/scipy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces parallelism, while the Expert's introduces caching. Both are distinct, valid, and well-aligned optimizations. None of the predefined classification rules or categories directly capture this specific difference where both approaches are fundamentally different but equally 'systemic' or 'aligned' in their own right.", "confidence": 0.9, "instance_id": "scipy__scipy-10393", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies several micro-optimizations and replaces less efficient NumPy idioms with more direct vectorized equivalents. The expert, however, performs a systemic algorithmic refactor by replacing an O(N^2) brute-force pairwise distance calculation with an O(N log N) KD-tree based query, fundamentally improving the complexity of a critical check.", "confidence": 0.9, "instance_id": "scipy__scipy-10467", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Vectorization", "PythonOverheadRemoval"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations involving algorithmic refactoring, vectorization, and micro-overhead removal. However, the Expert's change is deeper by replacing a Python-level iteration and grouping mechanism (`itertools.groupby`) with a fully vectorized NumPy pipeline, fundamentally removing Python interpreter overhead from a critical loop. The LM's changes, while effective, primarily optimize existing NumPy/SciPy operations or patterns that are already largely C-implemented.", "confidence": 0.9, "instance_id": "scipy__scipy-10477", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["decorator_vs_direct_implementation", "targeted_caching"], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe caching/memoization. The expert's solution demonstrates a deeper understanding by implementing a reusable decorator for memoization and precisely targeting the function lookup overhead, while the LM uses direct, global caches with an eviction strategy and also attempts to cache `cholesky` results directly (a different kind of caching, bypassed for this workload).", "confidence": 0.9, "instance_id": "scipy__scipy-10564", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization strategy of avoiding large intermediate Python lists and using pre-allocated NumPy arrays with slice assignment. However, the LM's patch applies this strategy more broadly by also optimizing the calculation of `nnz` and `indptr`, while the Expert's patch focuses only on `indices` and `data` arrays.", "confidence": 0.9, "instance_id": "scipy__scipy-10921", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to avoid repeated sparse matrix format conversions. The Expert, however, directly optimizes the `lil_matrix.tocsr` conversion method by replacing inefficient Python loops with highly optimized NumPy `np.fromiter` calls, effectively lowering the cost of the hot path itself.", "confidence": 1.0, "instance_id": "scipy__scipy-10939", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same core optimization strategy: switching from LIL to CSR format for sparse matrix operations. However, the Expert's explanation details a more systematic and deeper application of this strategy, including consistently redefining helper functions (`hstack`, `vstack`, `zeros`) to produce CSR matrices and optimizing specific matrix construction patterns in `_get_Abc`, which is a helper function for `_presolve`.", "confidence": 0.9, "instance_id": "scipy__scipy-11358", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path early-exit for sparse matrix multiplication when an operand is empty. The Expert, however, refactors the underlying C++ sparse matrix multiplication functions and their Python wrappers to optimize memory allocation and Python-C API interactions for the general case, which is a systemic improvement.", "confidence": 1.0, "instance_id": "scipy__scipy-11478", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its changes to `scipy/sparse/lil.py` (a part of its patch) \"do not contribute to the performance improvement for this specific workload,\" indicating an unaligned optimization. The expert's patch, however, directly targets and optimizes the `lil_matrix.tocsr` method, which is a measured hotspot in the workload.", "confidence": 0.9, "instance_id": "scipy__scipy-11517", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["micro-optimization", "dead-work-removal", "indexing-optimization"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations within the same hot loop. The LM optimizes NumPy indexing for the general case, while the Expert adds a conditional guard to skip `np.std` calls for bins with 0 or 1 elements, which is a 'safer' approach by explicitly handling edge cases.", "confidence": 0.9, "instance_id": "scipy__scipy-11757", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert optimize the `_kpp` function by replacing Python loops with vectorized operations and algorithmic refactoring. However, the Expert's approach for `_kpp` is deeper, leveraging the highly optimized `scipy.spatial.distance.cdist` function for efficient all-pairs distance calculation, which is a more robust and performant solution than the LM's manual iterative update using `np.sum` and `np.minimum`. The LM also includes an additional optimization for the `kmeans2` function that the expert does not.", "confidence": 0.9, "instance_id": "scipy__scipy-11982", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for `maxwell.fit` uses a heuristic for the `loc` parameter, which, despite claiming to compute MLEs, risks altering the output compared to the true MLE that the original numerical optimization would seek. The expert's optimization, in contrast, strictly preserves the mathematical semantics of the log-PDF while making its calculation more efficient and numerically stable.", "confidence": 0.9, "instance_id": "scipy__scipy-12001", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path that switches to a specialized algorithm (`eigh`) for Symmetric Positive Definite matrices, acting as a pattern-specific shortcut. The Expert, in contrast, performs a systemic optimization by Cythonizing a performance-critical nested Python loop within the general `_sqrtm_triu` function, lowering its implementation to native code.", "confidence": 0.9, "instance_id": "scipy__scipy-12474", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch adds generic f2py wrapper files, and its explanation speculatively connects this to the workload's `gengamma.rvs` call via `scipy.integrate`'s numerical methods, which is likely misdirected. The Expert's patch, in contrast, directly targets the `gengamma.rvs` hotspot by implementing a specialized, fast direct sampling algorithm using NumPy's optimized `standard_gamma` function.", "confidence": 1.0, "instance_id": "scipy__scipy-12587", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for small matrices via stack allocation in C++ and micro-optimizations for cache locality. The Expert, conversely, implements a more systemic optimization by moving significant Python-level overhead (NaN/inf checks, array creation) entirely into the C extension, fundamentally reducing Python interpreter involvement in the hot path.", "confidence": 0.9, "instance_id": "scipy__scipy-13107", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global memoization cache for the `_moment` function to avoid redundant calculations. The expert, instead, refactors the `skew` and `kurtosis` functions to compute the array mean only once and pass it to `_moment`, thereby eliminating redundant O(N) computations without caching.", "confidence": 1.0, "instance_id": "scipy__scipy-13388", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["memory_efficiency", "array_views"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot by replacing inefficient Python-NumPy interactions. However, the LM's solution uses `np.concatenate`, which still involves creating new arrays, while the Expert's solution mathematically decomposes the dot product to operate on array views, thereby eliminating intermediate array allocations and copies, representing a deeper optimization.", "confidence": 0.9, "instance_id": "scipy__scipy-13566", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for scalar arguments that efficiently creates a new array of size `count_nonzero(cond)`. The Expert, however, implements a systemic change by making scalar arguments pass through `argsreduce` without being reduced by `cond` at all, aligning the function's behavior with NumPy's broadcasting rules for scalars.", "confidence": 0.9, "instance_id": "scipy__scipy-13611", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path (a shortcut) for a common case, bypassing generic logic and using direct NumPy slicing. The expert's optimization, while a micro-overhead removal, can be interpreted as a localized dataflow restructuring by optimizing an arithmetic expression to reduce temporary NumPy array allocations.", "confidence": 0.8, "instance_id": "scipy__scipy-13759", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its patch includes a 'Semantic Correction' for the `chebyshev` function, changing its behavior to correctly apply weights, which was previously 'Unused'. This means the LM's patch alters the output semantics from the prior (incorrect) implementation. In contrast, the expert's explanation focuses on refactoring dispatch logic and reducing Python overhead, implicitly preserving the existing semantic behavior.", "confidence": 1.0, "instance_id": "scipy__scipy-13786", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe implementing a specialized `_add_sparse` method for `dia_matrix` to avoid costly `csr_matrix` conversions. The LM's implementation is deeper, pre-calculating all unique offsets and directly populating a pre-allocated NumPy array, while the Expert's uses iterative calls to `setdiag` and `diagonal` methods, which might incur more overhead.", "confidence": 0.9, "instance_id": "scipy__scipy-14004", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["NativeCodeImplementation", "PythonCAPI_vs_Pybind11"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe implementing the weighted Canberra distance in native code (C for LM, C++ for Expert) to reduce Python overhead. The expert's approach, however, leverages modern C++ features like templates and `transform_reduce_2d_` via Pybind11, which represents a deeper and potentially more optimized integration into the SciPy's C++ backend compared to the LM's direct C implementation using the older Python C API.", "confidence": 0.9, "instance_id": "scipy__scipy-14085", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a `multi_statistic` parameter to `binned_statistic_dd` to reuse intermediate binning and data grouping calculations across multiple statistics, explicitly mentioning 'caching/memoization'. The Expert's optimization, however, directly targets the internal computation of 'min', 'max', and 'median' statistics, replacing Python-loop-based approaches with highly optimized, vectorized NumPy operations, thus lowering the cost of the hotspot itself.", "confidence": 1.0, "instance_id": "scipy__scipy-14625", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path that explicitly notes a 'Potential Semantic Change/Tradeoff' where the generated distribution might differ from the intended one under certain conditions. The expert's optimization, conversely, is a systemic refactor of the core `_ppf` method to be fully vectorized and analytical, with no indication of altering documented behavior.", "confidence": 1.0, "instance_id": "scipy__scipy-16599", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by implementing a more efficient numerical algorithm (Newton's method) directly in Python. The Expert, in contrast, applies a systemic change by offloading the computation to a highly optimized, compiled C++ library (Boost Math) exposed via Cython, fundamentally shifting the execution to native code.", "confidence": 1.0, "instance_id": "scipy__scipy-16790", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and optimize by replacing expensive NumPy operations with direct Cython assignments in the inner loop. However, the Expert's solution is broader and deeper, additionally refactoring the data flow by preallocating and precomputing arrays (like `indptr` and `indices`) in the Python caller before passing them to the Cython function, moving more work out of the hot loop.", "confidence": 0.9, "instance_id": "scipy__scipy-16840", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's patch directly optimizes `lil_matrix.__iadd__` for `dia_matrix`, which is the exact operation in the workload (`L += A` where `A` is `dia_matrix`). The Expert's patch optimizes `lil_matrix.__setitem__` for `[:, :] = sparse_matrix`, based on an incorrect assumption that `L += A` for an empty `L` is equivalent to `L[:, :] = A`. Thus, the expert's optimization is misdirected for this specific workload.", "confidence": 0.9, "instance_id": "scipy__scipy-18211", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for the specific case where the parameter `z` is zero, effectively simplifying the distribution to a Beta distribution for that scenario. The Expert, however, applies an algorithmic refactor to the `_pdf` method that improves the general calculation of the `gausshyper` distribution for all parameter values, not just a specific one.", "confidence": 0.9, "instance_id": "scipy__scipy-18799", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a collection of micro-optimizations (e.g., replacing `einsum` with `sum(A*B)`, `np.where` with boolean indexing) and a specialized fast-path for 2D determinant. The Expert, however, implements a more fundamental algorithmic refactor by changing the mathematical approach to calculate the angle using the Law of Cosines, which is a systemic change to the core calculation.", "confidence": 0.9, "instance_id": "scipy__scipy-18850", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional manual Python loop (`if K > 1000`) to avoid a temporary array, which is a pattern-specific hack. In contrast, the Expert performs a systemic algorithmic refactor by replacing the entire Python loop structure with highly optimized, compiled SciPy `lfilter` functions.", "confidence": 0.9, "instance_id": "scipy__scipy-18917", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization enhances the existing memoization by converting it from a single-entry to a multi-entry dictionary cache. In contrast, the expert's optimization identifies that the memoizer's utility is limited to initial calls and introduces a flag to bypass the memoization lookup (the `np.all` comparison) entirely for subsequent iterations, thereby removing micro-overhead from the hot path without caching.", "confidence": 0.9, "instance_id": "scipy__scipy-18996", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to avoid re-computing the user-provided function for identical inputs. The Expert, conversely, lowers the cost of the hot path by replacing Python function calls (np.real/np.imag) with direct attribute access (.real/.imag), reducing micro-overhead without caching.", "confidence": 0.9, "instance_id": "scipy__scipy-19324", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a 'FastPath/SpecialCase' by adding an early exit in `correlation` that delegates to the newly optimized `cosine` for `centered=False`. The Expert, in contrast, focuses on more systemic `AlgorithmicRefactor` and `Native/Vectorized/Cython/Pythran` by optimizing the core calculation logic within `correlation` for both weighted and unweighted cases, without introducing such a specific fast path.", "confidence": 0.9, "instance_id": "scipy__scipy-19583", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations that replace a general NumPy function (`np.average`) with a more direct sequence of operations for weighted average calculation. However, the Expert's approach (`np.dot` with in-place normalization) is a deeper optimization, leveraging highly optimized BLAS routines and reducing memory allocations, representing a more advanced application of the same micro-optimization strategy.", "confidence": 0.9, "instance_id": "scipy__scipy-19589", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional guard to force a faster, approximate statistical method ('asymptotic') for large inputs, which is a fast-path decision. The Expert, in contrast, performs a systemic refactor by redesigning the data flow of tie information to compute it only once and reuse it across multiple functions, eliminating redundant and expensive calculations.", "confidence": 0.9, "instance_id": "scipy__scipy-19749", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path (`if arr.size > 10000`) to apply its optimization. The Expert, however, performs a more systemic algorithmic refactor of the core ranking logic, replacing less optimal operations with highly vectorized NumPy primitives without such a specific size-based guard.", "confidence": 0.9, "instance_id": "scipy__scipy-19776", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for setting the diagonal of an *empty* sparse matrix using a conditional guard. The Expert, conversely, implements a systemic refactor by eliminating intermediate sparse matrix object creation and direct attribute assignment during COO-to-compressed format conversions, which is a broader, more fundamental improvement to the sparse matrix data flow.", "confidence": 0.9, "instance_id": "scipy__scipy-19962", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized Python fast path for a very specific input pattern (1D horizontal structure, 2D input, 1 iteration). The expert, however, applies general micro-optimizations (using `asarray` and `size` attribute lookup) that reduce overhead in the existing `binary_erosion` function, improving the general case rather than adding a pattern-specific shortcut.", "confidence": 0.9, "instance_id": "scipy__scipy-20325", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for a specific input function (matrix squaring) by checking sample values. The Expert, conversely, applies a systemic optimization by offloading a general, computationally intensive loop within `funm` to Pythran-compiled native code, improving the general algorithm.", "confidence": 1.0, "instance_id": "scipy__scipy-21440", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is extensive caching and memoization of `linprog` results and sparse matrix constructions. The expert's optimization lowers a hotspot by refactoring a tight loop to hoist attribute lookups, reducing Python interpreter overhead without introducing caching.", "confidence": 1.0, "instance_id": "scipy__scipy-22660", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly conditional fast path for a very specific subset of integer inputs (2D, axis=-1, limited non-negative range) using `np.bincount`. The Expert, however, implements a more systemic, fully vectorized NumPy algorithm that applies to all multi-dimensional arrays (when axis=-1), replacing a less efficient approach with a sequence of optimized C-implemented NumPy operations.", "confidence": 0.9, "instance_id": "scipy__scipy-22676", "repo": "scipy/scipy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization involves full vectorization by eliminating a Python loop and performing object-lifetime pre-computation, representing a deeper and more systemic change. The Expert's optimization involves loop-invariant code motion and algebraic simplification *within* the Python loop, with per-call pre-computation. The rubric's categories, particularly 'Shortcut_vs_Systemic' and 'SameStrategy_DepthGap', are structured to assume the Expert's solution is broader/deeper/more systemic, which is not the case here, preventing a direct fit.", "confidence": 0.9, "instance_id": "scipy__scipy-8558", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a module-level cache to store LAPACK function objects, avoiding repeated lookups via `get_lapack_funcs`. The expert, however, optimizes the `find_best_blas_type` function itself (a component of the lookup process) by replacing a general-purpose NumPy call with a specialized, faster type-scoring and lookup system, thereby lowering the inherent cost of the hot path rather than just caching its result.", "confidence": 1.0, "instance_id": "scipy__scipy-9455", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific `elif` branches with hardcoded formulas for `order=1` and `order=2` (a shortcut), while the Expert implements a general algorithmic refactor using matrix operations on polynomial coefficients that applies to all `order > 0` (a systemic solution).", "confidence": 0.9, "instance_id": "scipy__scipy-9766", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path by pre-computing and caching specific factorial values up to 100. The Expert, however, implements a systemic improvement by leveraging the C-optimized `gmpy` library for general arbitrary-precision factorial calculations.", "confidence": 0.9, "instance_id": "sympy__sympy-10621", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["Caching", "AlgorithmicRefactor"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for large inputs (`n >= 1000000`) and heavily relies on `lru_cache` for repeated calls. In contrast, the Expert performs a systemic algorithmic refactor of the `_a` function, replacing a naive summation with a sophisticated number-theoretic approach involving precomputation and specialized modular arithmetic, fundamentally lowering the computational complexity of the hotspot.", "confidence": 0.9, "instance_id": "sympy__sympy-10919", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization (caching) for `diop_DN` and its internal calls, storing results for repeated identical inputs. The expert's solution, however, implements a specialized, more efficient algorithm for a specific range of inputs, directly lowering the computational cost of the hotspot rather than just caching its output.", "confidence": 1.0, "instance_id": "sympy__sympy-11675", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization strategy involves extensive caching of symbolic operations like `msubs` and `partial_velocity`. In contrast, the expert's solution fundamentally re-architects the `Vector` class's internal component aggregation from O(N^2) to O(N) and reduces intermediate `Vector` object creation, thereby lowering the inherent cost of vector operations rather than just caching their results.", "confidence": 0.9, "instance_id": "sympy__sympy-11676", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path for a single, hardcoded input pattern. The Expert, conversely, performs a systemic refactoring of the SAT solving pipeline, introducing new data structures and algorithms to reduce redundant computations for a broad range of inputs.", "confidence": 1.0, "instance_id": "sympy__sympy-11789", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional 'fast path' specifically for matrices containing only integer elements. In contrast, the Expert implements systemic optimizations within the `DenseMatrix` class, such as direct internal list operations, preallocation, and reduced memory copies, which improve the general performance of `DenseMatrix` operations regardless of element type.", "confidence": 0.9, "instance_id": "sympy__sympy-12640", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized algorithmic path by calling `jacobi_symbol` for the prime `p` case, which acts as a fast path for `_legendre`. The Expert, however, applies a systemic optimization by leveraging Python's C-implemented three-argument `pow` to avoid large intermediate integer calculations, representing a deeper, more fundamental fix to the modular exponentiation operation.", "confidence": 0.9, "instance_id": "sympy__sympy-14772", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to avoid recomputing identical sub-expressions. The Expert, conversely, optimizes the hot path by removing a redundant `try...except TypeError` block, thereby eliminating unnecessary exception handling overhead and lowering the cost of the existing computation without adding a cache.", "confidence": 0.9, "instance_id": "sympy__sympy-15379", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for two arguments that uses `functools.lru_cache`. The Expert, in contrast, implements a more systemic change by replacing the existing manual Python caching logic for `igcd` with a C-optimized `fastcache.clru_cache`, thereby improving the general caching infrastructure.", "confidence": 0.9, "instance_id": "sympy__sympy-15453", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the same hotspot and propose the same core optimization strategy: replacing a generic, Python-loop-based matrix element-wise multiplication with a call to a more efficient, specialized internal method. The expert's explanation provides a slightly deeper and more explicit description of the underlying mechanisms of this optimized method, mentioning potential implementations in C, Cython, or NumPy, which the LM only implicitly suggests.", "confidence": 0.9, "instance_id": "sympy__sympy-15736", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactors to count trailing zeros, targeting the same hotspot. However, the LM's effective optimization is deeper, replacing a Python loop with a single, highly optimized C-level bit manipulation function (`int.bit_length()`), while the Expert's uses a byte-by-byte Python loop, which is an improvement but still an interpreted loop.", "confidence": 0.9, "instance_id": "sympy__sympy-15909", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for a specific input pattern (Or of Symbols). The Expert implements a more systemic change by introducing a default limit on variables (8) to manage the exponential complexity of the simplification algorithm, which is an algorithmic refactor to control the general case's performance.", "confidence": 0.9, "instance_id": "sympy__sympy-16134", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same core optimization: replacing a Python function call with a C-optimized built-in `pow` function for modular exponentiation. The expert's explanation provides a slightly deeper analysis by explicitly detailing 'Reduced Python Overhead' and 'Leveraging C Optimization' as distinct benefits, while the LM's explanation implies these without explicitly separating them.", "confidence": 0.9, "instance_id": "sympy__sympy-17916", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths (`if n == 13`, `if x == 13`) that leverage `math.log` for a particular pattern, making it a benchmark-specific shortcut. The Expert, conversely, integrates a general-purpose C-implemented arbitrary-precision arithmetic library (`gmpy`) to handle `integer_nthroot` systemically, improving the general case when `gmpy` is available.", "confidence": 0.95, "instance_id": "sympy__sympy-18276", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces hardcoded early-exit conditions for the exact input values in the benchmark, acting as a narrow, benchmark-specific shortcut. The Expert implements a more general module-level caching mechanism that dynamically populates lists of known Mersenne primes and perfect numbers, providing a systemic improvement for a broader range of inputs.", "confidence": 0.9, "instance_id": "sympy__sympy-18591", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimizations introduce specific fast-paths and micro-optimizations within the existing Risch algorithm functions. In contrast, the Expert's changes involve a systemic refactor of the fundamental `Poly` class itself, improving its core design for memory, instantiation, and hashing, which is a broader, more foundational improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-19270", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a pattern-specific fast-path for `Sign(base**exp)` when the exponent is even. The Expert's optimization, however, refactors the conditional logic within the `sign` function's evaluation to avoid an expensive `im(a)` calculation for non-imaginary arguments, representing a more systemic improvement to the general execution flow by removing dead work.", "confidence": 0.9, "instance_id": "sympy__sympy-20228", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for `Poly` objects by delegating to a simpler string printer. In contrast, the Expert performs a systemic algorithmic refactor by replacing a Python-loop-based string width calculation with a C-optimized `str.translate()` method, improving a fundamental utility used throughout the pretty printing subsystem.", "confidence": 0.95, "instance_id": "sympy__sympy-20384", "repo": "sympy/sympy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its specialized integration paths and hardcoded solutions are not triggered by the workload's specific expression, making these optimizations misdirected. The Expert, conversely, targets general, fundamental hotspots in SymPy's symbolic computation, such as efficient symbol dependency checks and memoization of expensive conversions, which are aligned with the workload.", "confidence": 0.9, "instance_id": "sympy__sympy-20989", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot with similar strategies (replacing Python loops with C-optimized list operations). However, the Expert's implementation for `_eval_eye` uses a more efficient C-optimized slice assignment for setting diagonal elements, whereas the LM's uses a Python `for` loop. The Expert also provides a deeper explanation of the `copy=False` flag and its impact on the matrix constructor.", "confidence": 0.9, "instance_id": "sympy__sympy-21006", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary strategy involves introducing multiple memoization caches and a specific ASCII string fast path. The expert, in contrast, performs an algorithmic refactor within a hot loop, reducing the number of function calls and intermediate object creations from `2*(N-1)` to one, representing a systemic improvement rather than a narrow guard or cache.", "confidence": 0.9, "instance_id": "sympy__sympy-21169", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `n=2` matrix exponentiation, including an algorithmic optimization for complex matrices. The expert's patch, however, implements a systemic micro-optimization by refactoring `GaussianElement` instantiation to eliminate a redundant method call, improving the general overhead of object creation.", "confidence": 0.9, "instance_id": "sympy__sympy-21391", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific early-exit fast path for the benchmark's exact query and adds global caching. The Expert, in contrast, performs a systemic algorithmic refactor by expanding the pre-computed knowledge base of logical implications, turning a multi-step inference into a direct lookup.", "confidence": 0.9, "instance_id": "sympy__sympy-21455", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces hardcoded, specialized determinant formulas for small matrix sizes (1x1, 2x2, 3x3, 4x4) as fast paths. In contrast, the Expert replaces the general fraction-free Gaussian elimination algorithm with the Bareiss algorithm, which is a systemic algorithmic improvement for determinant calculation across various matrix sizes and domains.", "confidence": 0.95, "instance_id": "sympy__sympy-21501", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization (caching) to numerous helper functions within a module. The expert, in contrast, optimizes core arithmetic operations by adding early-exit conditions for zero and numerical operands, thereby avoiding expensive symbolic simplification calls and lowering the cost of the hotspot itself without caching.", "confidence": 1.0, "instance_id": "sympy__sympy-21543", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path for `q=1000` with a specialized GCD, acting as a pattern-specific hack. The Expert, in contrast, implements a more systemic refactor to eliminate redundant `Rational` object creation when integer arguments are passed, improving the general case for `Rational(int, int)`.", "confidence": 0.9, "instance_id": "sympy__sympy-21954", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces function-level memoization (`@cacheit`) to cache the results of `manualintegrate`. In contrast, the Expert optimizes the `special_function_rule` by refactoring expensive symbolic object creation and pattern construction into a lazily initialized module-level cache, and uses `evaluate=False` to reduce expression creation cost, thereby lowering the inherent cost of the hot path rather than just caching its output.", "confidence": 0.9, "instance_id": "sympy__sympy-23696", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization (caching) to avoid recomputing results for helper functions. The expert, however, replaces the entire `necklaces` function with a fundamentally more efficient FKM algorithm, directly generating results without the need for caching or filtering a combinatorially large set of intermediate values.", "confidence": 1.0, "instance_id": "sympy__sympy-24313", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized, persistent cache and a conditional fast path for specific `Mul` structures, heavily exploiting the benchmark's `timeit` setup. The Expert performs an algorithmic refactor of the `_eval_is_zero` method, fundamentally changing its complexity from O(N) to O(1) for the relevant case, representing a systemic improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-24485", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly details 'Caching Common Expressions' as one of its optimizations. In contrast, the Expert's optimization focuses on replacing an expensive symbolic substitution operation with more efficient direct matrix algebra, which lowers the hot path by changing the computation method rather than adding a cache.", "confidence": 0.9, "instance_id": "sympy__sympy-24792", "repo": "sympy/sympy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that a significant portion of its patch (the new `divfree.py` module and its functions) is 'not directly used by this workload', indicating optimization of an unexercised path. The Expert's explanation, conversely, targets a measured hotspot (`Mul.flatten`) that is heavily relied upon by the workload.", "confidence": 0.9, "instance_id": "sympy__sympy-24884", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for 2x2 matrix inversion using a hardcoded formula. The Expert, in contrast, implements a systemic change by integrating the DomainMatrix approach as a new default method for matrix inversion, which is a more general algorithmic refactor.", "confidence": 0.9, "instance_id": "sympy__sympy-25452", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path (early exit) for a particular query pattern, bypassing the general SAT solver. The expert, in contrast, implements a systemic change by refactoring the fact-loading mechanism to conditionally load only relevant facts based on expression kinds, thereby reducing the overall data processed by the SAT solver for a broader range of queries.", "confidence": 1.0, "instance_id": "sympy__sympy-25591", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes several hardcoded test cases for specific small ranges, acting as narrow fast-paths. In contrast, the Expert's patch applies a systemic algorithmic refactor to the existing Python sieve implementation, making it more efficient and correct by only processing prime factors.", "confidence": 0.9, "instance_id": "sympy__sympy-25631", "repo": "sympy/sympy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Heuristic/ParamTuning"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly introduces an approximation for the characteristic polynomial of submatrices within the Berkowitz algorithm, which risks altering the mathematical output. The expert's optimization, conversely, preserves exact mathematical behavior by leveraging matrix sparsity to avoid iterating over zero elements and reducing iteration overhead, thus removing dead work.", "confidence": 1.0, "instance_id": "sympy__sympy-26057", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific early-exit fast-path for identity matrices. In contrast, the Expert performs an algorithmic refactor by correcting how a utility function processes arguments from large matrices, fixing a systemic inefficiency in symbol extraction that benefits the general matrix solving algorithm.", "confidence": 0.9, "instance_id": "sympy__sympy-26063", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is memoization (caching) of symbolic derivatives. The expert, however, replaces the expensive symbolic differentiation with an algorithmic refactor using `linear_eq_to_matrix` to directly extract coefficients, which are the derivatives, thus lowering the cost of the hot path without caching.", "confidence": 1.0, "instance_id": "sympy__sympy-26367", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a hardcoded cache for specific input values, acting as a narrow fast path for the benchmarked input. In contrast, the expert performs a systemic algorithmic refactor of the `_primepi` function, introducing odd-number iteration and sieve-based composite skipping to generally improve its efficiency.", "confidence": 1.0, "instance_id": "sympy__sympy-26710", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization primarily relies on pre-populating the prime sieve with more initial primes (a form of pre-computation/caching) and adding a narrow fast path. The Expert, however, implements an algorithmic refactor for small prime lookups, replacing an expensive symbolic computation with a direct and efficient sieve extension. This aligns with the LM using a shortcut (pre-computed data) versus the Expert applying a systemic algorithmic improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-27051", "repo": "sympy/sympy"}
