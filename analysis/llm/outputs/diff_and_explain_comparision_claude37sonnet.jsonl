{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path to skip NaN checks when arrays are known to be NaN-free. The Expert, however, applies a systemic optimization by changing the underlying NumPy array view from `datetime64` to `int64` for comparison, leveraging a generally faster native vectorized comparison routine.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38248", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a Python-level fast path using `all(isinstance(x, bool) for x in key)` to avoid `np.asarray`. The Expert, in contrast, replaces the `np.asarray` call with a new Cython function that performs the boolean check at C speed, representing a more fundamental, systemic optimization.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-41861", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specialized, pattern-specific optimization for consecutive integer breaks, reducing complexity to O(1) by inferring the intersection from overall ranges. The Expert, in contrast, implements a more general algorithmic refactor for unique endpoints, leveraging existing C-implemented, vectorized operations like `get_indexer` for efficient computation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42293", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["algorithmic_refactor", "data_processing_strategy", "numerical_algorithm"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM refactors the numerical algorithm for variance within a Cython function for better stability and FPU efficiency. The Expert, however, enables a broader 'block-wise' data processing strategy for multi-column `groupby` operations, reducing Python overhead and improving cache locality by changing how data is dispatched to the underlying computations. Both are algorithmic refactors, but the Expert's is a more systemic change to the data processing pipeline, making it broader in impact.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43115", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a specific O(N) calculation (finding the minimum value) within the existing copy-and-modify logic. The Expert, however, performs a systemic refactor by changing the method's contract to avoid the entire O(N) data copy and in-place modification, instead returning a direct view.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45434", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by hoisting conditional checks out of an inner loop, a micro-optimization of control flow. The Expert, however, implements a more systemic change by refactoring the data pipeline to avoid unnecessary data type conversions and memory allocations, allowing direct processing of `int8` data in Cython.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46745", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization involves an algorithmic refactor of the serialization process (pickling raw values) and a structural redesign with a custom deserialization path. The expert's optimization is a more targeted micro-overhead removal by setting a flag in an existing generic factory function, which acts as a specific shortcut.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-47916", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, making no changes and thus failing to address any performance hotspot. The expert, however, identified and fixed a performance regression in the `factorize` function by conditionally applying an array copy, directly targeting a measured hotspot.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48620", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path within `Series.explode()` for a narrow data pattern (NumPy arrays of integers), directly addressing the benchmark's input. The Expert, conversely, refactors a core type conversion utility (`maybe_convert_objects`) by adding a parameter and early-exit logic, leading to a more systemic improvement in pandas' general type inference mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51517", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path that skips integrity checks (like `is_unique`) only when new levels are `numpy.arange`-like, a pattern-specific hack. The Expert, however, implements a systemic algorithmic refactor of the `_verify_integrity` method to only perform checks on the levels that were actually modified, a more general improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51873", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly notes a semantic change regarding the order of filtered items, which could be a behavioral risk. The expert's solution achieves performance by leveraging an optimized, C-implemented method without introducing such a semantic alteration, thus preserving documented behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52941", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path at the public `pd.concat` level, specifically guarding for identical DataFrame instances (`obj is first_obj`) and using `numpy.tile`. The Expert, conversely, optimizes a more systemic condition within the internal `_concat_homogeneous_fastpath` by checking if any reindexing is needed (`not indexers`) and using `np.concatenate` for efficient block stacking. The LM's approach is a narrow, pattern-specific shortcut, while the Expert's is a deeper, more general improvement to the internal data management.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53772", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast-path for 'inner' joins by explicitly finding common keys and re-mapping indices using Python sets. The Expert, conversely, makes a systemic correction by ensuring that 'StringDtype[pyarrow]' correctly dispatches to its already optimized PyArrow-native factorization path, avoiding costly Python object conversions.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54510", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization using `functools.lru_cache` to avoid recomputing results for identical inputs. The Expert introduces an early-exit fast-path for common numeric dtypes, which directly reduces the computational work within the hotspot function itself, rather than caching its results.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57478", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `datetime64` arrays with resolution mismatches, pre-converting the scalar fill value once. The Expert, in contrast, performs algorithmic refactoring by removing two distinct sources of redundant work: an unnecessary DataFrame copy when `inplace=True` and a redundant unit conversion when datetime units already match, improving the general algorithm flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57479", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path that switches to an interpolation-based method for large input arrays, which is a pattern-specific optimization. The Expert, in contrast, performs an algorithmic refactor by eliminating a redundant, expensive call to a low-level function, improving the efficiency of the general calculation path.", "confidence": 0.9, "instance_id": "astropy__astropy-10814", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multi-layered caching, which acts as a pattern-specific fast path for repeated inputs. The Expert performs an algorithmic refactor by fixing argument propagation to avoid unnecessary work in the parsing logic, improving the general case without caching.", "confidence": 0.9, "instance_id": "astropy__astropy-12699", "repo": "astropy/astropy"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is introduced via an invasive global monkey-patch of `numpy.arange`. In contrast, the expert's optimization is a local, contained change within a single function, making it minimal and maintainable.", "confidence": 1.0, "instance_id": "astropy__astropy-12701", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["FastPath", "ConditionalPlacement"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert introduce an early-exit fast-path for SkyCoord objects already in the target frame. The Expert's patch is 'deeper' by placing this fast-path as a new `elif` condition higher in the method's conditional structure, allowing it to short-circuit more of the original logic compared to the LM's patch, which is nested within the final `else` block.", "confidence": 0.9, "instance_id": "astropy__astropy-13471", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization introduces early-exit fast paths in the `Longitude` constructor to skip the entire angle wrapping process when angles are already in range, acting as a shortcut. The Expert's optimization is a micro-overhead removal (eliminating a redundant NumPy call) within the angle wrapping logic, which is a refinement of the existing algorithm.", "confidence": 0.9, "instance_id": "astropy__astropy-13497", "repo": "astropy/astropy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe the exact same early-exit fast-path optimization in `ManualInterval.get_limits`, targeting the same hotspot and using identical code. There is no discernible difference in their core optimization strategies, scope, or semantic impact.", "confidence": 1.0, "instance_id": "astropy__astropy-13898", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the same early-exit optimization. The expert's explanation, however, provides a slightly deeper analysis by explicitly listing all the expensive NumPy operations (`np.asarray().ravel()`, `np.min()`, `np.max()`) that are bypassed, and also mentions memory allocation reduction, indicating a more thorough understanding of the full impact.", "confidence": 0.9, "instance_id": "astropy__astropy-13899", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for scalar milliarcsecond parallaxes using a hardcoded arithmetic calculation, which is a narrow, pattern-specific hack. The Expert, in contrast, performs an algorithmic refactor by changing how an intermediate Quantity object is passed to the parent constructor, leading to a more general reduction in object creation overhead.", "confidence": 1.0, "instance_id": "astropy__astropy-15900", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path with narrow guards for `Angle` creation from NumPy arrays, bypassing general Python logic. The Expert applies `functools.cache` to a utility function, `_convert_unit_to_angle_unit`, providing a more general and systemic improvement to unit conversion efficiency for repeated calls.", "confidence": 0.7, "instance_id": "astropy__astropy-16088", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path to bypass the `_validate_angles` method entirely for a common input pattern. The Expert, in contrast, refactors the internal NumPy operations within `_validate_angles` to make the validation itself more efficient, representing a systemic improvement to the core logic.", "confidence": 0.9, "instance_id": "astropy__astropy-16096", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe fast-path/early-exit optimizations. However, the expert's change targets a deeper, more fundamental numerical operation (`_wrap_at` on large NumPy arrays) that is a bottleneck within the coordinate initialization, while the LM's change is a higher-level shortcut in the `SkyCoord` constructor itself.", "confidence": 0.9, "instance_id": "astropy__astropy-16222", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to reduce Python overhead. The LM introduces a fast path for a specific input type (`numpy.ndarray`), while the Expert applies caching to memoize an expensive unit conversion operation (`u.Unit()`) that occurs for any string unit input, making the Expert's approach broader in its applicability to unit handling.", "confidence": 0.9, "instance_id": "astropy__astropy-16243", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional 'fast path' for scalar inputs using an `isinstance` check, preserving the original NumPy-based path for array inputs. In contrast, the expert performs a more systemic refactor, redesigning the function to operate solely with native Python scalar operations and removing the NumPy dependency, which fundamentally changes its internal algorithm and input expectations.", "confidence": 0.9, "instance_id": "astropy__astropy-16295", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations (Micro-OverheadRemoval). However, the Expert's changes are deeper, targeting multiple points of overhead in the core model evaluation framework (e.g., unit handling, shape validation, parameter broadcasting) that affect a broader range of models, whereas the LM's change is a specific numerical expression refactoring within a single model's evaluate method.", "confidence": 0.9, "instance_id": "astropy__astropy-16670", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies micro-optimizations and local refactoring to the numerical expressions within the `Gaussian1D` model's `evaluate` and `fit_deriv` methods. The Expert, however, implements a systemic refactor of the fitting process by hoisting parameter introspection out of the hot loop and streamlining model evaluation to avoid repeated attribute assignments, addressing a broader overhead in the fitting subsystem.", "confidence": 0.9, "instance_id": "astropy__astropy-16673", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a hardcoded fast path that explicitly bypasses unit validation for specific argument values, which carries a `PotentiallyRisky` semantic impact by skipping checks. In contrast, the expert's optimization conditionally uses a `nullcontext` when no equivalencies are provided, removing unnecessary overhead while `Preserving` all original validation and behavior.", "confidence": 0.9, "instance_id": "astropy__astropy-16742", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple layers of caching to avoid re-parsing identical unit strings. The Expert, conversely, refactors the unit object construction within the parser to directly create specialized CompositeUnit objects, reducing object allocation overhead and method calls, thus making the parsing operation itself inherently faster without caching.", "confidence": 1.0, "instance_id": "astropy__astropy-16813", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization caches to store previously parsed `Unit` objects and formatters, avoiding redundant work by returning cached results. The Expert, in contrast, introduces a fast-path (`_parse_unit`) for simple unit strings, which directly lowers the computational cost of parsing the hotspot by using a simpler, more efficient algorithm, rather than caching the result of a slower one.", "confidence": 1.0, "instance_id": "astropy__astropy-17004", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization/caching for `to_string` results and formatter objects. The expert's solution, however, refactors the `_decompose_to_known_units` method to reduce object allocations and skip redundant error checks, directly lowering the cost of the hot path rather than caching its output.", "confidence": 1.0, "instance_id": "astropy__astropy-17043", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a global memoization cache for the `compose` method. The expert, however, focuses on fundamental algorithmic improvements and micro-optimizations within the `compose` method itself, such as reducing sorting complexity and optimizing unit comparison, thereby lowering the cost of the hot path without relying on caching.", "confidence": 1.0, "instance_id": "astropy__astropy-17425", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a direct memoization cache for a specific function (`getdata`) to handle repeated identical calls, acting as a pattern-specific shortcut. The Expert, however, implements a systemic optimization by caching values within the core `astropy.config.ConfigItem` descriptor, which is a foundational component used by `getdata` and potentially many other parts of Astropy, along with a structural refactor using `__set_name__`.", "confidence": 0.9, "instance_id": "astropy__astropy-17461", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to store and reuse results of repeated slicing operations. The Expert optimizes a different hotspot by removing unnecessary checks within `__setattr__` for internal attributes, thereby lowering the cost of the attribute setting operation itself rather than caching its output.", "confidence": 0.9, "instance_id": "astropy__astropy-6940", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache for repeated slicing operations. The expert, conversely, optimizes the object creation process itself by bypassing the `__init__` method for sliced objects, thereby lowering the overhead of the hot path rather than just caching its output. The expert's change also carries a documented semantic risk.", "confidence": 0.9, "instance_id": "astropy__astropy-6941", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `np.add.reduce` within the `Angle` class's `__array_ufunc__` method. The Expert, however, implements systemic optimizations within the core `astropy.units` subsystem, adding early-exit identity checks and removing overhead in unit validation and conversion functions that benefit all `Quantity` operations, not just a specific ufunc.", "confidence": 0.9, "instance_id": "astropy__astropy-7010", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["maintainability", "code_structure"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert optimize the same hotspot by ensuring `mask=False` is passed to the underlying `numpy.ma.MaskedArray` constructor. However, the Expert's approach is deeper and safer: it modifies the `mask` parameter within the existing initialization flow. The LM creates a separate, parallel fast-path that duplicates object construction and attribute setting logic, making the Expert's solution more integrated and maintainable.", "confidence": 0.9, "instance_id": "astropy__astropy-7422", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces global memoization caches to store results of unit computations, avoiding re-computation for identical inputs. The Expert, in contrast, optimizes the underlying unit arithmetic by reducing object creation, skipping redundant validation checks, and streamlining the power calculation logic, thereby lowering the cost of the hot path itself rather than just caching its output.", "confidence": 1.0, "instance_id": "astropy__astropy-7549", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes a conditional check, causing the wrapping calculation to *always* occur, whereas the original code *skipped* it for the benchmark's input, thus changing the execution semantics. The expert's optimization, by contrast, uses `copy=False` to avoid an unnecessary data copy, which is a behavior-preserving optimization.", "confidence": 0.9, "instance_id": "astropy__astropy-7616", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["FastPath", "Micro-Optimization", "Safety"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe adding an early-exit fast path for `unit.to(unit)` conversions. The LM's fast path is broader, applying for any `value` and also optimizing `_get_converter`. The Expert's fast path is more specific, only triggering when `value` is the default `1.0` (using `is UNITY`), which can be considered a safer or more conservative application of the fast path.", "confidence": 0.9, "instance_id": "astropy__astropy-7643", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path in `CompositeUnit.__init__` that precisely matches the benchmark's input pattern. The Expert, in contrast, implements a broader fast path in `CompositeUnit.__init__` and also applies systemic micro-optimizations to underlying utility functions like `sanitize_scale` and `resolve_fractions`, improving general performance across the subsystem.", "confidence": 0.9, "instance_id": "astropy__astropy-7649", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary strategy is to introduce memoization (caching) at multiple points to reuse previously computed or constructed objects. In contrast, the expert's optimization focuses on lowering the cost of a specific hot path by replacing an inefficient unit conversion sequence with a more direct and performant algorithmic approach, thereby reducing the inherent computational work rather than just avoiding it.", "confidence": 1.0, "instance_id": "astropy__astropy-7924", "repo": "astropy/astropy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, offering no optimization and thus failing to address the workload's hotspot. The expert, conversely, provided a targeted optimization that directly addressed the measured hotspot by removing redundant recursive computations in a critical path.", "confidence": 0.9, "instance_id": "astropy__astropy-8349", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a benchmark-specific fast-path that returns a 'minimal HDUList containing dummy PrimaryHDU and ImageHDU objects (with empty Header instances)', fundamentally altering the object's behavior for any operation beyond `len()`. The expert's solution, however, preserves full FITS parsing semantics while optimizing the underlying `Card` and `Header` object construction and keyword parsing.", "confidence": 1.0, "instance_id": "astropy__astropy-8428", "repo": "astropy/astropy"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "astropy__astropy-8494", "repo": "astropy/astropy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces new methods (`_seek_to_extension`) and fast paths, but its own analysis and the diff confirm that these new code paths are not triggered by the workload. The Expert's patch, however, directly targets the measured hotspot of parsing intermediate headers using Cython and lazy loading, which is explicitly invoked by the workload.", "confidence": 1.0, "instance_id": "astropy__astropy-8502", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow conditional guard to prevent a specific redundant attribute assignment. The Expert, however, implements a systemic refactoring of the `DataInfo` class by introducing `__slots__` and replacing dynamic attribute resolution with static descriptors, fundamentally redesigning the object's internal structure for broader performance improvements.", "confidence": 1.0, "instance_id": "astropy__astropy-8998", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch fundamentally changes the output of the `random_state_data_python` function from a list of tuples containing random integers to a list of `random.Random` internal states. In contrast, the expert's patch explicitly preserves the original function's output format while optimizing its internal computation using vectorized NumPy operations.", "confidence": 1.0, "instance_id": "dask__dask-10356", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-overhead removal. The LM's effective optimization replaces a Python arithmetic operation with a vectorized NumPy equivalent. The Expert's optimization is deeper by preventing entirely redundant data type conversions and memory copies during DataFrame creation, thus avoiding unnecessary work rather than just speeding it up.", "confidence": 0.9, "instance_id": "dask__dask-10428", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Robustness", "ErrorHandling"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe introducing a fast path using `df.drop_duplicates` to replace a slower operation. The LM uses a specific conditional check (`if all(isinstance(b, str)...)`) for its fast path, while the Expert uses a more robust `try...except` block, ensuring graceful fallback for any potential failure of the fast path, making it a safer and broader implementation of the same strategy.", "confidence": 0.9, "instance_id": "dask__dask-10922", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, conditional 'fast path' specifically for a narrow pattern (2D arrays indexed by two 1D arrays). The expert, however, performs a systemic algorithmic refactor within the existing general `_vindex_array` function, replacing Python-level loops with vectorized NumPy operations to improve performance for a broader range of NumPy array indexers.", "confidence": 0.9, "instance_id": "dask__dask-11625", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple conditional fast paths and pattern-specific guards (e.g., `len(a) <= 10`, `len(collections) > 1000`) to optimize specific scenarios. The Expert, however, applies a systemic algorithmic refactor within a core utility function (`ensure_dict`) to eliminate redundant dictionary updates, improving the general efficiency of graph processing.", "confidence": 0.9, "instance_id": "dask__dask-5501", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe caching/memoization. However, the LM caches the final result of the `_meta_nonempty` property at the instance level. The Expert's optimization is deeper, caching intermediate `_nonempty_series` results by dtype within the `meta_nonempty_dataframe` utility function, which is the true inner loop for metadata generation for wide DataFrames with uniform dtypes.", "confidence": 0.9, "instance_id": "dask__dask-5553", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM introduces two highly specific fast-paths/hacks based on object identity or identical values, tailored to the benchmark's input construction. Expert introduces a micro-optimization in a frequently called helper function (`atleast_nd`) that generally avoids unnecessary Python overhead when an array already has sufficient dimensions, representing a more systemic improvement.", "confidence": 0.9, "instance_id": "dask__dask-5884", "repo": "dask/dask"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization for the repeated workload is adding a module-level cache to `da.optimize`, completely bypassing subsequent optimization calls. The Expert, in contrast, introduces a fast path within a core graph rewriting function (`rewrite_blockwise`) that avoids significant internal overhead for simple cases, thereby making the underlying optimization process itself more efficient without caching.", "confidence": 0.9, "instance_id": "dask__dask-5890", "repo": "dask/dask"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly changes the function's behavior by returning a small sample of slices instead of all combinations for large inputs. In contrast, the expert's optimization preserves the full, correct output while drastically reducing the number of Python objects created for improved efficiency.", "confidence": 1.0, "instance_id": "dask__dask-5891", "repo": "dask/dask"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization includes adding a `seen_deps` cache, which is a form of caching/memoization. The Expert's optimization in `dask/core.py` changes argument passing to enable NumPy in-place operations, effectively lowering the hotspot by avoiding memory allocations and copies without using a cache.", "confidence": 0.9, "instance_id": "dask__dask-5933", "repo": "dask/dask"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": ["Eager computation", "Python overhead reduction", "Tuple indexing"], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an eager computation and caching mechanism (`self._cached_dict`) to avoid recomputing the `_dict` attribute. In contrast, the expert refactors the `make_blockwise_graph` function itself, reducing Python interpreter overhead by replacing expensive dictionary lookups with efficient tuple indexing and pre-computed structures within the hot loop, thereby making the original computation significantly faster without caching its result.", "confidence": 1.0, "instance_id": "dask__dask-5940", "repo": "dask/dask"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "dask__dask-6186", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global cache and pre-populates it during a specific `da.stack` operation to create a fast path for subsequent `__getitem__` calls, which is a pattern-specific shortcut. The Expert, in contrast, implements a systemic algorithmic refactor within `HighLevelGraph` to optimize the general case of graph construction with a single dependency, a more fundamental improvement to Dask's core graph building.", "confidence": 0.9, "instance_id": "dask__dask-6293", "repo": "dask/dask"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for `da.zeros` returns a `(1,1)` array internally for large inputs, fundamentally changing the array's shape and risking altered behavior for operations beyond `sum`. The expert's solution uses `np.broadcast_to` to create a memory-efficient view that correctly preserves the array's declared shape and documented behavior.", "confidence": 1.0, "instance_id": "dask__dask-6491", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations to reduce Python overhead within a hot loop. The LM's approach involves a broader refactoring to vectorized NumPy operations, while the Expert's is a more precise and minimal change, replacing `np.searchsorted` with `bisect` to avoid a specific, repeated implicit NumPy array conversion, demonstrating a deeper understanding of that particular micro-bottleneck.", "confidence": 0.9, "instance_id": "dask__dask-6669", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe implementing caching for the `Array.shape` property with invalidation on `_chunks` modification. The expert's approach is deeper and broader by introducing a reusable `cached_property` decorator and refactoring `_chunks` into a proper property with a setter for invalidation, which is a more idiomatic and maintainable solution compared to the LM's manual `__setattr__` override and dedicated slot.", "confidence": 0.9, "instance_id": "dask__dask-7023", "repo": "dask/dask"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "dask__dask-7104", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a conditional fast path for numeric data, falling back to the original Python-based merge sort for other types. The Expert's patch, in contrast, performs a systemic algorithmic refactor by completely replacing the Python-level merge sort with a vectorized NumPy approach for all cases, without a conditional fallback.", "confidence": 0.9, "instance_id": "dask__dask-7172", "repo": "dask/dask"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its proposed optimizations are not triggered by the provided workload, making them irrelevant to the benchmark's performance. In contrast, the expert's explanation details how its patch directly targets and improves the core graph processing logic that the workload heavily exercises.", "confidence": 1.0, "instance_id": "dask__dask-7403", "repo": "dask/dask"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path that changes the semantic interpretation of a list of strings passed to `plt.plot` (from attempting numerical conversion to plotting against indices). The expert's optimization, however, preserves the existing behavior of categorical plotting while making the tick formatting process significantly more efficient by batching operations.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-13917", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization for `tight_layout` is caching. The Expert's optimization for `get_tightbbox` is an early-exit mechanism within a loop over artists, which constitutes a 'tight loop refactor' to avoid an expensive computation without caching.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-14504", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["vectorization", "robustness"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization: vectorizing the `calc_arrow` function to eliminate a Python loop and leverage NumPy. The expert's implementation uses `np.divide` with `where` and `out` arguments for handling division by zero, which is a slightly more robust and idiomatic NumPy pattern compared to the LM's masking approach, indicating a minor depth/safety gap in the implementation of the same strategy.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-15346", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path that hardcodes a single input tuple value, acting as a narrow shortcut. The Expert, in contrast, performs a more systemic refactor by eliminating unnecessary NumPy array conversions for any iterable input, improving the general case for Python tuples.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-15834", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["memory_efficiency", "intermediate_string_avoidance"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert replace `textwrap.fill` with a manual string manipulation for line-wrapping hex data, targeting the same hotspot. However, the LM's approach is deeper as it avoids creating a single, massive intermediate hex string by converting byte chunks to hex, while the Expert's approach still creates the full hex string before slicing it.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17177", "repo": "matplotlib/matplotlib"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization bypasses `tight_layout` calculations with hardcoded values, which risks altering the plot's visual output. The expert's optimization, however, introduces a semantically preserving early-exit for trivial Bezier curves, avoiding unnecessary computation without changing behavior.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17994", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Dataflow/GraphRestructure", "Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's first optimization introduces a fast path for `Axes.bar` with a narrow guard (`len(x) > 100`) and specific conditions, which is a pattern-specific hack. In contrast, the Expert's optimization applies a vectorized algorithmic refactor using NumPy to a fundamental `Path` method (`get_extents`) for a common and general case (straight-line paths), representing a more systemic improvement.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17995", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe caching strategies. The LM caches the high-level result of text layout within the `Text` class. The Expert, however, caches a lower-level, frequently called utility function (`os.path.realpath`) within the `font_manager` subsystem, indicating a deeper and broader optimization within the same strategy family.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-18018", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new conditional fast path for a specific input type (naive datetimes). In contrast, the Expert performs a systemic refactor by removing the inefficient `np.vectorize` mechanism and replacing it with a direct, vectorized `astype` call, improving the general conversion logic.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-18756", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization strategy is centered on introducing multiple layers of caching and object reuse. The expert, however, focuses on lowering the cost of a hot path (PostScript tokenizer) by reducing string allocations, consolidating regular expressions, and micro-optimizations, rather than caching results.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-19564", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies multiple localized fast-paths (conditional guards) and extensive caching/object reuse across several modules. The Expert, in contrast, implements a single, more systemic optimization by structurally redesigning a core decorator's internal logic to avoid an expensive introspection call (`inspect.Signature.bind`) in the common case, which is a deeper algorithmic improvement.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-19760", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Heuristic/ParamTuning", "Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a collection of specific optimizations, including fast-path flags for `savefig`, parameter tuning for FFmpeg, and caching. The expert, however, implements a systemic algorithmic refactor by adding a visibility check to the core 3D projection loop, fundamentally removing dead work.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-21564", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to skip recomputing the rotation matrix for repeated inputs. The Expert, conversely, lowers the cost of the hot path by refactoring the matrix multiplication to use in-place scalar assignments, thereby avoiding NumPy array allocations and Python object overhead for every call, rather than caching.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-22108", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization strategy is primarily focused on introducing and enhancing caching mechanisms to store and reuse mathtext parsing results. In contrast, the expert's optimization refactors the underlying `pyparsing` grammar to reduce the overhead of parsing itself, making the hot path inherently faster without relying on memoization.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-22875", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization for the repeated workload is the introduction of a memoization cache for the `Name` constructor. The Expert, conversely, optimizes the underlying string processing algorithm itself by replacing a slow regex-based substitution with a pre-computed `str.translate()` call, making the hot path inherently faster without memoizing the entire object creation.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-23287", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["LazyInitialization", "Memoization"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM implements a 'lazy initialization' fast path to defer an expensive upfront task during import. The Expert applies memoization (caching) to specific introspection calls, which is an algorithmic refactor to avoid repeated computation.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-23759", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, conditional fast path (`_fast_subplots`) for specific subplot configurations (large grids, no sharing) and optimizes within it by skipping `self.sca(ax)`. The Expert, conversely, implements a more systemic optimization by refactoring the core initialization of `Axis` and `Spine` objects to avoid redundant `clear()` calls, improving efficiency for all object creations.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-26164", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is to increase the size of an LRU cache and enable packrat parsing (memoization) to avoid repeated work. The Expert's optimization, however, refactors the underlying pyparsing grammar definition to make the parsing process itself more efficient, thereby lowering the cost of the hot path rather than just caching its results.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-26198", "repo": "matplotlib/matplotlib"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "matplotlib__matplotlib-26899", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's most impactful optimization in `art3d.py` is explicitly gated by the `axlim_clip=False` argument, creating a specific fast path for that condition. The expert's primary optimization in `axes3d.py` and secondary optimization in `transforms.py` are general algorithmic refactors that apply broadly without such specific guards.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-29399", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a hardcoded fast path for a single, specific `einsum` pattern, which is a pattern-specific hack. The Expert, conversely, makes a systemic change by altering the default behavior of the `einsum` function's `optimize` argument, thereby avoiding the overhead of the general path-finding algorithm for many cases.", "confidence": 1.0, "instance_id": "numpy__numpy-11720", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a pattern-specific fast path within the `numpy.hstack` function. In contrast, the Expert implements a structural redesign by adding an early-exit fast path to NumPy's `__array_function__` dispatch mechanism, providing a more systemic optimization.", "confidence": 0.9, "instance_id": "numpy__numpy-12321", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for specific input characteristics (many named arrays) to optimize array construction. The Expert, conversely, performs a systemic algorithmic refactor of an internal helper function (`find_duplicate`), reducing its complexity from O(N^2) to O(N) for all callers, which is a more fundamental improvement.", "confidence": 0.9, "instance_id": "numpy__numpy-12575", "repo": "numpy/numpy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes a heuristic that skips a `find_duplicate` check for field names if `_nfields >= 1000`, which is a potentially risky semantic change that could hide errors. The expert's patch, conversely, performs an algorithmic refactor to avoid an expensive string concatenation, explicitly preserving all original behavior.", "confidence": 0.9, "instance_id": "numpy__numpy-12596", "repo": "numpy/numpy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a highly specific fast path that completely bypasses the execution of the user-provided `pad_with` function, hardcoding its assumed behavior based on its name and kwargs, which risks altering semantics for slightly different implementations. In contrast, the expert's optimization preserves the execution of the user-provided function but optimizes its invocation by avoiding intermediate copies, thus maintaining documented behavior.", "confidence": 0.9, "instance_id": "numpy__numpy-13250", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path based on object identity (`tup[0] is arr`) to optimize a specific input pattern. The Expert, in contrast, applies a more systemic refactor by changing argument unpacking (`atleast_Nd(*tup)`) to generally reduce Python function call overhead for any multiple inputs, rather than a specific data pattern.", "confidence": 0.9, "instance_id": "numpy__numpy-13697", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized 'fast path' with a narrow guard for a specific input pattern (median of a 1D array), applying an algorithmic improvement only for that case. The expert, conversely, implements a more general micro-optimization by removing a redundant `np.moveaxis` call, which improves the efficiency of the existing general code path for all `axis=0` scenarios.", "confidence": 0.9, "instance_id": "numpy__numpy-18203", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path triggered by hardcoded array dimensions (size 1001) and data types, essentially a pattern-specific hack. The Expert, in contrast, makes a systemic improvement by replacing a less efficient general-purpose array operation with a more optimized primitive (`np.take`) within a helper function, benefiting a broader range of inputs.", "confidence": 0.9, "instance_id": "numpy__numpy-18324", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple specific fast paths and micro-optimizations for common input patterns (e.g., `if type(line) is not bytes`, `try: float(x)`). The Expert performs a systemic refactor by hoisting nested helper functions to the module level, eliminating repeated function/closure creation and decorator overhead, which is a deeper structural change.", "confidence": 0.9, "instance_id": "numpy__numpy-19599", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimizations involve increasing a chunk size, hoisting a check out of a loop, and adding a conditional fast-path to skip a string method. The Expert's optimization replaces a general, less efficient regular expression-based comment stripping with a more performant, specialized string-based method, which is an algorithmic refactor for the hot path.", "confidence": 0.9, "instance_id": "numpy__numpy-19601", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies several micro-optimizations and fast-paths (e.g., increased chunk size, single comment fast path, local function caching, conditional string lowercasing). The Expert, in contrast, implements a more systemic algorithmic refactor by pre-binding packing logic with `functools.partial` and introduces highly optimized, specialized packing functions (`itemgetter(0)` or no-op lambdas) for common cases, fundamentally improving the data packing mechanism.", "confidence": 0.9, "instance_id": "numpy__numpy-19608", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies several targeted micro-optimizations and a specific fast-path for comment handling. The Expert, however, implements a systemic refactoring by redesigning the data flow, hoisting the entire line processing (splitting, stripping) out of the inner loop into an efficient, C-implemented iterator pipeline.", "confidence": 0.9, "instance_id": "numpy__numpy-19609", "repo": "numpy/numpy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global cache for `StringIO` objects to avoid re-reading and re-splitting lines on repeated calls. The Expert, instead, optimizes the column selection within the hot loop by replacing a Python list comprehension with the C-optimized `operator.itemgetter`, thereby lowering the cost of the core operation itself rather than caching its results.", "confidence": 1.0, "instance_id": "numpy__numpy-19618", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes a 'specific fast-path' for string splitting with a common delimiter. The Expert's patch refactors the type conversion pipeline by replacing less efficient NumPy utility functions with more direct and optimized Python built-ins, which constitutes an algorithmic refactor of the conversion process.", "confidence": 0.9, "instance_id": "numpy__numpy-19620", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast paths for scalar and matrix inputs, along with minor micro-optimizations. The Expert, however, fundamentally refactors the core `kron` algorithm to leverage NumPy's broadcasting, which is a systemic algorithmic improvement that eliminates large intermediate arrays and complex transpositions.", "confidence": 0.9, "instance_id": "numpy__numpy-21354", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to reduce Python overhead and leverage native code for dot products. However, the LM's approach is deeper, replacing multiple operations and potential temporary arrays with a single, highly optimized C-implemented `vdot` call, which is a more systemic improvement. The Expert's optimization is a more minor micro-optimization, switching from `numpy.dot` to `ndarray.dot` and caching attribute lookups.", "confidence": 0.9, "instance_id": "numpy__numpy-21394", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations within `np.linspace` to reduce Python overhead and NumPy function calls for common cases. The expert's approach is broader, addressing two distinct micro-optimizations (avoiding `issubdtype` when `dtype=None` and optimizing `_nx.any` for scalar `step`), whereas the LM's focuses on a single, albeit more extensive, rewrite of the core calculation for scalar inputs.", "confidence": 0.9, "instance_id": "numpy__numpy-21832", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The expert's optimization (`q.min()` and `q.max()`) is an algorithmic refactor that fundamentally changes the validation approach to avoid intermediate array allocations. The LM's change (`np.all((0 <= q) & (q <= 1))`) is a micro-optimization that relies on ufunc fusion to make existing element-wise operations more efficient, which is a less systemic improvement compared to eliminating intermediate allocations entirely.", "confidence": 0.9, "instance_id": "numpy__numpy-24610", "repo": "numpy/numpy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation describes an algorithmic refactor of the `equal_nan=True` logic, while the Expert's focuses on adding specific fast paths and removing micro-overhead. Neither the 'Shortcut_vs_Systemic' nor 'SameStrategy_DepthGap' rules are met as defined, as the LM's change is arguably more systemic/deeper in one aspect.", "confidence": 0.9, "instance_id": "numpy__numpy-24663", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an early-exit fast path for empty coefficient arrays. However, the LM's patch implements this check *before* NumPy array conversion, avoiding the overhead of `np.array` creation, whereas the Expert's patch implements it *after* conversion, avoiding only the `min()` call and intermediate list creation. The LM's approach is a deeper optimization for the same condition.", "confidence": 0.9, "instance_id": "numpy__numpy-25299", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path for a specific 2D array case within `tensordot`. The Expert, conversely, applies a systemic micro-optimization within the general `tensordot` logic by replacing Python loops and NumPy reductions with the C-implemented `math.prod` function, improving the general product calculation.", "confidence": 0.9, "instance_id": "numpy__numpy-25788", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both optimizations target the overhead of temporary NumPy array creation in `broadcast_shapes`. The LM introduces a conditional fast path that completely bypasses array creation by reimplementing the logic in pure Python for a subset of inputs. The Expert's solution is broader, applying to all inputs by using a special NumPy dtype to ensure temporary arrays allocate zero memory for their data buffers, thus making the existing array creation path more efficient.", "confidence": 0.9, "instance_id": "numpy__numpy-26599", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for large arrays, switching to a specialized, vectorized implementation of the recurrence. The expert, however, applies a micro-optimization by reordering arithmetic operations within the existing general recurrence to reduce array operations and temporary allocations, improving the systemic efficiency of the original algorithm.", "confidence": 0.9, "instance_id": "numpy__numpy-27830", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized algorithm as a fast path for a specific input data pattern (duplicate ambiguous timestamps). The Expert implements a more systemic optimization by introducing an early exit that completely bypasses the complex localization logic when the target timezone is already UTC, a fundamental and general case, and generalizes this check across multiple methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-23772", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a memoization cache for scalar equality comparisons. The Expert's optimization is an algorithmic refactor (fastpath) within the Categorical constructor, which is a different strategy and is explicitly stated to be unaligned with the given workload.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-23888", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, explicit fast path with a series of specific checks and a direct `np.array_equal` call. The Expert, in contrast, performs an algorithmic refactor by delegating the comparison to the already specialized `equals` method of the underlying `Categorical` object, which is a more systemic approach within the pandas object model.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-24023", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's `factorize` optimization for `PeriodIndex` is potentially risky as it effectively ignores the `sort` parameter and assumes the input is already sorted and unique, which could lead to incorrect results if `factorize` is called with unsorted data. The expert's solution, by contrast, provides a mechanism (`_values_for_argsort`) that enables efficient and semantically correct sorting of `PeriodArray` instances.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-24083", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["AnalyticalDepth", "HotspotAnalysis"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "rationale": "Both explanations describe micro-optimizations leveraging native code, fitting the 'same tactic family'. However, the Expert's explanation demonstrates a deeper analytical understanding by explicitly identifying that its own patch, while a valid optimization, does not apply to the specific workload's hotspot, a level of self-critique and workload alignment analysis not present in the LM's explanation.", "confidence": 0.75, "instance_id": "pandas-dev__pandas-24308", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast paths and guards for common cases (e.g., early exit for `timedelta`, `_hasnans` check to bypass complex logic). The Expert, however, implements a systemic algorithmic refactor by vectorizing a critical `searchsorted` operation in Cython, transforming N individual calls into a single, highly optimized array operation.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-24491", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path guard in two specific functions (`nanany`, `nanall`). The Expert, in contrast, performs a systemic refactor by introducing a new helper function (`_maybe_get_mask`) and modifying a central utility (`_get_values`) to conditionally avoid mask computation and memory allocations for boolean/integer dtypes, benefiting a broader set of `nanops` functions.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-25070", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply micro-optimizations to avoid unnecessary work. The LM uses a fast-path, caching, and a minor overhead removal. The Expert also uses micro-overhead removal, but targets a deeper and more expensive internal Matplotlib tick creation process, making its impact more significant within the same strategy family.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-25665", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply an algorithmic refactor to avoid the overhead of creating a MultiIndex for monotonicity checks. However, the Expert's solution is deeper, implementing the core logic directly in Cython using NumPy's lexsort and a Cython `is_monotonic` function, whereas the LM's solution remains at the Python level, delegating to existing `Index` methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-25820", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a class-level cache to reuse expensive `groupby` objects, avoiding their repeated creation. The Expert, conversely, refactors the internal `_get_grouper` logic to eliminate redundant computations and Python overhead when `level` is specified, thereby lowering the inherent cost of the hot path itself rather than caching its results.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-25953", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for a specific mapper type, explaining the benefit as avoiding generic Python overhead. The Expert also introduces a fast path, but explicitly frames the underlying optimization as an 'Algorithmic Improvement' by mapping categories instead of all values, which is a more systemic refactor of how categorical data is processed.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26015", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert replace the inefficient `MultiIndex` delegation with a direct, NumPy-based uniqueness check. However, the Expert's solution is deeper, incorporating a highly effective early exit (`left.is_unique or right.is_unique`) and a more targeted duplicate check that only iterates over indices with duplicated `left` values, making it more efficient for the workload's sparse duplicates.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26391", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a fast path that reorders Python-level conditional checks to reduce bytecode execution. The Expert's optimization, while also a fast path, is more systemic, structurally redesigning the input to `np.sum` to avoid intermediate list allocations and redundant string concatenations, thereby reducing actual work.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26605", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same core optimization: converting NumPy integer keys to native Python integers to reduce type conversion overhead. However, the expert's solution is more integrated, applying the conversion directly within the existing `is_integer` check and also extending it to `__getitem__`, whereas the LM introduces a new, separate conditional fast path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26697", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a `sys._getframe` check to return `int` objects instead of `Timestamp` objects, fundamentally altering the behavior of `DatetimeIndex.__iter__` for a specific caller. The expert's solution, conversely, preserves the documented behavior by delegating to a more efficient, specialized internal array iterator.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-26702", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the fundamental behavior of `IntervalIndex.intersection` from finding overlapping intervals to finding identical intervals by using set intersection of `(left, right)` tuples. The Expert's optimization preserves the correct semantics by intelligently reordering operands to utilize an existing, more efficient `_intersection_unique` algorithm.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-26711", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a micro-optimization by refactoring a functional chain into an explicit loop to reduce Python interpreter overhead. The Expert, however, implements a more systemic algorithmic refactor by using a specialized internal API to avoid redundant data copying and validation when constructing `CategoricalIndex` objects.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26721", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for a specific data format (ISO dates) using heuristic checks and caching. The Expert, however, performs a more systemic algorithmic refactor by replacing an expensive DataFrame transpose operation with a direct, optimized constructor for a specific data orientation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26773", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's optimization is a systemic algorithmic refactor of the core `SparseDataFrame` construction, while the Expert's is a micro-optimization of a type check, which the expert notes could have negligible impact for the workload's primary path. The rubric's categories and mapping rules do not directly cover this scenario where the LM performs the systemic improvement and the Expert's change is potentially misdirected or a minor shortcut, leading to no direct rule match.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-26776", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific override for `MultiIndex.shape` and adds caching, which is a fast-path for that class. The Expert performs a systemic refactor by moving the efficient `shape` property to the base `Index` class, making it the default for all subclasses.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27384", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path specifically for slice-based indexing on `CategoricalIndex` using an `isinstance` check. The Expert, however, applies an algorithmic refactor to the `CategoricalDtype.__eq__` method, introducing an early exit based on `categories.equals` to avoid a more expensive hash computation, which is a more systemic improvement to the comparison logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27448", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces caching for `is_monotonic_increasing` and `is_monotonic_decreasing` properties, along with algorithmic refactoring. The Expert, instead of caching, lowers the cost of the computation itself by introducing a fast path that leverages native code (`libalgos.is_lexsorted`) operating on efficient integer codes.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-27495", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path that re-implements the binning logic using NumPy for specific input characteristics (non-overlapping IntervalIndex, large array). The Expert, conversely, performs a systemic refactor by replacing an inefficient two-step object creation with a single, more direct, and memory-efficient constructor (`Categorical.from_codes`), improving the general case for IntervalIndex bins.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27669", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific caching mechanisms and fast paths for common replacement patterns (e.g., infinities), which are pattern-specific hacks. The Expert, however, implements a more systemic algorithmic refactor within the `Block.replace` method by filtering `to_replace` values based on the block's `dtype` compatibility, leading to early exits or delegation to more efficient scalar paths, thus improving the general handling of type mismatches.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-28099", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization focuses on micro-optimizations within the existing Python-level iteration loop, such as reducing function call overhead and using NumPy arrays for intermediate steps. The Expert's optimization, however, introduces an algorithmic refactor by first identifying unique dtypes and then leveraging highly optimized, vectorized Pandas/NumPy operations (`.unique()`, `.isin()`) to avoid the explicit Python loop over all columns entirely.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-28447", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an early-exit fast path optimization. The LM's fast path is a generic length check, whereas the Expert's fast path is a more specific and nuanced check involving `nlevels`, `isinstance`, and `is_object_dtype` that leverages deeper domain knowledge of `MultiIndex` equality rules.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-29134", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a cache but explicitly comments out existing tests in the diff, stating they are 'expected to fail' with the change, indicating a potential alteration of behavior or correctness. The expert's optimization, in contrast, is a micro-optimization that preserves documented behavior by replacing a property access with a direct attribute access.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-29469", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization introduces an instance-level cache to memoize category lookups. In contrast, the Expert's optimization is an algorithmic refactor that conditionally skips redundant NaN-handling operations for specific comparison operators, thereby lowering the hotspot by avoiding unnecessary work without caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-29820", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a complex custom `LazyRangeArray` subclass to defer materialization for `range` objects, which acts as a specialized 'fast path' or 'pattern-specific hack'. The Expert, conversely, applies a more systemic 'vectorization' by directly using the highly optimized `np.arange` function to efficiently materialize the array, which is a cleaner algorithmic refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30171", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces new `elif` branches as dedicated 'fast paths' for list and NumPy array keys, re-implementing indexing logic. The Expert applies a systemic algorithmic refactor by performing an early `np.asarray` conversion, allowing the existing, more general indexing logic to benefit from NumPy's efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30747", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional 'fast path' for specific input patterns (evenly spaced quantiles) that replaces a Python loop with vectorized NumPy operations. The expert performs an algorithmic refactor to reduce object allocations and avoid an expensive append operation in a more general part of the label formatting logic. The LM's approach is a pattern-specific shortcut, while the expert's is a structural improvement to the existing algorithm.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30768", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a new `_ndarray_values` property to `IntervalArray`, which changes the behavior of `getattr(idx, '_ndarray_values', idx)` from returning the default `idx` to returning a computed NumPy array. The expert's patch, in contrast, preserves the existing semantics of `_ndarray_values` on `IntervalIndex` by moving its delegation to a cached mechanism, without altering its fundamental behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-30797", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism (`_cached_array`) to avoid recomputing the `.array` property on subsequent accesses. The Expert, conversely, refactors the underlying implementation of the `.array` property to use polymorphic dispatch, eliminating runtime type checks and conditional branching, thereby making the computation inherently faster for all accesses without needing a cache.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-31037", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["GranularOptimization"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same core optimization: avoiding unnecessary data copies in `fill_binop` when no NaNs are present. However, the expert's patch implements this with more granular, independent conditional checks for `left` and `right` copies, making it more robust and efficient in cases where only one operand has NaNs. The LM's patch uses a single, broader conditional for both copies, which is less optimal.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-31300", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and aim to optimize the check for whether a float is an exact integer. The LM's approach is a shallower micro-optimization of the comparison logic after an expensive `int()` conversion, while the Expert's approach is a deeper optimization that replaces the costly `int()` conversion and comparison with the more efficient `float.is_integer()` method, avoiding the creation of an arbitrary-precision integer object for the check.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-31409", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization bypasses the `Index` object's `__init__` method and directly sets internal attributes (`_data`, `_index_data`) after using `object.__new__`. This direct manipulation of internal state, while potentially faster, carries a higher risk of subtle semantic issues or breaking invariants compared to the expert's approach. The expert's patch, conversely, safely reduces Python call overhead by removing a redundant `super()` call within a standard object construction path, explicitly preserving documented behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32130", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["micro-optimization", "python-object-model"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the hotspot and the optimization strategy: removing redundant `__init__` calls by directly creating an uninitialized object. The expert's explanation uses `object.__new__(cls)`, which is a slightly more canonical and robust way to obtain an uninitialized object compared to the LM's `cls.__new__(cls)`, indicating a marginally deeper understanding of Python's object model for this specific optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32821", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe similar core optimization strategies (algorithmic refactor, micro-overhead removal, leveraging native code). However, the Expert's explanation is deeper and broader, detailing changes across multiple files (e.g., `_libs/sparse.pyx` for `IntIndex` and `DataFrame._from_arrays`) and explicitly explaining the safety mechanisms (pre-sorting to skip integrity checks), which the LM's explanation omits.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32825", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for a specific input pattern (many SparseArrays) by adding a conditional block and consolidating them. The Expert, however, performs a systemic refactor of the BlockManager's core consolidation logic, replacing expensive string operations with cheaper dtype object comparisons, which is a more general algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32826", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast-path for a specific input pattern (many homogeneous SparseArrays) and adds caching. The Expert, conversely, implements a systemic, lower-level optimization by directly handling integer placements in Cython, reducing Python object overhead for any single-column block, which is a more general improvement to the core machinery.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32856", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path to copy a specific internal engine (`_engine`) during a shallow copy. The Expert, however, performs a more systemic refactoring of the `MultiIndex.copy` method to delegate to `_shallow_copy`, which then comprehensively copies the entire internal `_cache`, ensuring all pre-computed structures are reused.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32883", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and use algorithmic refactoring to avoid the expensive `_interleave()` call. However, the LM optimizes the code *within* the `if not items.is_unique` conditional branch, while the Expert completely *removes* this branch, indicating a deeper understanding that the general path is sufficient and more efficient, thus simplifying the control flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-33032", "repo": "pandas-dev/pandas"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pandas-dev__pandas-33324", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path guard and vectorized NumPy comparison for `is_monotonic_increasing` on categorical data. The Expert, in contrast, performs a more systemic optimization by ensuring the underlying `Categorical` object is constructed in its most canonical and efficient internal representation, which benefits all subsequent operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-33540", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `window=2` using vectorized NumPy operations. The Expert, however, implements a systemic algorithmic refactor by reordering data for cache locality and introducing a specialized indexer, improving the general `groupby().rolling()` mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34052", "repo": "pandas-dev/pandas"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pandas-dev__pandas-34178", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path/early-exit for already-sorted indices, bypassing the main sorting algorithm for a common pattern. The Expert, in contrast, removes a systemic overhead by eliminating a redundant data copy operation that occurs during the preparation phase for sorting when no key function is provided, which is a more fundamental improvement to the sorting infrastructure.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34192", "repo": "pandas-dev/pandas"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pandas-dev__pandas-34199", "repo": "pandas-dev/pandas"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pandas-dev__pandas-34354", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path triggered by exact values ([np.inf, -np.inf, 1] to np.nan), which is a pattern-specific hack. The Expert, conversely, implements a more systemic optimization by refactoring Block.putmask to avoid a redundant array copy when inplace=False and a dtype upcast occurs without actual value changes, improving a general data handling inefficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34737", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path within `Categorical.map` for dictionary mappers, specifically optimizing for one-to-one mappings by operating on categories instead of elements. The Expert, conversely, implements a micro-optimization for dictionary key/value extraction in `Series._init_dict`, a more fundamental change that improves the general efficiency of Series construction from dictionaries, which `Series.map` can then leverage.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34948", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["FastPath", "Vectorization", "LoopInvariantCodeMotion"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a functional change, altering the output type from a pandas.Series to a pandas.DataFrame for the specific lambda pattern it optimizes. The expert's patch, however, preserves the original behavior while optimizing by moving a loop-invariant context manager out of the hot loop.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-35166", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a simple length check fast-path and a hash caching mechanism. The Expert, in addition to similar early exits, fundamentally refactors the comparison logic for non-object dtypes by leveraging a highly optimized, vectorized `get_indexer` method, which is a more systemic algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36280", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path with a *sampled* check to bypass full type verification, which is a heuristic shortcut. The Expert, in contrast, makes a systemic change by refining conditional logic to avoid a redundant and expensive `lib.infer_dtype` call when the target dtype is already known to be string-like.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36317", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces conditional 'fast paths' with early exits to bypass an expensive element-wise loop if the input is already an array of strings. The Expert, conversely, performs a structural redesign of the object instantiation by bypassing the `__init__` method to eliminate redundant validation, which is a more systemic removal of overhead.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36325", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's fast path is conditioned on the input array already being a Unicode NumPy array (`values.dtype.kind == \"U\"`), but the workload's input is an `object` dtype array. The LM's explanation relies on a hypothesis of an intermediate conversion that would make its fast path active, which is not directly supported by the expert's analysis or the patch. The expert's patch, however, directly targets the conversion from `object` dtype to string dtype, which is the actual hotspot for the workload.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36432", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["LM not triggered", "Expert targets memory/copy overhead"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states its introduced fast paths are not triggered by the workload's DataFrame size (1,000,000 rows vs. > 1,000,000 condition), making its optimization unaligned with the hotspot. In contrast, the expert's changes directly target and optimize the measured hotspot by eliminating expensive data copies and improving slicing efficiency.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-36638", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, optimized Cython implementation and corrects a dispatch error, representing a systemic algorithmic and native code optimization. The Expert removes a Python-level dynamic dispatch overhead. Neither explanation fits the specific 'LM is worse than Expert' patterns defined in the rubric's categories, and the 'SameStrategy_DepthGap' rule is inverted.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36872", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces extensive caching (memoization) for intermediate results and prepared data within the `Expanding` and `ExpandingGroupby` classes. The expert's optimization, however, refactors the core `ExpandingGroupby` implementation to eliminate redundant `groupby.apply` dispatch and reduce Python overhead, thereby lowering the cost of the hot path itself rather than caching its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-37064", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for integer DataFrame.sum() that directly calls NumPy's optimized sum, bypassing generic Python logic. The Expert, conversely, refactors the general `_reduce` method to reduce redundant iterations and Python overhead for dtype checks, improving efficiency for all reduction operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37118", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a `ValueError` when comparing `RangeIndex` objects of different lengths, which alters the documented behavior of `__eq__`. The Expert's optimization, by contrast, correctly handles various comparison operators and falls back to the superclass method for non-fast-path cases, preserving the original semantics.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-37130", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for a specific `SeriesGroupBy.fillna` method, bypassing the general `groupby` application logic. The Expert, however, optimizes the existing internal reindexing logic within `groupby.py` by adding a condition to avoid expensive, redundant operations and unnecessary data copies, which is a systemic improvement to the general case of that reindexing.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37149", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for integer dtypes within `nansum` to bypass NaN-handling logic. The Expert performs a more systemic refactor in `DataFrame._reduce` by removing redundant calculations and correcting conditional logic to avoid an inefficient or semantically incorrect code path for numeric data.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37426", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a class-level cache to memoize the base `__dir__` results. In contrast, the Expert refactors the `_dir_additions` logic to conditionally skip an expensive `unique()` computation for non-string indices, effectively removing the hotspot for the specific workload rather than caching its result.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-37450", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path based on a narrow object identity check (`self._values is other._values`), which is a specific shortcut. The Expert introduces a fast path based on a more robust semantic equivalence check (`self.is_(other)`) in a base class (`NumericIndex`) and refactors a subclass (`RangeIndex`) to use it, representing a more systemic and robust change.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37569", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, conditional fast path at the `Series.fillna` API level to bypass general logic for specific inputs. The Expert, conversely, makes a systemic improvement by replacing a less efficient NumPy operation with a more performant one (`np.putmask`) within a low-level internal utility (`_putmask_simple`) that is used broadly by block operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37945", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization sorts `IntervalArray`s only by their left bounds, which is a semantic simplification and potentially alters the sort order for intervals with identical left bounds. The Expert's solution correctly implements a full lexicographical sort using `np.lexsort` on both left and right bounds, preserving the expected behavior while optimizing performance.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37971", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its patch does not benefit the provided workload because the optimized code path is not exercised and the data lacks NaNs. The Expert's explanation, however, clearly identifies and optimizes a hotspot (`searchsorted` for `DatetimeIndex`) that is directly invoked by the workload's `s.asof(date)` operation.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-38103", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path to avoid a `value.copy()` operation for a specific 2D NumPy array assignment. The Expert performs an algorithmic refactor, replacing an inefficient Python loop for adding columns one-by-one with a single, vectorized `reindex_axis` call on the internal BlockManager, which is a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38148", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path within a generic `isin` function, directly implementing vectorized NumPy operations. The Expert, however, performs a more systemic refactor by dispatching `isin` to a specialized method on `IntervalArray` itself, which then leverages a novel `complex128` view of combined interval bounds for highly efficient `np.in1d` checks, representing a deeper algorithmic and data-structure-level optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38353", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path with hardcoded size thresholds (`len(comps) > 1_000_000 and len(values) <= 26`) for `IntegerArray`. In contrast, the Expert performs a systemic refactor by introducing a general `isin` method on `BaseMaskedArray` and refining the dispatch mechanism for all ExtensionArrays, providing a broader, more general improvement.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-38379", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM adds a specific `isinstance` fast-path check within `RangeIndex.equals` for `MultiIndex`. The Expert, conversely, refactors the dispatch logic in the base `Index.equals` to correctly route comparisons involving `MultiIndex` to its specialized method, representing a more systemic improvement to the comparison hierarchy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38560", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path within `_get_indexer` by directly comparing underlying `int64` values to avoid `tz_convert` overhead. The Expert, in contrast, implements a more systemic refactoring by centralizing timezone standardization (via `tz_convert(\"UTC\")`) in a general utility (`_maybe_promote`) and removing redundant conversion calls from other methods, representing a structural redesign of timezone handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-39332", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by refactoring Python-level calls to `Rolling` objects to reduce redundant instantiations and method calls. The Expert, however, implements a systemic change by replacing these Python-level computations with direct calls to highly optimized, low-level `window_aggregations` functions, which are typically implemented in Cython or C, moving the core computational loop to a compiled layer.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-39388", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Parallelization", "Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes the existing Python `groupby.apply` mechanism by introducing Numba JIT compilation, aggressive Numba settings, and caching, and adds a specific fast path for `var`/`std`. In contrast, the Expert performs a systemic algorithmic refactor by eliminating the Python `groupby.apply` overhead entirely and moving the group iteration into batched Cython functions, fundamentally changing how groups are processed.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-39664", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is to add memoization (caching) to the `Styler.render()` method. The expert, however, optimizes the underlying `_translate` method by replacing slow Python-level `iloc` access with the faster, C-backed `DataFrame.itertuples()` iteration, effectively lowering the cost of the hot path itself rather than caching its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-39972", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizing the `json_normalize` function for nested data. The LM optimizes an existing, general-purpose flattening function by removing an expensive `deepcopy`. The Expert, however, introduces a new, simpler, and specialized algorithm and a conditional fast-path dispatch to use it for the most common, basic use cases of `json_normalize`, representing a broader architectural change.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40035", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["AlgorithmicRefactor", "CodeUnification"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the O(N^2) to O(N) algorithmic improvement for time-weighted EWMA. However, the expert's solution is broader, involving the removal of the `ewma_time` function and unifying its functionality into the existing `ewma` function, along with changes in the dispatch logic in `ewm.py`. The LM's solution only modifies `ewma_time` in place.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40072", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations include 'Micro-OverheadRemoval' in their strategies. The LM applies micro-optimizations to speed up individual function lookups and memory allocation. The Expert's 'Micro-OverheadRemoval' (refactoring to a module-level function) enables a broader and deeper optimization through caching, which eliminates repeated lookup overhead entirely for subsequent calls.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-40178", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path within `ArrayManager.isna` for float/complex NumPy arrays, directly calling `np.isnan`. The Expert performs a more systemic refactor of the core `_isna` utility function, removing redundant Python overhead (attribute lookups, type checks) from its inner array-processing logic, which benefits all callers, including `ArrayManager.isna`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40254", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new fast path for dense data using NumPy operations, bypassing the general Cython function for a specific case. The Expert, in contrast, applies systemic optimizations like object freelisting, direct attribute assignment for `Categorical` creation, and stronger Cython typing for array indexing, which improve the general performance of core pandas components.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40339", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path to bypass Kahan summation for NaN-free data, which is a specific shortcut. The Expert performs a systemic refactor of the core `take` operation, replacing `numpy.take` with a Cython-optimized pandas implementation and removing redundant work, representing a broader algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40818", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes `dta.T` with a narrow fast-path (`return self`) specific to 1D arrays and `dta.copy()` with micro-optimizations. The Expert, in contrast, implements a systemic refactor by introducing a Cython base class (`NDArrayBacked`) and migrating both `copy()` and `T` to Cython, leveraging NumPy C API calls for general, lower-level performance gains across a broader set of array types.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-40840", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Neither the LM nor Expert's optimization strategies align with the specific conditions required by the rubric's classification rules. The LM performs a systemic Cython compilation, while the Expert adds a fast-path guard to skip redundant work, which inverts the expected roles for 'Shortcut_vs_Systemic' and does not meet the 'Expert is deeper' condition for 'SameStrategy_DepthGap'.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41567", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'fast path' for boolean Series without NaNs, short-circuiting generic logic and directly calling NumPy. The Expert, conversely, performs a more systemic algorithmic refactor by eliminating an unnecessary large memory allocation in a core utility function (`_maybe_get_mask`) that was always occurring for boolean/integer dtypes, regardless of specific fast-path conditions.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41911", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path guard to directly call NumPy's `all()` for boolean Series without NaNs. The Expert, in contrast, implements a more systemic optimization by refactoring the internal `nanops` functions to avoid unnecessary memory allocations and array summations for boolean/integer dtypes, improving the general handling of null masks within the subsystem.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41924", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path for a specific `loc` pattern (single-element integer key on `UInt64Index`). The Expert implements a systemic algorithmic refactor in the core `_maybe_promote` method to efficiently handle type promotion between `UInt64Index` and non-negative `Int64Index` for broader applicability.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41972", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path that detects a specific 'shifted by 1' pattern in `IntervalIndex.intersection` and performs an early exit. The Expert, however, implements a systemic improvement by replacing generic deduplication with a new `IntervalArray.unique` method that leverages C-implemented hash tables for complex numbers, fundamentally optimizing the underlying unique operation for `IntervalIndex`.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-42197", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized fast-path (`if isinstance(other, type(self))`) for `IntervalIndex.intersection` and optimizes within it using NumPy. The Expert, conversely, identifies and disables an existing suboptimal fast-path for `IntervalIndex` in the base class and introduces a systemic data representation change (using tuples instead of `Interval` objects) to make the general intersection algorithm more efficient for `IntervalIndex`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42268", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path for small list-like inputs (len <= 10) using Python list comprehensions. The Expert, however, implements a systemic algorithmic refactor by leveraging the internal integer codes and a specialized engine for `CategoricalIndex` lookups, converting expensive string operations to efficient integer operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42270", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'fast path' with an early exit for the subset case, which is a pattern-specific hack. The Expert, however, performs a structural redesign by removing redundant object allocations and type conversions in the general `_union` method, improving its efficiency for all cases.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42353", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces conditional fast paths within `DataFrame.to_dict` to bypass certain operations for specific data types, acting as a pattern-specific hack. The Expert, however, optimizes a fundamental, lower-level utility function (`maybe_box_native`) by reordering type checks, providing a systemic improvement to scalar boxing that benefits all its callers.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42486", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'fast path' for a narrow input pattern (single string `exclude`) within `select_dtypes`. The Expert, conversely, performs an algorithmic refactor by delegating column filtering to the internal data manager (`_get_data_subset`), leading to a more systemic improvement in how column selection is handled.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42611", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces narrow fast paths specifically for `Int64` arrays. The Expert, conversely, applies more systemic optimizations by removing general runtime assertions, streamlining block instantiation for various types, and adding caching for a common block property, which improves the general case of DataFrame construction.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42631", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'fast path' with a narrow guard (`if all_true`) directly within a Cython loop to bypass null-handling logic. The Expert, conversely, implements a more systemic refactor by propagating an `allow_fill` flag through the pandas internal block management system, enabling a lower-level, already optimized `take` method to use its more efficient path when no fills are needed.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42704", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch modifies `pytest` configuration, which is entirely unrelated to the `pandas.Series.isin` benchmark, thus having no impact on the workload. The expert's patch, however, directly optimizes a critical array creation step within the `isin` method for nullable dtypes, which is the measured hotspot of the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-42714", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations leverage Cythonization to optimize `groupby().any()/all()` operations. However, the Expert's approach is deeper, modifying the Cython function to accept 2D arrays and refactoring the Python dispatch to send multi-column data in a batched manner, significantly reducing Python-to-Cython overhead. The LM's approach primarily enables Cython dispatch for these operations, likely on a per-column basis.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42841", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a heuristic to trigger an existing consolidation mechanism more frequently based on block count. In contrast, the Expert performs a systemic refactor by Cythonizing core array manipulation logic within the `insert` operation and adding specialized fast paths for common insertion scenarios, fundamentally improving the underlying algorithm.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-42998", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific `isinstance` guard for `pandas.Series` within the `mad` method, creating a fast path that directly uses NumPy arrays to avoid intermediate `Series` objects. In contrast, the Expert introduces a new method in the internal `BlockManager` to systemically optimize how numeric data is retrieved, avoiding unnecessary copies at a lower, more fundamental level of the pandas data structure.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43010", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces fast paths and caching for specific data patterns (constant or few unique deltas) within the EWMA calculation. The Expert, however, performs a more systemic algorithmic refactor by recognizing when time data is entirely absent (`self.times is None`) and simplifying the core EWMA calculation to avoid unnecessary exponentiation altogether.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43052", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["FastPath", "Vectorization", "MemoryOptimization"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces several fast-paths (e.g., conditional date conversion, early-exit for categoricals) for specific data scenarios. The Expert's patch, however, focuses on more systemic optimizations by leveraging direct NumPy array operations (`._values`) and explicitly avoiding data copies (`copy=False`), which fundamentally lowers the overhead of data processing.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43059", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path that explicitly changes the semantic behavior of `groupby().apply()` by returning the original DataFrame instead of a new, copied, and potentially re-indexed one. The expert's optimizations, conversely, preserve documented behavior by refactoring internal type-checking utilities to reduce Python overhead.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43073", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert introduce fast paths for `to_numpy()` on mixed-type DataFrames resulting in `object` dtype. However, the LM's fast path optimizes the *type inference* step (`find_common_type`), while the Expert's fast path optimizes the *actual array construction* by using a more direct data extraction method (`blk.get_values`) for `ExtensionArray`s within the `_interleave` method, which is a deeper and more impactful optimization for data movement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43160", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's effective optimization for the workload is a fast path that directly calls Cython functions, reducing Python call overhead. The Expert's optimization is a systemic refactor that changes the internal data processing strategy from block-wise ArrayManager application to direct column iteration, reducing abstraction overhead.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43171", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations involve strategies like FastPath/SpecialCase and Micro-OverheadRemoval. The Expert's change is deeper and safer by targeting a fundamental Python overhead (expensive `CategoricalDtype.__eq__` comparisons) in a core grouping function, making it a more robust micro-optimization compared to the LM's more complex, specific-case block consolidation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43237", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a systemic optimization by rewriting the core `groupby().skew()` computation in highly optimized Cython. The Expert performs a micro-optimization by conditionally skipping irrelevant Python-level dtype checks in a shared internal method. The provided categories do not directly capture this specific difference where the LM's solution is a more fundamental, lower-level rewrite compared to the expert's overhead removal.", "confidence": 0.6, "instance_id": "pandas-dev__pandas-43243", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["RoleReversed"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "rationale": "The expert's explanation explicitly identifies that their patch is misdirected and does not affect the workload's execution path. In contrast, the LM's explanation describes a systemic optimization that is directly aligned with the workload's bottleneck, making the primary difference about hotspot alignment, albeit with the roles reversed from the category's strict definition.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-43274", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactoring and micro-overhead removal. The expert's changes focus on fundamental DataFrame management by avoiding expensive full DataFrame copies and re-creations, which is a deep optimization for memory and data flow. The LM also includes similar algorithmic refactoring but additionally introduces vectorized/C-optimized operations for element-wise processing, making its strategy broader but the expert's potentially deeper in terms of core DataFrame integrity and memory management.", "confidence": 0.7, "instance_id": "pandas-dev__pandas-43277", "repo": "pandas-dev/pandas"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's change modifies global configuration variables (`_MIN_ELEMENTS`, `_op_str_mapping`) and adds a special case to a core expression evaluation function, broadly impacting how `floordiv` is handled by the `numexpr` subsystem. The expert's change is a local micro-optimization within a specific helper function, reducing redundant array operations without altering global behavior or configuration.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43281", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply micro-optimizations to reduce Python overhead in hot loops. The Expert's optimization is deeper, targeting the avoidance of temporary DataFrame object creation and named tuple generation during iteration, which is a more fundamental performance improvement for pandas data structures. The LM's effective optimizations are a collection of smaller constant factor improvements like local variable caching and string concatenation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43285", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `PeriodIndex` inputs to the `PeriodArray` constructor, directly reusing its internal data. The Expert, however, applies multiple micro-optimizations and algorithmic refinements to fundamental Pandas internal mechanisms (dtype equality, block storage, array extraction) that have a broader, systemic impact.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43308", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized, vectorized algorithm for large cross-merges, representing a systemic improvement. The Expert provides a micro-optimization by replacing a general-purpose column drop with a more direct, lower-overhead deletion method, which is a pattern-specific hack.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43332", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization relies on a narrow, unpredictable 'hack' of adding unused variables to subtly influence C compiler heuristics. In contrast, the Expert's approach involves systemic improvements through algorithmic refactoring (caching redundant computations) and structural redesign (avoiding an expensive DataFrame copy).", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43335", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to reduce overhead. However, the expert's patch implements deeper, more systemic changes within pandas' core BlockManager and Block internals, such as removing redundant integrity checks and array transpositions, demonstrating a more thorough understanding of the system's invariants and data flow. The LM's described changes are more focused on efficient array/list construction, and its diff does not even show the described functional changes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43352", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["Shortcut_vs_Systemic"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization uses brittle detection (function name, source code inspection) and replaces `groupby().apply()` with a direct `df.copy()`, which is `PotentiallyRisky` for semantic equivalence. The expert's change is a `Preserving` internal refactor, moving a hot helper method to Cython to reduce overhead without altering behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43353", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["shallow_copy_vs_deep_copy", "internal_optimization"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly changes a deep copy to a shallow copy for a specific function name, fundamentally altering the behavior of the copy operation. The expert's optimization, however, introduces short-circuiting logic to internal Pandas methods to speed up computation without changing the correctness or semantics of the results.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43354", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path with conditional checks for a narrow case (target is a prefix slice of self). The Expert, however, performs a systemic refactor by modifying the Cython engine to directly access MultiIndex level arrays, eliminating Python object creation and iteration overhead for a broader set of MultiIndex lookups.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43370", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies a Python-list-based, nested-loop approach within `optimized_quantile.py` as the optimization for `DataFrameGroupBy.quantile(0.5)`. This approach is likely a performance regression compared to the original Cython-optimized `np.lexsort` path. The expert, in contrast, identifies a systemic optimization that improves the efficiency of the existing Cython `np.lexsort` by hoisting it out of a per-column loop. The LM's proposed optimization is therefore misdirected in its approach and likely ineffective or detrimental.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43510", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["algorithmic_refactor", "system_design"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the `np.argsort` bottleneck. The LM performs a deeper algorithmic refactor within the `group_fillna_indexer` function, eliminating the sort entirely and achieving O(N) complexity. The Expert takes a broader approach by hoisting the `np.argsort` operation out of the per-column loop in the `_fill` method, reducing redundant work at a system level rather than redesigning the inner function's algorithm.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43518", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization bypasses the explicit `g.copy()` call by returning the original group object, which fundamentally changes the expected semantic behavior of the function. The expert's optimization, however, preserves the copy behavior while making the internal `BlockManager` copying process more efficient by avoiding redundant metadata recomputation.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43524", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for a specific case by directly constructing a DataFrame from raw series data, avoiding some Python object overhead. The Expert, in contrast, implements a systemic refactor by moving the 2D conversion logic to the internal block manager, enabling zero-copy data views and skipping integrity checks, which is a more fundamental improvement to data handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43558", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path triggered by a function's name and its observed behavior, acting as a pattern-specific hack. The Expert, however, performs a systemic algorithmic refactor within the `groupby().apply()` method, replacing an inefficient internal call with direct access to pre-computed data and vectorized operations, improving a general case.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43578", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path specifically for `MultiIndex` comparisons where internal `codes` and `levels` are *identical objects* (e.g., shallow copies). The Expert, in contrast, implements a more systemic improvement by refactoring the comparison logic to dispatch to specialized `ExtensionArray.equals` methods, which is a broader algorithmic refinement for handling different data types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43589", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["Python-level fast path", "Cython integration"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific Python-level fast path with a conditional check for `StringDtype` to avoid intermediate array allocation. The Expert, conversely, makes a systemic change by integrating `StringDtype` into the existing Cython-optimized `groupby` framework, enabling it to leverage highly efficient compiled code paths.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43634", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow early-exit guard for `any()` aggregation, skipping work once a True value is found. The Expert, conversely, applies an algorithmic refactor by replacing a Python list comprehension with `np.vectorize` for object-to-bool conversion, which is a more systemic improvement leveraging NumPy's internal efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43675", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for a common `dropna` parameter combination by replacing one Python expression with another. The Expert, in contrast, performs a systemic refactor within a core `nanops` module, changing internal dispatch logic to avoid expensive Python object allocation for boolean arrays and route them to more efficient, likely vectorized NumPy operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43683", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization to cache internal group code computations. The expert's optimization, however, directly lowers the cost of a hot path by refactoring the data preparation to avoid expensive object creation and name inference, rather than caching results.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43694", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specialized fast path for `nsmallest` under very specific conditions (`n <= 5`, `keep='last'`). In contrast, the Expert makes a systemic improvement to the general `Index.drop` method by avoiding redundant data materialization, which benefits any caller of this core utility.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43696", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert apply algorithmic refactoring and micro-overhead removal. However, the LM's patch includes a deeper, more systemic optimization in Cython by removing a loop-carried dependency to enable compiler auto-vectorization and future parallelism, which is a lower-level performance improvement compared to the Expert's Python-level overhead removal.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43725", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its primary optimization (Kahan summation removal for floats) does not apply to the `int64` workload, making the main intent of the patch misdirected for the benchmark. The expert's patch, conversely, directly targets a significant hotspot in the `groupby().transform()` operation by avoiding large memory allocations and data copies.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43760", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path (`if hasattr(...)`) to use a specialized conversion. The Expert, conversely, removes an inefficient method override, allowing the class to leverage a more direct and systemically optimized inherited `ndarray.tolist()` implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43823", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a conditional fast-path by automatically switching to the 'pyarrow' engine and a micro-optimization within that engine. The Expert's optimization is a systemic algorithmic refactor, changing a quadratic time complexity operation to linear time complexity in a core parsing component.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-44192", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific conditional fast-path to dispatch `nansum` on float dtypes to the C-optimized `bottleneck` library. The Expert, in contrast, performs an algorithmic refactor by refining the conditions for an existing `maybe_operate_rowwise` decorator, preventing an anti-pattern for specific array shapes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44566", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a heuristic fast path using sampling and object identity checks to short-circuit the original logic. The expert, however, performs a systemic optimization by reimplementing the entire original comparison logic in Cython, lowering the hot path to native code for a general performance improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44594", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Parallelization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is a conditional fast-path to automatically select and configure the PyArrow engine based on heuristics (file size, index_col). The Expert's change is an algorithmic refinement within the existing parser's type inference, specifically optimizing `na_values` handling for numeric columns.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44610", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast paths for common dtypes and adds caching, which are pattern-specific optimizations. The Expert, in contrast, implements a more systemic change by refactoring the data flow to pass a precomputed mask, thereby eliminating redundant and expensive array computations across multiple call sites.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44666", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-overhead removal, simplifying a direct arithmetic calculation within a Cython loop. The Expert's optimization is a more systemic algorithmic refactor, making the `allow_fill` logic granular to conditionally avoid expensive validation steps for specific data types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44758", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a conditional fast path for structured arrays to create an index, falling back to the original slower method for other cases. The Expert's patch, conversely, performs a more systemic algorithmic refactor by unconditionally replacing the old index creation logic with a direct, optimized call, improving the general case for default index creation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44827", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's optimization directly targets the benchmarked `dfT.equals(dfT)` call with a `self is other` fast path, which is hit by the workload. The expert's explanation explicitly states that their patch is not exercised by the workload due to an existing identity check in `DataFrame.equals` and a `strict_nan` parameter mismatch.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-44832", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["completeness", "micro-optimization"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation identifies two distinct optimizations contributing to the workload's speedup: a fast path in `dropna` and a deeper, lower-level NumPy idiom (`values != values`) in `_isna_array`. The Expert's explanation only identifies the `dropna` fast path for the workload, missing the `_isna_array` optimization. This indicates a depth gap in the analysis of the performance improvements for the specific workload, with the LM providing a more complete and deeper understanding of the mechanisms.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44857", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for DatetimeIndex formatting using vectorized strftime. The Expert implements caching for the data_index property, which constitutes a structural redesign of data access (dataflow restructure). This aligns with the LM using a fast path (shortcut) and the Expert applying a systemic change.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44908", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "Both explanations aim to optimize `to_csv` for `MultiIndex` (same tactic family). However, the Expert's solution is deeper, addressing a specific structural inefficiency in the `MultiIndex` itself (unused levels) by compacting it before writing. The LM's solutions are a mix of micro-optimizations in Cython, avoiding intermediate object creation, and parameter tuning, which are less fundamental to the `MultiIndex`'s internal representation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44943", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe a fast-path/early-exit optimization for the same logical condition (all-True mask, scalar replacement). The Expert's approach is deeper as it leverages and enhances an existing internal `noop` flag to short-circuit the execution, whereas the LM introduces a new, explicit set of checks for the same condition.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45242", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The Expert targets a specific, high-impact bottleneck in the warning issuance mechanism (`find_stack_level`) that is repeatedly triggered by the workload. The LM, while making valid optimizations to the core `groupby.apply` logic, does not address this specific, primary bottleneck of the benchmark, making its optimizations 'misdirected' relative to the most impactful hotspot for this specific workload.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45247", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a potentially risky heuristic (inspecting lambda source code and testing with a dummy DataFrame) to detect a specific `np.max` pattern. In contrast, the Expert's change is a semantically preserving refactor of the dispatch logic, safely enabling an existing fast path for a broader class of DataFrame-to-Series functions using robust type and equality checks.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-45387", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["ImportPlacement", "CodeStyle"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the exact same core optimization strategy: replacing a Python-level loop with a C-extension function for `TimedeltaArray.astype(object)`. The only discernible difference in the patches is that the LM places the import statement inline within the `elif` block, while the Expert places it at the top of the file, which is generally considered better practice for code organization and maintainability, making it subtly 'safer' or 'cleaner' in a broader sense.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45571", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path by using brittle string matching on lambda source code to identify specific `np.max`/`np.min` patterns. In contrast, the Expert implements a systemic improvement by replacing an inefficient `np.concatenate` idiom with the optimized `np.tile` within a general internal function responsible for broadcasting UDF results, benefiting any such UDF.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45708", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces two distinct conditional 'fast path' blocks for `isna` and non-`isna` scalar values, which are specific shortcuts. The Expert, in contrast, applies an algorithmic refactor by changing the array construction to use a single-element sequence followed by a vectorized `.repeat(length)` operation, which is a more systemic improvement to the general scalar broadcasting logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45854", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path that switches from binary search to a vectorized linear scan for large arrays, which is a pattern-specific optimization. The Expert, however, implements a systemic algorithmic refactor by deferring the allocation of a large `Index` object, thereby avoiding significant memory and CPU overhead for single-element lookups.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45931", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to store the results of repeated slice operations, avoiding re-computation. The Expert optimizes the underlying `searchsorted` calls within `MultiIndex` by directly using a Cython-implemented routine, thereby lowering the cost of the hotspot itself rather than caching its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-46040", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization moves the `GroupBy.last()` operation from a Python-based aggregation to a Cython-optimized path. The Expert's optimization, while also leveraging Cython, provides a deeper micro-optimization *within* the Cython `group_last` function by efficiently handling null values using pre-computed masks, avoiding more expensive null-checking function calls. Both use Cython for performance, but the Expert's change is a more granular refinement of the compiled code.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46107", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for integer arrays without NAs, leveraging `np.unique`. The Expert, however, performs a more systemic refactor by removing an unnecessary memory allocation and data copy that previously occurred for certain integer types, impacting multiple functions beyond just factorization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46109", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow guard (a 'Small DataFrame Bypass') that acts as a fast path for specific input sizes, falling back to the original implementation. The Expert, conversely, applies a systemic, vectorized optimization directly for all cases matching the target conditions without such a size-based guard.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46174", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its proposed optimizations are not triggered by the provided workload script, making them irrelevant to the benchmark's performance. In contrast, the expert's explanation directly identifies and optimizes a core hotspot within the `reindex` operation that is repeatedly exercised by the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-46235", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization for `fast_zip` is a specialized Cython fast path for the narrow case of exactly two input arrays (`k=2`). In contrast, the expert's optimization is an algorithmic refactor within `MultiIndex._values` that systematically reduces expensive object boxing for specific dtypes by changing the order of operations, improving the general handling of these types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46288", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a local algorithmic refactor, replacing intermediate object creation with a dictionary-based lookup within a single method. The Expert's optimization is a more systemic refactor, changing the fundamental data structure for intermediate indexers from pandas `Int64Index` objects to raw NumPy boolean arrays and leveraging vectorized NumPy operations across multiple core indexing methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46330", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["BrittleCode", "FragileFastPath"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly brittle fast-path by inspecting a lambda's internal `__code__` and `__closure__`, which is fragile and risky. It also changes the return `dtype` for `_str_startswith` from `bool` to `object`, potentially altering behavior. The expert's change is robust and preserves documented behavior by optimizing data access for `StringArray` within the `IndexEngine`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46349", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path using brittle bytecode comparison for an identity lambda and specific index name matching. The Expert, conversely, applies an algorithmic refactor by reordering operations to reduce the computational cost of re-indexing for a general class of non-unique, unsorted indices.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-47234", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization involves adding memoization/caching for PyArrow dtype mappings. In contrast, the expert's optimization refactors a hot conversion path (`StringArray.__from_arrow__`) to leverage PyArrow's C++ backend for concatenation, eliminating Python loops and multiple allocations, effectively lowering the hotspot rather than caching its result.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-47781", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by changing the arithmetic algorithm within an already Cythonized function to reduce divisions. The Expert makes a more systemic change by fixing the dispatch logic to ensure a Cython-optimized path is used instead of a slower Python-based one for `ddof != 1` cases, leveraging existing compilation infrastructure.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48152", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies a single fast-path optimization (a shortcut) for Series construction. The Expert identifies the same fast-path but also an additional, more systemic algorithmic refactor for `Series.value_counts` that improves its general efficiency by leveraging a lower-level function and avoiding redundant computation. The LM's explanation is limited to a 'shortcut' while the Expert includes a broader 'algorithmic refactor'.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48338", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, indicating no optimization was applied and thus completely missing any hotspot. The Expert, conversely, provided a targeted optimization that directly addresses a measured hotspot in `pandas.Index.get_indexer` by refactoring data preparation to enable a more efficient internal lookup mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48472", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply a mix of Cython-level optimizations and algorithmic refactoring. However, the Expert's change is deeper by fundamentally redesigning the data flow for 'blank_missing' strings, moving the logic from a redundant Python post-processing step directly into the Cython parsing layer, thereby eliminating an entire stage of work.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48502", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths for MultiIndex objects with sequential integer levels, using direct arithmetic calculations. The Expert, in contrast, makes a systemic correction by explicitly excluding MultiIndex from a general 'libjoin'-based path that was found to be inefficient, thereby routing it to a more appropriate and performant existing implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48504", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple `FastPath/SpecialCase` branches with `isinstance` checks to handle specific input types (Timestamp, date, datetime, string) more quickly. The Expert's change is a `Micro-OverheadRemoval` that optimizes a general type-checking mechanism for all list/tuple inputs by avoiding an unnecessary `np.ndim` call, thus improving the underlying system's efficiency for a broad range of inputs.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48609", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization (caching) to store results of repeated indexer calls. In contrast, the expert's optimization directly lowers the cost of the hotspot by avoiding redundant `algos.take_nd` calls when an identity mapping is implied during MultiIndex reconstruction, thus removing unnecessary computation rather than just storing its result.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48611", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation includes a 'FastPath/SpecialCase' (the `isinstance` check to avoid redundant `MultiIndex` construction). In contrast, the expert's explanation describes a more 'AlgorithmicRefactor' approach, using `algos.unique` and `MultiIndex.get_indexer` to fundamentally change the lookup strategy, which is a systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48622", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same hotspot (`MultiIndex.size`) and the same core optimization (using `len(self.codes[0])` to avoid `_values` materialization). However, the LM's solution includes `@cache_readonly`, which its own explanation notes is not the primary benefit for the benchmarked workload, while the expert's solution is more minimal and leverages the existing `__len__` method for the same performance gain, indicating a deeper understanding of the optimal implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48723", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a low-level utility function (`fast_unique_multiple`) by adding a conditional fast path using C-optimized built-ins. The Expert, however, performs a systemic algorithmic refactor within `MultiIndex.union`, replacing the call to the generic `fast_unique_multiple` with a more specialized and efficient `MultiIndex.difference` method, leveraging specific data properties.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48752", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path for a specific high-cardinality categorical case, bypassing a heuristic with a direct NumPy sort. The Expert performs a systemic algorithmic refactor, replacing multiple high-level Categorical object manipulations with more direct and efficient NumPy array operations to reduce overhead for the general `groupby(categorical, sort=False)` case.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48976", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path specifically for single-chunk arrays, which the benchmark uses. The Expert, however, implements a more systemic optimization by refactoring the null-handling logic to leverage PyArrow's C++ compute kernels (`pyarrow.compute.fill_null`) and reduce intermediate data conversions, providing a more general improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49177", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe a fast-path optimization using an `isinstance` check. However, the LM's fast path delegates to a specialized `algos.isin` (an algorithmic refactor), while the Expert's fast path avoids a redundant `MultiIndex.from_tuples` call (a micro-overhead removal). This represents a depth gap in the underlying optimization strategy, with the Expert's change directly optimizing the existing flow by removing a known bottleneck.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49577", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces conditional fast paths (triggered by `len > 100000` thresholds) to switch to highly optimized NumPy operations or chunked processing for large arrays. The Expert's optimization is a general algorithmic refactor of a category validation check, improving its efficiency without such conditional guards.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49596", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "BehaviorChanging", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization fundamentally changes the behavior by setting an entire column to a value when only a single element was targeted, introducing a semantic risk. The expert's solution, conversely, preserves the exact behavior while optimizing the underlying data modification to be in-place, avoiding costly memory operations.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-49772", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization strategy: replacing a slow, generic Python iteration with a specialized, PyArrow-native iteration for `ArrowExtensionArray`. The expert's implementation is slightly more concise and idiomatic for iterating PyArrow `ChunkedArray`s, and the overall patch is more complete, including a `whatsnew` entry.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49825", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert introduce an early-exit fast path for empty inputs. However, the Expert's patch is broader, addressing similar performance regressions in multiple functions (infer_dtype and isin) and documenting it in the changelog, indicating a more systemic approach. The Expert's specific fast path for infer_dtype is also slightly more robust by checking `if not value:` after ensuring it's a list, and explicitly avoids a function call.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49839", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert identify the same hotspot (iteration over Pandas Extension Arrays) and apply a fast-path strategy to reduce Python overhead. However, the Expert's implementation is deeper and more effective, leveraging direct NumPy array iteration (`for val in self._data: yield val`) which is more performant than the LM's Python-indexed loop (`for i in range(len(data)): yield data[i]`) within its fast path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49851", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific early-exit fast-paths and micro-optimizations for particular conditions, some of which it notes are not hit by the workload. The Expert implements a systemic architectural change by removing a `@final` decorator and adding a specialized `ExtensionBlock.fillna` method that delegates to the underlying `ExtensionArray`, enabling broader, type-specific optimizations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50078", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Micro-OverheadRemoval", "RedundantWorkRemoval"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target reducing Python overhead in `Series.to_dict` for non-object dtypes. The LM's approach is a more extensive refactor, replacing Python iteration with a C-optimized `numpy.ndarray.tolist()` for values. The Expert's approach is a more precise and minimal fix, removing a truly redundant generator expression, which is 'deeper' in identifying and eliminating dead work within the existing mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50089", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for a single, exact datetime format string and adds a timezone object cache. The Expert, however, implements a systemic algorithmic refactor by replacing element-wise Python loops with vectorized DatetimeArray operations, grouping by unique timezones for efficient processing. The LM's fast path is a pattern-specific shortcut, while the Expert's approach is a broader structural improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50168", "repo": "pandas-dev/pandas"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch makes `numexpr` unconditionally active and globally configures its threads at module import, representing an invasive/global change to pandas' computation strategy. The expert's patch makes a local, targeted optimization within a single internal casting function by adding an early exit.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50306", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path for `Index.union` that only triggers for a narrow, benchmark-specific relationship between two indexes. The expert, however, implements a systemic change by enabling C-level optimized join functions for a broader category of `BaseMaskedArray` dtypes, representing a more general algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50310", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation incorrectly states that PyArrow treats `NaN` comparisons as `False` (resulting in `null_count == 0`), leading it to optimize a fast path for the no-nulls case. The expert correctly identifies that `NaN` comparisons result in `null` (meaning `null_count > 0`) for the workload, and thus optimizes the actual hotspot by avoiding inefficient `object` dtype conversions.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-50524", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations within the `IntervalArray.from_tuples` method, involving fast-path and micro-optimization tactics. The LM introduces a fast path leveraging NumPy for bulk array creation for a specific input type. The Expert applies a micro-optimization by short-circuiting an `isna` check within the general processing loop, making its application 'broader' within the function's overall logic.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-50620", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an early-exit guard (a shortcut) within an existing Cython loop to skip iterations once a group's result is determined. The Expert, however, performs a systemic refactor by replacing a slow Python-level `np.vectorize` loop with highly optimized, vectorized NumPy operations for boolean conversion, fundamentally changing the processing approach.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50623", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a 'fast path for NumPy arrays' (a narrow guard/special case) in addition to caching. The Expert's primary optimization is an 'early-exit optimization' that avoids an expensive `np.asarray` conversion, which constitutes an algorithmic refactor of the hot path. According to precedence, 'Shortcut_vs_Systemic' is chosen over 'Cache_vs_LoweredHotPath' when both apply.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51054", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation states that the provided patch is empty and thus cannot identify any optimizations. Therefore, there is no LM optimization strategy to compare against the expert's detailed explanation of removing redundant validation checks.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-51339", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional 'fast path' that activates only for specific category removal patterns (subset, large reduction). The Expert, in contrast, makes a more systemic improvement by replacing a general Python-level iteration and set construction with highly optimized C/Cython-implemented pandas Index methods, improving the general processing of the 'removals' argument.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51344", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path with guards for a narrow case (int64[pyarrow] without NAs) that leverages a C++ optimized PyArrow function. The Expert performs a structural refactor by moving warning handling out of the hot path for a broader set of non-NA conversions, which is a more general cleanup of Python overhead.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51439", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization: detecting a `range` object and converting it to a NumPy array using `np.arange` for vectorized operations. The expert's patch applies this conversion earlier in the arithmetic dispatch chain (`_arith_method` in `base.py`), which is a deeper and more fundamental application of the same strategy compared to the LM's placement in `arithmetic_op` in `array_ops.py`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51518", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is to add caching for the validity mask. The expert's optimization refactors the `find_valid_index` function to remove overhead associated with ExtensionArray dtypes by ensuring it only operates on a simple NumPy boolean array, effectively lowering the cost of the hotspot itself without caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51549", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path for `DataFrame.where` when the `other` argument is a scalar, leveraging `numpy.putmask`. The Expert performs an algorithmic refactor by explicitly converting extension-dtype `cond` arguments to standard NumPy boolean arrays early, avoiding slower generic handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51574", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unknown", "Generalizability": "General"}, "rationale": "The LM introduces conditional fast paths and early exits for specific MultiIndex lookup patterns. The Expert, in contrast, makes a more systemic improvement by normalizing NaN/NaT inputs to an existing LRU cache, thereby increasing cache hit rates for a broadly used utility function.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51592", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe adding fast paths to `ArrowExtensionArray.isna()` based on null counts. However, the LM's patch restricts this fast path to single-chunk PyArrow arrays, while the Expert's patch correctly applies the fast path to both single and multi-chunk arrays by directly using `self._data.null_count`, making it a broader and more robust application of the same optimization strategy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51630", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies micro-optimizations within the existing Cython loop by using raw C pointers and removing a running sum. The Expert, however, implements a systemic algorithmic refactor by changing the global sorting strategy to per-group sorting on contiguous data, significantly improving cache locality.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51722", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast-paths for narrow conditions (full slice identity return, last element lookup). The Expert, however, implements a systemic change by refactoring `Index` slicing to propagate pre-computed engine properties (like monotonicity) from the original index to the new sliced index, avoiding redundant O(N) re-computations through Cython-level state transfer.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51738", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation correctly identifies that its proposed optimization is misdirected because the workload's data generation prevents the optimized code path from ever being executed. In contrast, the expert's optimization targets a core internal mechanism (`Series.name` handling) that is a measured hotspot in the workload's `groupby().agg()` operation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51784", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for a narrow `float32` to `int32` conversion. The Expert implements a more systemic refactor of the DataFrame construction logic to avoid a redundant memory copy when type conversion is required, improving general memory management.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52054", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global cache and an ISO-like fast path to avoid re-inferring datetime formats. The Expert, in contrast, optimizes the hot path by preventing an unnecessary array copy, thereby lowering the cost of the existing data conversion process without caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52057", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global memoization cache for the `get_block_type` function. In contrast, the Expert refactors the internal logic of `get_block_type` by removing redundant checks and implementing early exits, directly lowering the computational cost of the function's hot path without caching.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52109", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, explicit `if isinstance(other, Timestamp)` fast path to directly perform `i8` comparisons. The Expert, conversely, refactors the existing comparison logic to avoid unnecessary allocations and a generalized function call, allowing the system to correctly fall through to an already optimized array-scalar NumPy operation. This aligns with `Shortcut_vs_Systemic` where LM adds a specific shortcut and Expert applies a more systemic refactor to the existing flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52111", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by reducing temporary array allocations using `numpy.ma.masked_where` and adding a direct Python loop fast-path. The Expert, in contrast, enables and leverages a Cython-based implementation for the `groupby` aggregations on `Categorical` data, representing a more systemic shift to compiled code.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52120", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a pattern-specific hack for `RangeIndex` slicing by returning the slice object itself as the new index. In contrast, the expert performs a systemic refactor of `Series.__getitem__` to prioritize any slice operation with an early exit, improving the general control flow and object construction.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52145", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path for `ArrowDtype` transpose by changing dispatch logic to route to a highly optimized NumPy-backed implementation. The Expert's optimization is a micro-overhead removal, specifically a minor algorithmic refinement to avoid a redundant type cast in an array constructor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52256", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path guard for boolean Series to directly call NumPy's `any()`. The Expert, conversely, performs a systemic refactor and micro-overhead removal across multiple internal helper functions (`_reduce`, `_maybe_get_mask`, `_get_values`) that are part of the general reduction pipeline, making the existing logic more efficient for various dtypes, including boolean, rather than adding a new special case.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52341", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path specifically for boolean NumPy arrays. The Expert's solution is more systemic, providing a broader fast path (covering integer, unsigned integer, and boolean types) and integrating it with a structural refactor of how `Series.any()` and `Series.all()` delegate to internal reduction functions.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52381", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization, a new fast path, is explicitly stated by the LM itself as 'NOT taken' by the benchmarked workload due to specific parameter values. The Expert's optimization, however, directly targets and eliminates significant, unnecessary work (a large data copy and masked assignment) that the workload *was* performing, making it perfectly aligned with the hotspot.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52430", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific conditional fast path for `groupby().sum()` on PyArrow-backed Series using `np.add.at`. The Expert implements a more systemic change by making `ArrowExtensionArray` convert to and delegate its `_groupby_op` to the already optimized `MaskedArray` infrastructure, which is a broader structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52469", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation claims multiple optimizations (isna caching, fast paths for arr1 and arr2) contribute to the workload's speedup. The expert's explanation explicitly states that only the optimization for arr3 is relevant, and that the paths for arr1 and arr2 are 'UNCHANGED' and 'not affected' in performance for the workload. This indicates the LM is optimizing paths that are not the measured hotspot or have negligible impact according to the expert's analysis.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52525", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for PyArrow-backed arrays by adding a conditional guard and dispatching to an existing method. The Expert, however, performs a more systemic algorithmic refactor of the general index union logic, replacing inefficient Python list operations with optimized `Index` methods.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52541", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply micro-optimizations/fast-paths to skip redundant date conversions. However, the Expert's solution is precisely targeted to a single, identified bottleneck (unnecessary NumPy casting), making it 'deeper' in its focus on the true inner loop. The LM's solution is 'broader,' applying similar tactics in multiple places and adding other distinct optimizations not explicitly tied to the primary bottleneck.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52548", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-optimization of an existing fast-path condition check (replacing a list comprehension with a short-circuiting loop). In contrast, the Expert's optimization involves a systemic algorithmic refactor of the concatenation plan generation and its implementation in Cython, fundamentally changing how column alignment is handled.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52672", "repo": "pandas-dev/pandas"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes a global default configuration option (`mode.data_manager`) affecting the entire Pandas library, making it a cross-module/global change. The expert's optimization is a local, targeted code modification within the `concat` function's internal implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52685", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's fast-path condition `hasattr(values, '_data')` will never be met because `self.values` for a DataFrame with `Int64` columns returns a NumPy `object` array, not an `ExtensionArray` with `_data` and `_mask` attributes. Thus, the LM's optimization is misdirected and would not be triggered by the workload. The Expert's solution correctly targets the `BaseMaskedDtype` and refactors the logic to operate on the underlying arrays.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52836", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a type-specific fast path for `Float64Dtype` by directly calling `pyarrow.Array.to_numpy()`. The Expert, however, performs a more systemic algorithmic refactor in the base `NumericDtype` to efficiently handle `pyarrow.ChunkedArray` by using `combine_chunks()` to avoid Python loops, multiple allocations, and concatenation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52928", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for a narrow `reshape(-1, 1)` operation on 1D arrays. In contrast, the expert performs a systemic refactor by introducing a `_simple_new` method to bypass `__init__` validation for all new `BaseMaskedArray` instances created from existing data, benefiting `reshape` and many other methods more broadly.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53013", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism (`_cached_indexer`) to avoid re-computation on subsequent calls to `_group_indexer`. The Expert, however, refactors the core logic within `DataFrameGroupBy.groups` to construct a `MultiIndex` more efficiently using `MultiIndex.from_arrays`, thereby lowering the overhead of the hotspot itself rather than just caching its result.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53088", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, resulting in no optimization and thus failing to address any hotspot. The expert, however, precisely targeted a measured hotspot by eliminating Python object allocation overhead for PyArrow string concatenation.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53150", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for a specific input value (`i=1`) by adding an `if` condition. The Expert, conversely, implements a more systemic optimization by changing how `None` values are handled in PyArrow's `if_else` function, replacing a large temporary array with a scalar, which is a general improvement in memory and object management for all cases where `None`s might be generated.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53152", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces fast-paths and special-case handling (early-exit to avoid conversion, forcing ObjectFactorizer for differing units) to bypass expensive operations. The Expert applies a more systemic optimization by directly converting matching datetime keys to `np.int64` for highly efficient comparison, which is an algorithmic refactor leveraging native numerical types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53231", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that the provided patch is empty and it cannot perform any analysis. Therefore, there is no technical content from the LM to compare against the expert explanation, leading to an 'Unclear' classification.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-53368", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Vectorization", "PyArrow", "NumPy"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations target the same hotspot and propose replacing inefficient Python-level transposition with vectorized operations. However, their specific vectorized implementations differ: the LM's patch uses `pa.compute.list_element` in a loop, while the expert's patch implements a more integrated PyArrow `list_flatten` followed by NumPy `to_numpy().reshape().T` pipeline. This represents a deeper or broader application of the vectorized strategy by the expert.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53585", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an optimized path for a specific data type, leveraging PyArrow compute but retaining a Python loop for the final matrix population. The Expert performs a more systemic algorithmic refactor, completely eliminating Python loops for matrix population by leveraging advanced PyArrow compute and NumPy vectorized operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53655", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path that bypasses the Numba engine for specific aggregation functions by dispatching to existing Cython implementations. The Expert, however, performs a systemic algorithmic refactor of the Numba-accelerated `groupby` path, eliminating a costly sorting step and introducing new Numba kernels for direct, unsorted grouping.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53731", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces fast paths in `lexsort_indexer` by returning an identity array for already-sorted data and defers mask creation in `_Unstacker`. The Expert, however, implements a more systemic algorithmic refactor in `compress_group_index`, replacing a hash-table-based approach with a vectorized `cumsum` algorithm for the already-sorted case, which is a deeper change to the core grouping logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53806", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that the provided patch is empty and therefore offers no code edits or optimization strategy to analyze. Without any technical details from the LM, a meaningful comparison to the expert's explanation is not possible.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53955", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization uses a 'shortcut' by converting `ArrowDtype` data to NumPy arrays to leverage NumPy's fast transpose, incurring a conversion cost. The Expert's solution is 'systemic,' implementing a specialized, native `pyarrow`-based transpose that operates directly on `pyarrow` arrays, avoiding data conversions and integrating deeper with the underlying data representation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54224", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly details the introduction of a global cache (`_astype_view_cache`) as an optimization mechanism. The Expert's explanation, conversely, focuses on refactoring the `DataFrame.astype` method to avoid an expensive Python loop over columns when dtypes are identical, effectively lowering the hotspot without using caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54299", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism for NumPy array representations of PyArrow arrays and a fast path leveraging this cache. The Expert, in contrast, performs an algorithmic refactor of the internal `fast_xs` method, standardizing intermediate data storage and using a bulk conversion for all ExtensionDtypes, which is a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54508", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path for a specific data type and operation (`float64[pyarrow]` sum) by leveraging native PyArrow compute. The Expert implements a caching mechanism for `inspect.signature` results, which is a structural redesign of the DataFrame reduction logic that broadly improves performance for all ExtensionDtypes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54509", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths for a narrow, benchmark-specific input pattern within set operations. The Expert, however, implements a systemic algorithmic refactor by replacing a pandas-internal sorting mechanism with a direct call to NumPy's optimized `np.lexsort`, providing a general performance improvement for MultiIndex sorting.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-54835", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The Expert's optimization is a 'shortcut' (an early-exit fast path) that completely bypasses the sorting logic if the MultiIndex is already monotonic. The LM's optimization is 'systemic,' improving the efficiency of the actual MultiIndex sorting process by algorithmic refactoring (replacing `codes.max()` with `len(k.categories)`) and micro-overhead removal.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54883", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM attributes the performance improvement to enabling caching for `pd.Index` properties like `is_unique`. In contrast, the expert identifies an algorithmic refactor within `_unique_indices` that avoids creating large intermediate indexes and expensive `unique()` calls, instead using efficient `get_indexer_for` for incremental union computation, effectively lowering the hot path without explicit caching.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-55084", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations that use conditional logic to dispatch to highly optimized, native code. The LM's approach directly calls PyArrow's C++ compute engine for `min`/`max` aggregations. The Expert's approach refactors the dispatch to convert PyArrow timestamp/duration arrays to native Pandas `DatetimeArray`/`TimedeltaArray` which are already optimized for *all* `_groupby_op` calls, making the Expert's solution broader in its applicability to aggregations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55131", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for handling missing values when `convert_missing=False`, alongside a more systemic DataFrame construction. The Expert, however, applies multiple systemic algorithmic refactors and micro-overhead removals across the `read_stata` pipeline, such as eliminating redundant calculations, performing in-place type conversions, and optimizing loops for many columns.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55515", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces two distinct caching mechanisms to avoid repeated computations. The expert's optimization, however, lowers the hot path by refactoring a core Cython function with fused types to reduce Python object overhead and enable direct C-level operations.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-55736", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces caching and a special-case fast path in `fast_zip`, a general utility function, without explicitly linking it to the benchmark's `MultiIndex.get_indexer` hotspot. The expert, however, directly targets the measured hotspot in `MultiIndex.get_indexer` by refactoring its fill-indexing logic to use integer encoding and delegate to highly optimized single-level `Index` operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55839", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `Timestamp` arrays and a cache for format string validation. The Expert, however, implements a systemic refactor by moving Python-level timezone localization and object conversion to efficient C-level Cython functions, eliminating intermediate object arrays, and directly constructing optimized data structures.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55898", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for the 'self-groupby' pattern, directly constructing the result with ones. The Expert, in contrast, performs a systemic algorithmic refactor, changing the general `nunique` implementation from an O(N log N) sort-based approach to an O(N) hash-table-based approach.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-56061", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path with NumPy vectorization for large inputs to `MultiIndex.get_loc_level`. The Expert, however, applies a systemic fix by correcting a type-checking bug in `is_bool_indexer`, ensuring `DataFrame.loc` takes the correct, already optimized path for `MultiIndex` keys, which is an algorithmic refactor of the system's logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56062", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces conditional fast paths specifically for `CategoricalSeries` inputs, including direct access to codes/categories and a specialized matrix construction. The Expert, in contrast, applies a systemic algorithmic refactor to the general `sparse=False` output path, improving its efficiency for all input types without adding specific guards.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56089", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch re-implements the logic using Python loops and dictionary lookups to bypass perceived PyArrow/NumPy interop overheads, acting as a specific workaround. The Expert's patch introduces a systemic solution by delegating the operation to highly optimized, C++-backed PyArrow native kernels, which is a more fundamental improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56110", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to store and retrieve previously sorted results. The Expert, instead, implements an early-exit fast path that avoids the expensive sorting operation entirely when the index is already monotonic, replacing it with much cheaper copy or reverse operations, thereby lowering the hotspot.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56128", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path within `_factorize_keys` for handling categorical dtype mismatches by directly remapping codes. The Expert performs an algorithmic refactor (category reordering) that enables `CategoricalIndex` to utilize an existing, highly optimized, Cython-backed `_join_monotonic` path, representing a more systemic integration into the high-performance core.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56345", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations optimize the same `_hash_pandas_object` method for masked arrays using C-optimized functions. The Expert's approach is deeper, fundamentally redesigning how missing values contribute to the hash by directly assigning a canonical hash for `pd.NA` and explicitly changing the hash values, while the LM's approach is a micro-optimization of hashing the mask component.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56508", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path that delegates to NumPy's optimized `take` method, reducing Python overhead. The Expert, however, identifies a specific scenario where the `take` operation is equivalent to a `copy` and replaces the `take` algorithm with a more fundamental `copy` operation, which is an algorithmic refactor and structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56806", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes fast-path early exits and micro-optimizes a specific loop pattern (redundant while loop removal) within a Cython function. The Expert's patch performs a systemic algorithmic refactor of the Python-level dispatch logic to enable a more specialized and efficient indexer method (`_left_indexer_unique`) to be called in a broader set of scenarios.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56841", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for the specific case of exactly two groups, which the benchmark triggers. In contrast, the expert performs a systemic algorithmic refactor, replacing an O(N log N) sorting step with an O(N) linear scan, which is a more general and fundamental improvement to the groupby.ffill operation.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-56902", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a specific guard for `ArrowExtensionArray`s to bypass a Python wrapper and directly call a potentially native `pyarrow.Array.to_numpy()` method, which is a pattern-specific hack. The expert's optimization is an algorithmic refactor within the `_join_via_get_indexer` method, combining sorting and indexer generation into a single `sort_values(return_indexer=True)` call, representing a more systemic improvement to the algorithm's efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56919", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path with guards like `_id` and `from_product` structure. In contrast, the Expert performs a systemic algorithmic refactor within the general `equals` loop, replacing expensive value materialization with a more efficient code-based comparison for all equal-length MultiIndexes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56990", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces fast paths that its own analysis explicitly states are not triggered by the provided workload, leading to negligible impact or even slight degradation. The Expert's patch, however, correctly targets the workload's hot path by introducing a specialized Cython-based engine for string dtypes.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-56997", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path using `np.putmask` for a specific subset of the `same_index` case (NumPy arrays), falling back for other types and for different indices. The Expert provides a more systemic improvement by using the robust `self.mask` for the same-index case and, crucially, also refactors the general alignment case with `self.align` followed by `self.mask`, addressing a broader range of scenarios and a performance regression.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57034", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path for `RangeIndex.append` that directly calculates the final `RangeIndex` parameters, bypassing array operations entirely. The Expert introduces a more general algorithmic improvement within the array concatenation logic, replacing `np.concatenate` with the more efficient `np.tile` for repeated elements, which is a vectorized improvement to the underlying array handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57252", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for same-dtype NumPy comparisons and expands/tunes `numexpr` usage. The Expert implements a systemic algorithmic refactor by changing the memory layout of internal data blocks to Fortran-contiguous for improved cache locality within pandas' BlockManager.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57459", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to avoid re-computing `argsort` results. The expert, conversely, replaces a less efficient C-level check with highly optimized vectorized NumPy operations (`np.divmod`, `.all()`), thereby lowering the cost of the hotspot rather than caching its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-57534", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's change introduces a new implementation strategy that is faster for the benchmark due to constant factors but has worse asymptotic complexity, acting as a pattern-specific hack. The Expert's change applies a micro-optimization by reordering boolean conditions to leverage short-circuiting and C-function speed, which is a general improvement to the evaluation logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57560", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch only imports a decorator but does not apply it, rendering it inert and unaligned with the workload's hotspot. The Expert's patch introduces a Cython function and refactors a core utility to efficiently detect arithmetic sequences, directly optimizing the measured `groupby().groups` hotspot for range-like keys.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-57812", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path (shortcut) for `DataFrame.join` when the left DataFrame is empty, bypassing the general join algorithm. The Expert, conversely, performs a micro-algorithmic refactor within `RangeIndex._join_empty` to avoid redundant object creation, improving the general efficiency of that method's internal logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57855", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is an algorithmic refactor and micro-overhead removal via efficient NumPy operations. The Expert's primary optimization is a fast-path/special-case to bypass Python overhead. While the nature of the difference is 'systemic vs. shortcut', the rubric's mapping rules for 'Shortcut_vs_Systemic' are not met as the LM does not use a fast-path. The 'SameStrategy_DepthGap' rule is also not met as the Expert's change is not broader/deeper than the LM's.", "confidence": 0.6, "instance_id": "pandas-dev__pandas-58027", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for `_daily_finder` introduces sampling for large spans, explicitly changing the function's output from a full `PeriodIndex` to a sampled one. In contrast, the expert's optimization uses `functools.cache` for memoization, which strictly preserves the original behavior and output of the functions it decorates.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-58992", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-overhead removal and algorithmic refactoring. However, the Expert's optimization is deeper as it completely eliminates an expensive, unnecessary computation (index processing when `index=False`), whereas the LM's optimization focuses on batching existing computations to reduce their frequency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-59608", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is the introduction of an instance-level cache (`_update_dtype_cache`) to memoize results based on input object identity. The Expert's optimization is an early-exit fast path that avoids the expensive re-validation and re-creation of a `CategoricalDtype` object, effectively lowering the hot path by removing redundant work without caching.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-59647", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's fast path incorrectly assumes no NaN values in the input `np.float64` array by creating an all-False mask, which would alter the output for valid inputs containing NaNs. The Expert's optimization correctly uses `np.isnan` to efficiently detect NaNs, preserving documented behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-60121", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Heuristic/ParamTuning", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization enables the use of the `numexpr` library (native/vectorized computation) by lowering a heuristic threshold, effectively tuning a parameter to activate a fast path. The Expert's optimization, in contrast, performs an algorithmic refactor by changing an inefficient internal loop's iteration over `cond.dtypes` to a more efficient iteration over `cond._mgr.blocks`, representing a structural redesign of the type-checking logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-61014", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies several micro-optimizations and a narrow fast-path for small arrays. In contrast, the Expert performs a systemic algorithmic refactor by hoisting expensive coordinate validation and localization steps out of a loop over variables in `Dataset.interp`, fundamentally changing the complexity for these steps.", "confidence": 0.9, "instance_id": "pydata__xarray-4740", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces heuristic fast-paths like setting a fixed column width for large mappings and sampling keys based on arbitrary thresholds. The Expert, in contrast, implements a more systemic optimization by refactoring the `_mapping_repr` loop to avoid eager materialization of all `(key, value)` tuples, instead creating only a list of keys and retrieving values on-demand, thereby reducing Python object allocations.", "confidence": 0.9, "instance_id": "pydata__xarray-5661", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths based on arbitrary string patterns (`long_variable_name_`) and variable counts (`len > 1000`) that are characteristic of the benchmark. The Expert, in contrast, implements more systemic early-exit optimizations within the core decoding pipeline, avoiding unnecessary work (object allocations, attribute lookups) for any variable that genuinely does not require decoding, which is a more general algorithmic improvement.", "confidence": 0.9, "instance_id": "pydata__xarray-7374", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple specific fast paths, including an 'Ultra fast path' that is a pattern-specific hack for the exact workload. The Expert introduces a systemic algorithmic refactor to index comparison, adding an identity check that provides a general O(1) fast path for identical index objects, avoiding costly O(N) comparisons.", "confidence": 0.9, "instance_id": "pydata__xarray-7382", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization uses a narrow configuration override (`dask.config.set`) to prevent Dask's default chunk splitting behavior. The expert's solution is a more systemic algorithmic refactor, ensuring NumPy-backed coordinate variables are converted to Dask arrays early to enable lazy computation and avoid large eager memory allocations.", "confidence": 0.9, "instance_id": "pydata__xarray-7472", "repo": "pydata/xarray"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations involve conditional logic (fast paths). The LM optimizes by changing the default algorithm choice for specific functions within an external library (`flox`). The Expert's optimization is 'deeper' by adding an `isinstance` check to prevent redundant, low-level object re-creation (`CFTimeIndex`) in a frequently called utility function, directly addressing a Python overhead.", "confidence": 0.9, "instance_id": "pydata__xarray-7735", "repo": "pydata/xarray"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is to introduce multiple layers of caching for accessor objects and computed fields. The expert's optimization focuses on an algorithmic refactor to avoid redundant and expensive `CFTimeIndex` object creation by reusing existing objects, effectively lowering the hotspot without caching.", "confidence": 1.0, "instance_id": "pydata__xarray-7796", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast path for the specific case of two datasets, replacing a general sort with a direct comparison. In contrast, the Expert implements systemic improvements by refactoring core index creation to use NumPy vectorization and reducing general Python object overhead across multiple modules, representing a broader algorithmic and micro-architectural change.", "confidence": 0.9, "instance_id": "pydata__xarray-7824", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism with a fast path for specific `isel` calls, which is a pattern-specific hack. The Expert performs an algorithmic refactor by removing redundant internal function calls and object wrapping in a core data handling utility, improving the general case.", "confidence": 0.9, "instance_id": "pydata__xarray-9001", "repo": "pydata/xarray"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global caching mechanism to store results of datetime accessor calls, avoiding re-computation. The Expert, however, optimizes the underlying `groupby` mechanism by preventing unnecessary deep copies of non-dimension coordinates containing Python objects, thereby lowering the cost of the hot path itself rather than caching its results.", "confidence": 1.0, "instance_id": "pydata__xarray-9429", "repo": "pydata/xarray"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "pydata__xarray-9808", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM introduces a fast path via Cython loop unrolling for `n_components=2` and other systemic optimizations. The Expert applies an algorithmic refactor by simplifying a mathematical expression for `degrees_of_freedom=1`, effectively creating a fast path by skipping an expensive power operation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-10610", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces multiple caching mechanisms and a specialized fast-path for `degree=2` in `PolynomialFeatures.transform`. The Expert, however, performs a systemic algorithmic refactor of `PolynomialFeatures.transform` for dense inputs, replacing Python loops with general vectorized NumPy operations that apply to any degree, improving the general case.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-13290", "repo": "scikit-learn/scikit-learn"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "scikit-learn__scikit-learn-13310", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Parallelization", "DataPreparation"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the core algorithmic refactor to a sparse-aware merge algorithm in Cython. However, the Expert's solution is deeper and broader, additionally including crucial `sum_duplicates()` preprocessing in the Python layer and OpenMP parallelization (`prange`) in the Cython code, which the LM completely misses.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-15049", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactors and micro-overhead removals. However, the LM's approach is deeper and broader, re-expressing the core numerical computation using `np.einsum` (leveraging optimized C code) and directly constructing the sparse matrix. The expert's approach focuses on a memory optimization by batching the existing `np.multiply` operation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-15257", "repo": "scikit-learn/scikit-learn"}
{"classification": "Unknown / Not Enough Information", "confidence": "low", "instance_id": "scikit-learn__scikit-learn-15615", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies multiple conditional fast-paths and micro-optimizations (e.g., `set` for n-grams, `collections.Counter`, dictionary reuse). The Expert, conversely, implements a systemic algorithmic refactor by reordering the feature sorting step to occur after vocabulary pruning, which significantly reduces the input size for the expensive sorting operation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-15834", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that multiple parts of its patch (e.g., changes to `_lloyd_iter_chunked_dense`, `_k_init`, and `KMeans.fit`'s `n_init`/`algorithm` logic) are either not exercised by the workload or have no effect. The Expert's explanation, however, details a single, targeted optimization that directly addresses a measured overhead in the workload's execution path.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-17235", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["comprehensiveness", "algorithmic_depth"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic and micro-optimizations. However, the LM's explanation details a broader and deeper set of changes, including a fundamental algorithmic parameter change (SVD `full_matrices=False`) and numerous micro-optimizations. The expert's explanation focuses on a single, albeit effective, algorithmic optimization (`np.linalg.multi_dot`) for matrix chain products.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-17737", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies micro-optimizations and parameter tuning to the existing NearestNeighbors usage. The Expert, however, implements a systemic refactor by directly using KDTree and its `query_radius` method with `count_only=True`, which leverages native code to avoid Python loops and large memory allocations, fundamentally changing the approach to neighbor counting.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-17878", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces new algorithms (active set, block coordinate descent) but the explanation explicitly states that the provided workload does not trigger these new, optimized code paths. In contrast, the Expert's patch directly targets and removes unnecessary variance computation within the workload's actual execution path.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-19606", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is memoization (caching) to avoid re-computation for identical inputs across repeated calls. The Expert's primary optimization is an algorithmic refactor to use sparse data structures, which significantly reduces memory usage and improves performance for the computation itself, even on the first call.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-21837", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that no patch was provided, rendering it unable to analyze any code changes or explain optimizations. Therefore, no meaningful comparison can be made against the expert's detailed analysis.", "confidence": 0.4, "instance_id": "scikit-learn__scikit-learn-22106", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for uniform `sample_weight` and micro-optimizations for array construction. The Expert, however, implements a more systemic change by ensuring internal matrices are constructed in the `sparse.csc_matrix` format from the outset when using the `highs` solver, which is a structural redesign of the data flow to align with the solver's optimal internal representation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-22206", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path with an algorithmic refactor to avoid a large intermediate matrix. The Expert's optimization is a systemic change that ensures the input data type is optimal for leveraging highly vectorized and native floating-point operations in the existing computation path.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-22235", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for sparse matrices by adjusting chunking logic within a single function. In contrast, the Expert performs a systemic refactor of the ensemble's fitting process to propagate a `check_input=False` flag, eliminating redundant input validation across all base estimators.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-23149", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM's optimization is a low-level micro-optimization (loop unrolling) within Cython code, making existing computations slightly faster. The Expert's optimization is an algorithmic refactor that significantly reduces the amount of histogram computation by pruning features based on interaction constraints, representing a systemic redesign of the tree-growing process.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-24856", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's approach combines caching/memoization and a scalar fast path for a helper function with sparse matrix format conversion. The Expert, however, implements a systemic algorithmic refactor by precomputing decision path lengths and average path lengths during the `fit` phase using a new Cython method, fundamentally changing the `predict` logic from on-the-fly computation to fast array lookups.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25186", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific `if batch_size == 1:` fast-paths and specialized NumPy calls for that condition. The Expert performs a systemic refactoring of the sparse encoding validation logic, moving redundant validation out of the hot loop by restructuring the call chain, which is a more fundamental structural improvement.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25490", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies micro-optimizations like loop-invariant code motion and common subexpression elimination within the existing Cython loops. The Expert, however, performs a more systemic refactor by eliminating the creation of massive temporary NumPy arrays for loop bounds and leveraging Cython memory views for direct C-level data access, addressing a larger architectural bottleneck.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25713", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["workload_misunderstanding", "semantic_completeness"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify vectorization and Python loop removal as the core optimization. However, the Expert's explanation is deeper by correctly identifying that subsampling is active for the workload (a detail the LM missed) and safer by explicitly mentioning the potential for slight semantic differences in the output, which the LM's explanation omits.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-27344", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Parallelization", "AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation includes an 'algorithmic improvement' that replaces a precise percentile calculation with direct sampling from sorted data, which is a heuristic approximation and risks altering the exact bin thresholds. The expert's optimization, in contrast, focuses solely on parallelizing independent tasks, thereby preserving the original semantics.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-28064", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Parallelization", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM's explanation includes a narrow fast-path (early exit for empty receivers), while the expert's optimization is an algorithmic refactor that removes dead work by refining the set of rows considered for imputation.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-29060", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific fast paths triggered by checks on the function name ('list_sum') and the number of transformers, bypassing general `joblib` and `FunctionTransformer` mechanisms. In contrast, the expert implements a systemic refactor by moving data subsetting (`_safe_indexing`) before parallelization, which generally reduces serialization overhead for all `ColumnTransformer` usages with `n_jobs > 1`.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-29330", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for covariance calculation replaces `np.cov` with a direct `np.dot` that 'assumes the data is already centered around zero', which is a potentially risky semantic change compared to `np.cov`'s explicit centering. The Expert's optimizations, however, are explicitly preserving of the original behavior.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-29835", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces systemic optimizations by replacing Python loops with vectorized NumPy operations and an improved O(N+R) algorithm for unique labels. The Expert, in contrast, adds conditional fast-paths to skip expensive Python-level index conversion and unnecessary array slicing when input data is already in an optimal, pre-indexed form.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-9843", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation includes explicit memoization (pre-computing and storing index masks in a dictionary). The Expert's optimization focuses on lowering the cost of a hot path by pre-allocating a buffer and performing in-place updates to avoid repeated large memory allocations and copies, rather than caching computation results.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-9858", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation focuses on micro-optimizations like pre-allocation, memory reuse (views), and faster NumPy calls to reduce overhead within the existing Householder transformation. The Expert, however, describes a systemic algorithmic refactor that changes the computational complexity of applying the Householder transformation from O(dim\u00b3) to O(dim\u00b2) per step.", "confidence": 0.9, "instance_id": "scipy__scipy-10064", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Parallelization", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a simple configuration change to enable parallel execution by setting a default worker count, which can be seen as a 'pattern-specific hack' or parameter tuning. The Expert's optimization is a deep, structural redesign in the C++ backend to implement an FFT plan caching mechanism, which is a more sophisticated 'algorithmic refactor' for repeated computations.", "confidence": 0.9, "instance_id": "scipy__scipy-10393", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies several micro-optimizations and NumPy idiom improvements, reducing constant factors and intermediate allocations. The Expert, however, implements a fundamental algorithmic complexity improvement, replacing an O(N^2) brute-force check with an O(N log N) KD-tree approach, representing a much deeper algorithmic change.", "confidence": 0.9, "instance_id": "scipy__scipy-10467", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations using algorithmic refactoring, vectorization, and micro-overhead removal. However, the Expert's change is deeper, specifically targeting and eliminating a Python-level iteration bottleneck (`itertools.groupby`) with a fully C-optimized NumPy solution (`np.argsort`, `np.bincount`, `np.cumsum`), whereas the LM applies a broader collection of good NumPy practices across multiple functions.", "confidence": 0.9, "instance_id": "scipy__scipy-10477", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe caching/memoization. The Expert's approach is deeper and broader by implementing a reusable decorator and applying it to the internal `get_lapack_funcs` call that `cholesky` makes, which is the true source of repeated work. The LM directly caches `cholesky` results, but this is bypassed for the benchmark's small input.", "confidence": 0.9, "instance_id": "scipy__scipy-10564", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization strategy: avoiding large intermediate Python lists and directly populating pre-allocated NumPy arrays. However, the LM's patch applies this strategy more broadly within the `tocsr` method, also optimizing the `nnz` and `indptr` calculations, while the expert's patch focuses only on the `indices` and `data` arrays.", "confidence": 0.9, "instance_id": "scipy__scipy-10921", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to avoid repeated sparse matrix format conversions. The Expert, however, directly optimizes the `lil_matrix.tocsr` conversion method by replacing inefficient Python loops with highly optimized NumPy `np.fromiter` calls, effectively lowering the cost of the hot path itself.", "confidence": 1.0, "instance_id": "scipy__scipy-10939", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the core optimization as switching from LIL to CSR for sparse matrix operations. However, the Expert's explanation provides a broader and deeper analysis, detailing how this strategy is applied consistently across `_presolve` and its helper function `_get_Abc`, including changes to `hstack`, `vstack`, and `zeros` to default to CSR, and more efficient construction of new sparse matrix rows.", "confidence": 0.9, "instance_id": "scipy__scipy-11358", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path early-exit for sparse matrix multiplication when an operand is empty. The Expert, however, refactors the underlying C++ sparse matrix multiplication functions and their Python wrappers to optimize memory allocation and Python-C API interactions for the general case, which is a systemic improvement.", "confidence": 1.0, "instance_id": "scipy__scipy-11478", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path to filter explicit zero entries in Python, reducing Python overhead for a specific data characteristic. The Expert's optimization is a systemic refactor that moves critical Python loops to highly optimized Cython functions, fundamentally changing the execution engine for the conversion.", "confidence": 0.9, "instance_id": "scipy__scipy-11517", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["micro-optimization", "dead-work-removal", "indexing-optimization"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations within the same hot loop. The LM optimizes NumPy indexing for the general case, while the Expert adds a conditional guard to skip `np.std` calls for bins with 0 or 1 elements, which is a 'safer' approach by explicitly handling edge cases.", "confidence": 0.9, "instance_id": "scipy__scipy-11757", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert optimize the `_kpp` function by replacing Python loops with vectorized operations and algorithmic refactoring. However, the Expert's approach for `_kpp` is deeper, leveraging the highly optimized `scipy.spatial.distance.cdist` function for efficient all-pairs distance calculation, which is a more robust and performant solution than the LM's manual iterative update using `np.sum` and `np.minimum`. The LM also includes an additional optimization for the `kmeans2` function that the expert does not.", "confidence": 0.9, "instance_id": "scipy__scipy-11982", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for `maxwell.fit` uses a heuristic for the `loc` parameter, which, despite claiming to compute MLEs, risks altering the output compared to the true MLE that the original numerical optimization would seek. The expert's optimization, in contrast, strictly preserves the mathematical semantics of the log-PDF while making its calculation more efficient and numerically stable.", "confidence": 0.9, "instance_id": "scipy__scipy-12001", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path that switches to a specialized algorithm (`eigh`) for Symmetric Positive Definite matrices, acting as a pattern-specific shortcut. The Expert, in contrast, performs a systemic optimization by Cythonizing a performance-critical nested Python loop within the general `_sqrtm_triu` function, lowering its implementation to native code.", "confidence": 0.9, "instance_id": "scipy__scipy-12474", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation attributes the performance issue to missing Fortran wrappers in `scipy.integrate`, assuming `gengamma.rvs` relies on these for numerical integration. The expert, however, correctly identifies the hotspot within `gengamma.rvs` itself, replacing a generic inverse-CDF method with a direct, NumPy-accelerated sampling algorithm. The LM's optimization targets a component not directly responsible for the workload's bottleneck.", "confidence": 0.9, "instance_id": "scipy__scipy-12587", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for small matrices by using stack allocation in the C++ core. The Expert, however, performs a more systemic refactor by moving Python-level checks and array creation entirely into the C extension, fundamentally redesigning the Python-C interaction to reduce interpreter overhead.", "confidence": 0.9, "instance_id": "scipy__scipy-13107", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global memoization cache for the `_moment` function to avoid redundant calculations. The Expert, instead, refactors the `skew` and `kurtosis` functions to compute the array mean only once and pass it to `_moment`, thereby eliminating redundant O(N) mean calculations within the hot path without using a cache.", "confidence": 1.0, "instance_id": "scipy__scipy-13388", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["memory_allocation", "array_copying", "numpy_views"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot by refactoring NumPy operations in a hot loop. However, the expert's solution is deeper as it explicitly avoids intermediate array copying by using NumPy views, whereas the LM's solution, while improved, still relies on `np.concatenate` which creates new arrays.", "confidence": 0.9, "instance_id": "scipy__scipy-13566", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces fast paths and micro-optimizations (e.g., using `np.full` for scalars) to efficiently produce the *same output shape* for scalar arguments as the original behavior. The Expert, conversely, implements an `AlgorithmicRefactor` that fundamentally changes the *output shape* for scalar arguments (from `count_nonzero(cond)` elements to 1 element), which is a more systemic change in the function's behavior.", "confidence": 1.0, "instance_id": "scipy__scipy-13611", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path (a shortcut) for a common case, bypassing generic logic and using direct NumPy slicing. The expert's optimization, while a micro-overhead removal, can be interpreted as a localized dataflow restructuring by optimizing an arithmetic expression to reduce temporary NumPy array allocations.", "confidence": 0.8, "instance_id": "scipy__scipy-13759", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its patch includes a 'Semantic Correction' for the `chebyshev` function, changing its behavior to correctly apply weights, which was previously 'Unused'. This means the LM's patch alters the output semantics from the prior (incorrect) implementation. In contrast, the expert's explanation focuses on refactoring dispatch logic and reducing Python overhead, implicitly preserving the existing semantic behavior.", "confidence": 1.0, "instance_id": "scipy__scipy-13786", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe implementing a specialized `_add_sparse` method for `dia_matrix` to avoid costly `csr_matrix` conversions. The LM's implementation is deeper, pre-calculating all unique offsets and directly populating a pre-allocated NumPy array, while the Expert's uses iterative calls to `setdiag` and `diagonal` methods, which might incur more overhead.", "confidence": 0.9, "instance_id": "scipy__scipy-14004", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert implement a specialized native code path for the weighted Canberra distance. However, the Expert's explanation highlights the use of C++ templates and `transform_reduce_2d_`, explicitly mentioning potential benefits like vectorization (SIMD) and multi-threading, suggesting a deeper or more advanced native code optimization strategy compared to the LM's more direct C loop implementation.", "confidence": 0.9, "instance_id": "scipy__scipy-14085", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a `multi_statistic` parameter to `binned_statistic_dd`, allowing shared computation of binning and data grouping (caching intermediate results) when multiple statistics are requested. In contrast, the Expert's optimization replaces the generic, likely Python-loop-based implementations for 'min', 'max', and 'median' with highly optimized, vectorized NumPy operations, thereby lowering the hot path for these specific calculations.", "confidence": 1.0, "instance_id": "scipy__scipy-14625", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path that explicitly notes a 'Potential Semantic Change/Tradeoff' if `loc < 0`, meaning it might generate samples from a different distribution. The expert's optimization, conversely, fundamentally rewrites the `_ppf` method to be fully vectorized and analytical, preserving the distribution's documented behavior without introducing semantic risks.", "confidence": 1.0, "instance_id": "scipy__scipy-16599", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by implementing a specialized Newton's method in Python. The Expert, however, offloads the computation to a highly optimized, compiled C++ library (Boost) via Cython ufuncs, representing a systemic shift to native code execution rather than an in-Python algorithmic improvement.", "confidence": 1.0, "instance_id": "scipy__scipy-16790", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and optimize by replacing expensive NumPy operations with direct Cython assignments in the inner loop. However, the Expert's solution is broader and deeper, additionally refactoring the data flow by preallocating and precomputing arrays (like `indptr` and `indices`) in the Python caller before passing them to the Cython function, moving more work out of the hot loop.", "confidence": 0.9, "instance_id": "scipy__scipy-16840", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's patch directly optimizes `lil_matrix.__iadd__` for `dia_matrix`, which is the exact operation in the workload (`L += A` where `A` is `dia_matrix`). The Expert's patch optimizes `lil_matrix.__setitem__` for `[:, :] = sparse_matrix`, based on an incorrect assumption that `L += A` for an empty `L` is equivalent to `L[:, :] = A`. Thus, the expert's optimization is misdirected for this specific workload.", "confidence": 0.9, "instance_id": "scipy__scipy-18211", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for the specific case where the parameter `z` is zero, effectively simplifying the distribution to a Beta distribution for that scenario. The Expert, however, applies an algorithmic refactor to the `_pdf` method that improves the general calculation of the `gausshyper` distribution for all parameter values, not just a specific one.", "confidence": 0.9, "instance_id": "scipy__scipy-18799", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies multiple micro-optimizations and pattern-specific replacements (e.g., explicit 2D determinant formula, `einsum` to `sum(A*B)`, `np.where` to boolean indexing). The Expert, in contrast, implements a more fundamental algorithmic refactor by changing the mathematical approach to calculate the angle using the Law of Cosines, representing a more systemic change to the core computation.", "confidence": 0.9, "instance_id": "scipy__scipy-18850", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional Python loop (`if K > 1000`) to avoid a temporary array, which is a specific fast-path/micro-optimization. The expert, however, performs a systemic refactor by replacing the entire Python `for` loops with highly optimized, compiled SciPy digital filtering functions (`lfilter`, `lfiltic`), representing an algorithmic and native code improvement.", "confidence": 0.9, "instance_id": "scipy__scipy-18917", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization enhances memoization by converting a single-entry cache to a multi-entry dictionary cache. The expert's optimization, however, removes the overhead of an `np.all` comparison in the hot path of the memoizer once the initial (and only useful) memoized value has been missed, effectively lowering the cost of subsequent function calls without adding more caching.", "confidence": 1.0, "instance_id": "scipy__scipy-18996", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to avoid re-computing the user-provided function for identical inputs. The Expert, conversely, lowers the cost of the hot path by replacing Python function calls (np.real/np.imag) with direct attribute access (.real/.imag), reducing micro-overhead without caching.", "confidence": 0.9, "instance_id": "scipy__scipy-19324", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path by dispatching `correlation(..., centered=False)` to `cosine`, which is a shortcut. The Expert, however, performs a more systemic algorithmic refactor within the `correlation` function, including weight normalization and restructuring weighted calculations to leverage `np.dot` more efficiently.", "confidence": 0.9, "instance_id": "scipy__scipy-19583", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to replace `np.average` with a more explicit sequence of NumPy operations. However, the expert's solution leverages `np.dot` and an in-place division (`w /= w.sum()`), which are typically more deeply optimized (e.g., BLAS, avoiding temporary arrays) than the LM's explicit `np.sum(w * u_ne_v) / np.sum(w)` sequence, indicating a deeper understanding of NumPy's performance characteristics.", "confidence": 0.9, "instance_id": "scipy__scipy-19589", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization forces the 'asymptotic' method for large inputs, which is a 'fundamental change in the algorithm' from potentially exact to an approximation, introducing a semantic risk. The expert's optimization strictly preserves the original statistical behavior by refactoring tie calculation to avoid redundant computations, ensuring semantic preservation.", "confidence": 1.0, "instance_id": "scipy__scipy-19749", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path (`if arr.size > 10000 and method != 'ordinal':`) to switch to a different NumPy-based algorithm. The Expert, however, performs a more systemic refactoring of the core ranking logic, replacing less optimal NumPy operations with more direct and vectorized primitives that apply generally, rather than being gated by a specific condition.", "confidence": 0.9, "instance_id": "scipy__scipy-19776", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for setting the diagonal of an empty sparse matrix by directly constructing its internal arrays. The Expert, in contrast, performs a more systemic refactoring by avoiding intermediate Python object creation and method call overhead during sparse matrix format conversions and attribute assignments, which is a deeper improvement to the underlying data handling.", "confidence": 0.9, "instance_id": "scipy__scipy-19962", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific Python fast path for a narrow case, which implicitly avoids generic C overhead (a micro-optimization). The Expert, however, applies more fundamental and general micro-optimizations by avoiding redundant array allocations/copies (`asarray`) and replacing function calls with attribute lookups (`.size`), which are broadly applicable improvements to core array handling. Both involve micro-optimizations, but the expert's are deeper and broader in their general impact.", "confidence": 0.9, "instance_id": "scipy__scipy-20325", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for a specific input function (matrix squaring) by checking sample values. The Expert, conversely, applies a systemic optimization by offloading a general, computationally intensive loop within `funm` to Pythran-compiled native code, improving the general algorithm.", "confidence": 1.0, "instance_id": "scipy__scipy-21440", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization strategy is extensive caching and memoization of `linprog` results and sparse matrix constructions. In contrast, the Expert's optimization focuses on lowering the hot path by reducing Python interpreter overhead through hoisting attribute lookups out of a tight loop, making the existing computation faster without introducing caching.", "confidence": 1.0, "instance_id": "scipy__scipy-22660", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly conditional fast path for a very specific subset of integer inputs (2D, axis=-1, limited non-negative range) using `np.bincount`. The Expert, however, implements a more systemic, fully vectorized NumPy algorithm that applies to all multi-dimensional arrays (when axis=-1), replacing a less efficient approach with a sequence of optimized C-implemented NumPy operations.", "confidence": 0.9, "instance_id": "scipy__scipy-22676", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactoring and micro-overhead removal by pre-computing transformations and simplifying calculations for the `gaussian_kde` evaluation. However, the LM's approach is deeper as it fully vectorizes the core loop using NumPy broadcasting, eliminating the Python `for` loop entirely, while the expert's approach retains the Python loop but optimizes the operations within it.", "confidence": 1.0, "instance_id": "scipy__scipy-8558", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a module-level cache to store the result of `get_lapack_funcs` calls, avoiding repeated lookups. The Expert, instead, refactors the internal `find_best_blas_type` function, replacing a general-purpose NumPy call with a specialized, faster type-scoring system, thereby lowering the inherent cost of the type determination hotspot without using a cache.", "confidence": 1.0, "instance_id": "scipy__scipy-9455", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific `elif` branches with hardcoded formulas for `order=1` and `order=2` (a shortcut), while the Expert implements a general algorithmic refactor using matrix operations on polynomial coefficients that applies to all `order > 0` (a systemic solution).", "confidence": 0.9, "instance_id": "scipy__scipy-9766", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path by pre-computing and caching specific factorial values up to 100. The Expert, however, implements a systemic improvement by leveraging the C-optimized `gmpy` library for general arbitrary-precision factorial calculations.", "confidence": 0.9, "instance_id": "sympy__sympy-10621", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["Caching", "AlgorithmicRefactor"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for large inputs (`n >= 1000000`) and heavily relies on `lru_cache` for repeated calls. In contrast, the Expert performs a systemic algorithmic refactor of the `_a` function, replacing a naive summation with a sophisticated number-theoretic approach involving precomputation and specialized modular arithmetic, fundamentally lowering the computational complexity of the hotspot.", "confidence": 0.9, "instance_id": "sympy__sympy-10919", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization (caching) for `diop_DN` and its internal calls, storing results for repeated identical inputs. The expert's solution, however, implements a specialized, more efficient algorithm for a specific range of inputs, directly lowering the computational cost of the hotspot rather than just caching its output.", "confidence": 1.0, "instance_id": "sympy__sympy-11675", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization strategy involves extensive caching of symbolic operations like `msubs` and `partial_velocity`. In contrast, the expert's solution fundamentally re-architects the `Vector` class's internal component aggregation from O(N^2) to O(N) and reduces intermediate `Vector` object creation, thereby lowering the inherent cost of vector operations rather than just caching their results.", "confidence": 0.9, "instance_id": "sympy__sympy-11676", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path for a single, hardcoded input pattern. The Expert, conversely, performs a systemic refactoring of the SAT solving pipeline, introducing new data structures and algorithms to reduce redundant computations for a broad range of inputs.", "confidence": 1.0, "instance_id": "sympy__sympy-11789", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path specifically for matrices containing only integers, falling back to the original for other types. The Expert, however, implements systemic optimizations for `DenseMatrix` operations (addition and multiplication) that improve performance generally by reducing Python overhead, memory allocations, and copies, regardless of the specific element type.", "confidence": 0.9, "instance_id": "sympy__sympy-12640", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization uses `jacobi_symbol` as a 'special case' for the Legendre symbol, valid only when `p` is prime, which aligns with the workload. The Expert, in contrast, applies a systemic optimization by leveraging Python's highly optimized C-level built-in `pow(base, exp, mod)` for modular exponentiation, which is a general and fundamental performance improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-14772", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to avoid recomputing identical sub-expressions. The Expert, conversely, optimizes the hot path by removing a redundant `try...except TypeError` block, thereby eliminating unnecessary exception handling overhead and lowering the cost of the existing computation without adding a cache.", "confidence": 0.9, "instance_id": "sympy__sympy-15379", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for two arguments that uses `functools.lru_cache`. The Expert, in contrast, implements a more systemic change by replacing the existing manual Python caching logic for `igcd` with a C-optimized `fastcache.clru_cache`, thereby improving the general caching infrastructure.", "confidence": 0.9, "instance_id": "sympy__sympy-15453", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the same hotspot and propose the same core optimization strategy: replacing a generic, Python-loop-based matrix element-wise multiplication with a call to a more efficient, specialized internal method. The expert's explanation provides a slightly deeper and more explicit description of the underlying mechanisms of this optimized method, mentioning potential implementations in C, Cython, or NumPy, which the LM only implicitly suggests.", "confidence": 0.9, "instance_id": "sympy__sympy-15736", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces an 'Extremely fast path' for a specific number pattern, which is a form of shortcut, even if the LM's explanation notes it's not taken by the workload. The Expert's patch, in contrast, applies a more general algorithmic refactor (byte-by-byte reduction) to improve the `trailing` function's performance.", "confidence": 0.9, "instance_id": "sympy__sympy-15909", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow, pattern-specific fast path for 'Or' expressions composed solely of 'Symbol's. The Expert implements a more systemic change by introducing a configurable limit on the number of variables (8) for simplification, addressing the exponential time complexity of the problem for large inputs, which is a design decision about the function's behavior.", "confidence": 0.9, "instance_id": "sympy__sympy-16134", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["minimalism", "focus"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same core algorithmic optimization: replacing a Python function call with a C-optimized built-in `pow` function. However, the LM's patch also includes an irrelevant caching mechanism (`@cacheit`) that its own explanation states does not contribute to the benchmark's performance. The expert's patch is more minimal and precisely targets only the effective optimization, demonstrating a deeper understanding of what truly impacts performance for the given workload.", "confidence": 0.9, "instance_id": "sympy__sympy-17916", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces highly specific `if n == 13` and `if x == 13` fast paths, leveraging `math.log` for the benchmark's exact parameters. The Expert, in contrast, implements a systemic improvement by integrating the `gmpy` library's C-coded `iroot` function, providing a general, native-code solution for `integer_nthroot` for all large integer inputs when `gmpy` is available.", "confidence": 1.0, "instance_id": "sympy__sympy-18276", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces hardcoded early-exit conditions for the exact input values in the benchmark, acting as a narrow, specific shortcut. The Expert implements a more systemic module-level caching mechanism that dynamically populates lists of known values, providing a general solution for repeated checks of these number types.", "confidence": 0.9, "instance_id": "sympy__sympy-18591", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimizations introduce specific fast-paths and micro-optimizations within the existing Risch algorithm functions. In contrast, the Expert's changes involve a systemic refactor of the fundamental `Poly` class itself, improving its core design for memory, instantiation, and hashing, which is a broader, more foundational improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-19270", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a pattern-specific fast-path for `Sign(base**exp)` when the exponent is even. The Expert's optimization, however, refactors the conditional logic within the `sign` function's evaluation to avoid an expensive `im(a)` calculation for non-imaginary arguments, representing a more systemic improvement to the general execution flow by removing dead work.", "confidence": 0.9, "instance_id": "sympy__sympy-20228", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for `Poly` objects by delegating to a simpler string printer. The Expert, in contrast, implements a systemic optimization by refactoring the core `line_width` calculation to use a C-optimized `str.translate()` method, improving a fundamental utility for all pretty printing.", "confidence": 0.9, "instance_id": "sympy__sympy-20384", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific fast-paths and pattern matching for a narrow class of trigonometric-sqrt expressions, including a hardcoded result for a very specific pattern. The Expert, conversely, applies systemic algorithmic refactoring by optimizing fundamental symbol dependency checks using set operations and memoizing expensive function calls in polynomial solvers, which are general improvements to core SymPy operations.", "confidence": 0.9, "instance_id": "sympy__sympy-20989", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot with similar strategies (replacing Python loops with C-optimized list operations). However, the Expert's implementation for `_eval_eye` uses a more efficient C-optimized slice assignment for setting diagonal elements, whereas the LM's uses a Python `for` loop. The Expert also provides a deeper explanation of the `copy=False` flag and its impact on the matrix constructor.", "confidence": 0.9, "instance_id": "sympy__sympy-21006", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces five distinct memoization caches and an ASCII-specific fast path. The expert's optimization refactors a core loop to reduce function calls and intermediate object allocations, thereby lowering the overhead of the hot path directly rather than caching its results.", "confidence": 0.9, "instance_id": "sympy__sympy-21169", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations, with the LM focusing on algorithmic and micro-architectural improvements for matrix multiplication, and the Expert on Python object instantiation overhead. The Expert's optimization for `GaussianElement` instantiation is broader in its general applicability to all `GaussianElement` creations, fitting the 'Expert is broader' criterion for SameStrategy_DepthGap.", "confidence": 0.9, "instance_id": "sympy__sympy-21391", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific early-exit fast path for the benchmark's exact query and adds global caching. The Expert, in contrast, performs a systemic algorithmic refactor by expanding the pre-computed knowledge base of logical implications, transforming a multi-step inference into a direct lookup for the benchmark's query and many others.", "confidence": 0.9, "instance_id": "sympy__sympy-21455", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces hardcoded, specialized determinant formulas for small matrix sizes (1x1, 2x2, 3x3, 4x4) as fast paths. In contrast, the Expert replaces the general fraction-free Gaussian elimination algorithm with the Bareiss algorithm, which is a systemic algorithmic improvement for determinant calculation across various matrix sizes and domains.", "confidence": 0.95, "instance_id": "sympy__sympy-21501", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization (caching) to numerous helper functions. The expert's optimization, in contrast, directly lowers the cost of fundamental arithmetic operations by adding early-exit fast paths for common cases (e.g., adding zero, multiplying numbers), thereby avoiding expensive symbolic simplification calls.", "confidence": 1.0, "instance_id": "sympy__sympy-21543", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path for `q=1000` with a specialized GCD, acting as a pattern-specific hack. The Expert, in contrast, implements a more systemic refactor to eliminate redundant `Rational` object creation when integer arguments are passed, improving the general case for `Rational(int, int)`.", "confidence": 0.9, "instance_id": "sympy__sympy-21954", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces function-level memoization (`@cacheit`) to cache the results of `manualintegrate`. In contrast, the Expert optimizes the `special_function_rule` by refactoring expensive symbolic object creation and pattern construction into a lazily initialized module-level cache, and uses `evaluate=False` to reduce expression creation cost, thereby lowering the inherent cost of the hot path rather than just caching its output.", "confidence": 0.9, "instance_id": "sympy__sympy-23696", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization (caching) to speed up helper functions within the existing `necklaces` algorithm. The expert, in contrast, completely replaces the `necklaces` function with a more efficient FKM algorithm, thereby lowering/removing the hotspot by avoiding the generation of redundant intermediate sequences altogether, rather than caching their results.", "confidence": 0.95, "instance_id": "sympy__sympy-24313", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized, persistent cache and a conditional fast path for specific `Mul` structures, heavily exploiting the benchmark's `timeit` setup. The Expert performs an algorithmic refactor of the `_eval_is_zero` method, fundamentally changing its complexity from O(N) to O(1) for the relevant case, representing a systemic improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-24485", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactoring. The LM's approach optimizes the execution pattern of symbolic operations by hoisting calculations and using list comprehensions. The Expert's approach implements a deeper algorithmic change by replacing an expensive generic symbolic substitution with more efficient, specialized matrix algebra, fundamentally altering how a core calculation is performed.", "confidence": 0.9, "instance_id": "sympy__sympy-24792", "repo": "sympy/sympy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that a significant portion of its patch (the new `divfree.py` module and its functions) is 'not directly used by this workload', indicating optimization of an unexercised path. The Expert's explanation, conversely, targets a measured hotspot (`Mul.flatten`) that is heavily relied upon by the workload.", "confidence": 0.9, "instance_id": "sympy__sympy-24884", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for 2x2 matrix inversion using a hardcoded formula. The Expert, in contrast, implements a systemic change by integrating the DomainMatrix approach as a new default method for matrix inversion, which is a more general algorithmic refactor.", "confidence": 0.9, "instance_id": "sympy__sympy-25452", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast path (early exit) for a particular query pattern, bypassing the general SAT solver. The expert, in contrast, implements a systemic change by refactoring the fact-loading mechanism to conditionally load only relevant facts based on expression kinds, thereby reducing the overall data processed by the SAT solver for a broader range of queries.", "confidence": 1.0, "instance_id": "sympy__sympy-25591", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes several hardcoded test cases for specific small ranges, acting as narrow fast-paths. In contrast, the Expert's patch applies a systemic algorithmic refactor to the existing Python sieve implementation, making it more efficient and correct by only processing prime factors.", "confidence": 0.9, "instance_id": "sympy__sympy-25631", "repo": "sympy/sympy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Heuristic/ParamTuning"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly introduces an approximation for the characteristic polynomial of submatrices within the Berkowitz algorithm, which risks altering the mathematical output. The expert's optimization, conversely, preserves exact mathematical behavior by leveraging matrix sparsity to avoid iterating over zero elements and reducing iteration overhead, thus removing dead work.", "confidence": 1.0, "instance_id": "sympy__sympy-26057", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific early-exit fast-path for identity matrices. The Expert, in contrast, fixes a systemic inefficiency in argument handling for symbol generation within the general matrix solver, which is a structural improvement to a core utility function.", "confidence": 0.9, "instance_id": "sympy__sympy-26063", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is memoization (caching) of symbolic derivatives. The expert, however, replaces the expensive symbolic differentiation with an algorithmic refactor using `linear_eq_to_matrix` to directly extract coefficients, which are the derivatives, thus lowering the cost of the hot path without caching.", "confidence": 1.0, "instance_id": "sympy__sympy-26367", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a hardcoded cache for specific input values, acting as a narrow fast path for the benchmarked input. In contrast, the expert performs a systemic algorithmic refactor of the `_primepi` function, introducing odd-number iteration and sieve-based composite skipping to generally improve its efficiency.", "confidence": 1.0, "instance_id": "sympy__sympy-26710", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a shortcut that pre-populates the global sieve with more primes, effectively a narrow fast-path for very small `n`. The expert, however, introduces an algorithmic refactor for `prime(n)` for `n < 1000`, replacing an expensive symbolic approximation with a direct, efficient sieve extension and lookup, which is a more systemic improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-27051", "repo": "sympy/sympy"}
