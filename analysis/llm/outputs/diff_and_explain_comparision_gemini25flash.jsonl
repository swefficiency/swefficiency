{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path guard (`isinstance` check) to bypass a general Python method call (`_unbox`). The Expert applies a more systemic optimization by changing the underlying NumPy array view to `int64` to leverage a significantly faster, more primitive NumPy comparison algorithm for `datetime64` values.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38248", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["semantic_edge_case"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization: replacing an expensive `np.asarray` call with a Cython loop for checking boolean lists. The expert's patch, however, includes an additional `len(key) > 0` guard in `common.py`, which subtly alters the behavior for empty lists (returning `False` instead of `True`) compared to the LM's patch and the original implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41861", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe deep optimizations for the same hotspot. The LM optimizes a specific NumPy operation by rewriting it in Cython for direct implementation efficiency. The Expert introduces a broader algorithmic refactor by adding a new, specialized algorithm and conditional dispatch for a common input pattern, leveraging multiple optimized primitives.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-42293", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-optimization of a single C function call (`sqrt`) within Cython. The Expert's optimization is a systemic change that enables a more efficient 'block-wise' data processing strategy for `groupby().std()`, fundamentally altering how data is handled across multiple columns, which is an algorithmic refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43115", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a sub-component (replacing an O(N) `data.min()` call with an O(1) lookup) within an existing O(N) copy-and-modify operation, and adds a fast path. The Expert performs a systemic refactor by changing the method's contract and implementation to avoid the O(N) copy and modification entirely, making the overall operation O(1).", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45434", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation states that the provided git patch is empty and thus no code changes or optimizations can be analyzed. This prevents a meaningful comparison of optimization strategies.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-46745", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation includes an optimization for `pickle.dumps` (removing `list()` conversions) which is not the measured workload, even if it claims indirect benefits for `pickle.loads`. The expert's explanation, however, exclusively targets the `verify_integrity=False` flag, which directly optimizes the `pickle.loads` operation, the actual hotspot.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-47916", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for `DataFrame.duplicated` when all subset columns are `object` dtype, leveraging C-hashing for this specific pattern. The expert refactors the core `factorize` algorithm to conditionally avoid an unnecessary `np.where` call, which is a more systemic improvement to the algorithm's general efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48620", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactoring and micro-optimizations. The LM directly refactors the `explode` function's core algorithm. The Expert refactors a core type inference utility (`maybe_convert_objects`) to allow early exits for specific call patterns, making it more broadly efficient for its callers, indicating a broader systemic impact.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51517", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states its optimization is not activated by the workload due to default parameter values, making it unaligned with the hotspot. The expert's optimization, however, directly targets the workload's bottleneck by limiting integrity checks to only the modified levels, thus aligning with the hotspot.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-51873", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert explanations describe the exact same optimization strategy (replacing a Python list comprehension with a C/Cython-optimized `Index.intersection` call) applied to the same hotspot, with identical scope and semantic impact. There is no discernible difference in their approach or depth.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52941", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert introduce fast paths for vertical DataFrame concatenation by leveraging NumPy operations. The Expert's approach is deeper by directly using `np.concatenate` on the underlying NumPy arrays for the entire block, which is a more efficient and idiomatic NumPy pattern for this task compared to the LM's column-wise iteration and slice assignment.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53772", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The Expert's patch introduces a systemic fix by correctly routing `StringDtype[pyarrow]` to the PyArrow-native factorization path, avoiding an expensive conversion to Python objects. In contrast, the LM's patch applies micro-optimizations within an *already engaged* PyArrow path, refining specific PyArrow API calls and null handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54510", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization using `functools.lru_cache` to cache function results. The Expert, conversely, implements a fastpath (early-exit optimization) within the function itself, which directly lowers the computational cost of the hotspot for common cases, effectively making the work cheaper rather than caching its output.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57478", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations include elements of micro-overhead removal. However, the Expert's changes are deeper and broader in this specific tactic, targeting fundamental overheads like unnecessary DataFrame copies for `inplace=True` and redundant unit conversions in core helpers, making existing paths more efficient. The LM's micro-optimizations are embedded within its new, vectorized implementation and specialized dispatch.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-57479", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly states it \"trades off a negligible amount of precision\" for performance, indicating a potential semantic change. In contrast, the Expert's optimization strictly preserves behavior by eliminating a redundant, unnecessary call to a low-level function, thus having no semantic impact.", "confidence": 1.0, "instance_id": "astropy__astropy-10814", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's proposed optimization involves removing the entire FITS unit format implementation, which would fundamentally change the behavior of the workload from parsing FITS units to failing or falling back. In contrast, the expert's explanation describes a bug fix that correctly propagates an argument to avoid unnecessary work during FITS unit parsing, thereby preserving the intended semantics while improving performance.", "confidence": 1.0, "instance_id": "astropy__astropy-12699", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized path guarded by a specific NumPy array dtype, which acts as a pattern-specific hack for that input. The Expert introduces an early exit for the common '*' pattern in a format selection function, which simplifies the function's logic for its most general query, akin to a structural redesign.", "confidence": 0.8, "instance_id": "astropy__astropy-12701", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The Expert's patch introduces a semantic risk by incorrectly returning `True` for the `changed` flag in `convert_input` when no actual transformation occurs. In contrast, the LM's patch correctly returns `False` in this fast-path scenario, preserving the documented behavior of the `changed` flag.", "confidence": 0.9, "instance_id": "astropy__astropy-13471", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new fast path (specific 'elif' block) to optimize object creation by avoiding an intermediate copy for NumPy array inputs. The Expert, however, removes a redundant NumPy operation ('np.nan_to_num') from a core utility function ('_wrap_at'), which was dead work for the given workload, representing a deeper cleanup of an existing hot path.", "confidence": 0.9, "instance_id": "astropy__astropy-13497", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe the exact same early-exit optimization in `ManualInterval.get_limits` to avoid `np.asarray().ravel()` when `vmin` and `vmax` are already set. There is no discernible difference in strategy, depth, or scope between the two explanations.", "confidence": 1.0, "instance_id": "astropy__astropy-13898", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "Both the LM and Expert identify the same early-exit fast-path optimization for `ManualInterval.get_limits`. The Expert's explanation, however, is deeper by explicitly detailing all the expensive NumPy operations (`np.asarray().ravel()`, `np.min()`, `np.max()`) that are bypassed, while the LM primarily focuses on `np.asarray().ravel()`.", "confidence": 0.9, "instance_id": "astropy__astropy-13899", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["CorrectnessFix", "BuildSystem"], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch primarily addresses a correctness issue (test failure due to build system incompatibility) which then enables the intended, faster code path. This constitutes a change from incorrect to correct behavior. The expert's patch, in contrast, performs a micro-optimization that strictly preserves the existing, correct behavior while improving performance.", "confidence": 0.9, "instance_id": "astropy__astropy-15900", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a fast path that sets `copy=False` for NumPy array inputs, which could potentially alter the documented behavior regarding input array modification. The expert's patch uses `functools.cache` for memoization, a purely performance-enhancing change that explicitly preserves the original semantics.", "confidence": 0.9, "instance_id": "astropy__astropy-16088", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["NumPy_idiom", "micro-optimization"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to NumPy array validation within the same function. The LM combines two `np.any` calls using a bitwise OR, while the Expert uses `np.abs` to simplify the range check, which is a more idiomatic and potentially deeper optimization in NumPy, reducing distinct operations and allowing for better internal fusion.", "confidence": 0.9, "instance_id": "astropy__astropy-16096", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe fast-path optimizations. However, the LM's fast path is at the `SkyCoord` constructor level, avoiding Python-level dispatch, while the Expert's is a deeper early-exit optimization in a low-level angle utility (`_wrap_at`) that avoids expensive NumPy array operations on large datasets.", "confidence": 0.9, "instance_id": "astropy__astropy-16222", "repo": "astropy/astropy"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM implements a custom, global cache within the `_UnitMetaClass` to memoize `Unit` object creation from strings, affecting the entire `astropy.units` subsystem. The Expert uses the standard library `@functools.cache` decorator on a specific method within the `Angle` class, which is a more localized and maintainable approach.", "confidence": 0.9, "instance_id": "astropy__astropy-16243", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path using an `isinstance` guard to bypass NumPy for scalar inputs while retaining the NumPy path for arrays. The Expert, conversely, performs a more systemic refactor by replacing NumPy operations with native Python scalar operations and restructuring the conditional logic across multiple related functions, effectively making them scalar-only (as indicated by type hints) and removing the NumPy dependency for their core logic.", "confidence": 0.9, "instance_id": "astropy__astropy-16295", "repo": "astropy/astropy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch is primarily cosmetic, with its only functional change being a build system dependency pin, offering a speculative and indirect explanation for performance. The expert's patch directly targets the measured hotspot with concrete micro-optimizations, dead work removal, and early exits within the core evaluation logic, directly impacting the workload's execution path.", "confidence": 0.9, "instance_id": "astropy__astropy-16670", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimizations are micro-level, focusing on common subexpression elimination and reducing array conversions. The Expert's optimizations are systemic, involving algorithmic refactoring like hoisting invariant computations out of the hot loop and redesigning parameter handling and model evaluation to reduce overhead.", "confidence": 0.9, "instance_id": "astropy__astropy-16673", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path guard (object identity check) and caching. The Expert, however, implements a more systemic refactor by conditionally bypassing a significant and unnecessary overhead (creating a duplicate registry) within the decorator's core logic, which is a deeper structural improvement.", "confidence": 0.9, "instance_id": "astropy__astropy-16742", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces `lru_cache` to memoize results of `CDS.parse`, effectively caching repeated identical calls. The Expert, however, refactors the internal unit parsing logic to directly construct `CompositeUnit` objects, avoiding intermediate object creation and method call overhead, thereby lowering the cost of the hot path itself rather than just caching its output.", "confidence": 1.0, "instance_id": "astropy__astropy-16813", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM introduces caching layers to avoid re-computation for repeated inputs, which is a pattern-specific optimization. Expert implements a centralized, early-exit fast path for simple unit strings, representing an algorithmic refactor and structural redesign of the parsing process to inherently make it faster for common cases.", "confidence": 0.9, "instance_id": "astropy__astropy-17004", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization via `lru_cache` to avoid re-computing results for repeated inputs. In contrast, the expert optimizes the actual computation within the hot path by refactoring the `CompositeUnit` construction to reduce object allocations and skipping redundant error checks, thereby lowering the intrinsic cost of the work.", "confidence": 1.0, "instance_id": "astropy__astropy-17043", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to avoid re-computation for identical inputs. The expert, however, focuses on algorithmic improvements (e.g., optimizing unit comparison and sorting complexity) and micro-optimizations to make the core computation itself faster, rather than just caching its results.", "confidence": 1.0, "instance_id": "astropy__astropy-17425", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a specific parameter tweak (`lazy_load_hdus=False`) creating a fast path for a particular function call by avoiding unnecessary setup. The Expert's optimization is a systemic caching mechanism implemented in a core configuration component, representing a broader structural redesign that improves the general case of configuration access.", "confidence": 0.9, "instance_id": "astropy__astropy-17461", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both patches apply micro-optimizations by introducing fast paths and removing Python overhead. The LM's patch optimizes a specific `__getitem__` call pattern within a generic dispatcher. The Expert's patch optimizes the `__setattr__` method in a base class, skipping an expensive check for all internal attributes during object initialization, which is a more fundamental and broader removal of dead work in the object's lifecycle.", "confidence": 0.9, "instance_id": "astropy__astropy-6940", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization strategy of bypassing `__init__` using `__new__` for object creation during slicing. However, the expert's solution is broader, applying the optimization across multiple related classes, and deeper, explicitly acknowledging the potential semantic risk of bypassing `__init__` for custom implementations, which the LM's explanation omits.", "confidence": 0.9, "instance_id": "astropy__astropy-6941", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a single, narrow fast path for a specific ufunc/method combination (`np.add.reduce`). The Expert, in contrast, implements multiple early-exit optimizations and identity checks that structurally improve the general efficiency of the unit handling subsystem for various operations where units are identical, representing a more systemic redesign.", "confidence": 0.9, "instance_id": "astropy__astropy-7010", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations within the `MaskedColumn` constructor. However, the expert's solution is deeper, targeting a specific, documented, and highly impactful performance trap in the underlying `numpy.ma.MaskedArray` when `mask=None` is passed. The LM's solution is a refactoring of `MaskedColumn`'s own object creation, which might be less impactful than the expert's targeted fix for the true bottleneck.", "confidence": 0.9, "instance_id": "astropy__astropy-7422", "repo": "astropy/astropy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies a single micro-optimization (replacing `Fraction(1, 2)` with `0.5`). The Expert includes this same optimization but also implements several other related micro-optimizations across multiple files, collectively reducing overhead in the core unit exponentiation and composite unit creation logic, demonstrating a broader and deeper optimization strategy within the same tactic family.", "confidence": 0.9, "instance_id": "astropy__astropy-7549", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path to bypass a property setter for specific input conditions, acting as a shortcut. The Expert, in contrast, optimizes the underlying mechanism of the property setter itself by avoiding an unnecessary data copy, which is a more systemic improvement to data handling.", "confidence": 0.9, "instance_id": "astropy__astropy-7616", "repo": "astropy/astropy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["LM_FailedToIdentifyOptimization"], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation incorrectly states that its patch introduces no performance optimization, effectively missing the entire point of the task. The expert, conversely, precisely identifies and explains a targeted early-exit optimization for the workload's hotspot, directly aligning with the performance goal.", "confidence": 1.0, "instance_id": "astropy__astropy-7643", "repo": "astropy/astropy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation states its patch is the workload script itself and does not modify any library code, thus failing to provide any optimization for the hotspot. The expert's patch, however, introduces multiple fast-paths and micro-optimizations directly within the `astropy.units.CompositeUnit` constructor, which is the workload's measured hotspot.", "confidence": 1.0, "instance_id": "astropy__astropy-7649", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache to avoid repeated computation of `_get_deriv_key`. The expert, instead, refactors the internal logic of `_get_deriv_key` to make the unit decomposition significantly faster, thereby lowering the cost of the hotspot itself rather than just caching its results.", "confidence": 1.0, "instance_id": "astropy__astropy-7924", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a pattern-specific optimization by precomputing mathematical terms for a single model's evaluation. The Expert, however, implements a structural redesign by optimizing the recursive traversal and mapping logic for compound models, which is a more systemic improvement to how these models handle their internal structure.", "confidence": 0.9, "instance_id": "astropy__astropy-8349", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes low-level data handling (binary I/O, bytearray for buffering) to create a faster data path. In contrast, the Expert applies algorithmic refactoring to the core parsing logic and structurally redesigns header object construction for more systemic performance gains.", "confidence": 0.9, "instance_id": "astropy__astropy-8428", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Caching/Memoization", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a Cython shim with a hardcoded cache for specific column names ('a' through 'e'), acting as a pattern-specific fast path for the benchmark's `Row.__getitem__` calls. The Expert, in contrast, applies a general algorithmic refactor to `Table.__len__` (O(N_cols) to O(1)) and a micro-optimization to `Row.__getitem__` that benefits any single column access, improving the general case.", "confidence": 0.9, "instance_id": "astropy__astropy-8494", "repo": "astropy/astropy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path early-exit by stopping file reading once the target extension is found. The Expert, however, implements a systemic redesign of header parsing, utilizing Cython for native performance, introducing lightweight header objects, and employing lazy evaluation to avoid parsing unnecessary card types for intermediate HDUs.", "confidence": 1.0, "instance_id": "astropy__astropy-8502", "repo": "astropy/astropy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the default behavior of `m.info` from printing to standard output to returning an `OrderedDict`, thus altering the observable output. The expert's optimization, in contrast, makes systemic internal improvements to the `DataInfo` class using `__slots__` and descriptors, explicitly stating it should not affect simple subclasses and preserving documented behavior.", "confidence": 1.0, "instance_id": "astropy__astropy-8998", "repo": "astropy/astropy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization (caching) to avoid re-computation for identical inputs. In contrast, the expert's optimization fundamentally lowers the cost of the computation itself by replacing a slow Python loop with a vectorized NumPy implementation, thus lowering the hot path rather than just caching its results.", "confidence": 1.0, "instance_id": "dask__dask-10356", "repo": "dask/dask"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM attributes performance to a `from dask.dataframe import align` statement, claiming it reduces symbol lookup overhead, which is likely to have negligible impact. The expert, however, correctly identifies and optimizes the true hotspot: redundant `astype` calls leading to costly memory allocations and copies during DataFrame partition creation, which is a significant performance bottleneck for the given workload.", "confidence": 0.9, "instance_id": "dask__dask-10428", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a narrow guard that skips a redundant `explode()` call which is a no-op for specific dtypes. The Expert's optimization is a more systemic algorithmic refactor, introducing a fast path that leverages highly optimized, C/Cython-implemented Pandas operations (`drop_duplicates`, `set_index`) for the core logic.", "confidence": 0.9, "instance_id": "dask__dask-10922", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for already-sorted or reverse-sorted arrays by adding conditional checks. The Expert, however, performs a systemic refactor of the `_vindex_array` function, replacing Python-level loops and `bisect` calls with highly optimized, vectorized NumPy operations for general cases, which is an algorithmic and native code improvement.", "confidence": 1.0, "instance_id": "dask__dask-11625", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization enables an existing 'inline_functions' fast path for a specific pattern (leaf tasks). The Expert's optimization is a more systemic refactor of a core utility function ('ensure_dict') to avoid redundant work, improving the general efficiency of graph merging.", "confidence": 0.9, "instance_id": "dask__dask-5501", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path for single-partition indexing (`npartitions=1` and `loc[0]`), which is a narrow guard. The Expert, in contrast, implements a more systemic improvement to metadata generation by caching `_nonempty_series` results based on dtype within a core utility function, which is an algorithmic refactor improving the general case.", "confidence": 0.9, "instance_id": "dask__dask-5553", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM performs a systemic algorithmic refactor by completely rewriting `da.block` to consolidate multiple traversals into two, reducing overall Python overhead. In contrast, the Expert adds a narrow fast-path guard to `atleast_nd` to avoid a specific micro-overhead when `diff == 0`. This represents a difference between a systemic redesign and a shortcut micro-optimization.", "confidence": 0.9, "instance_id": "dask__dask-5884", "repo": "dask/dask"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a global memoization cache to `dask.array.optimize` that benefits from repeated calls with identical object inputs. The Expert adds a fast path within `rewrite_blockwise` to avoid complex graph processing for simple, single-input blockwise operations, effectively lowering the cost of this specific hotspot.", "confidence": 1.0, "instance_id": "dask__dask-5890", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization creates a generator, which acts as a 'fast path' for this specific workload because the workload does not consume the generator's output, effectively skipping all work. The expert, however, implements an algorithmic refactor that drastically reduces the number of Python objects created, providing a systemic performance improvement for the function in all general use cases.", "confidence": 1.0, "instance_id": "dask__dask-5891", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by changing default parameters for an existing graph fusion algorithm, making it more aggressive. The Expert applies an algorithmic refactor by moving the fusion call earlier in the graph construction and a micro-optimization (generator expression) to enable in-place NumPy operations, representing a more systemic improvement.", "confidence": 0.9, "instance_id": "dask__dask-5933", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and aim to reduce Python overhead in the graph generation loop. The LM optimizes by avoiding the creation of large intermediate lists and using direct dictionary insertion. The Expert's approach is deeper, introducing pre-computed mappings and replacing expensive dictionary lookups with highly efficient tuple indexing for coordinate resolution within the innermost loop.", "confidence": 0.9, "instance_id": "dask__dask-5940", "repo": "dask/dask"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch is a pure whitespace change, explicitly stated to have no performance impact, thus being completely unaligned with any hotspot. The Expert's patch, however, directly targets a measured hotspot (`_compute_sum_of_squares` within `groupby().agg(['std'])`) by replacing an inefficient `groupby().apply()` with vectorized operations and an optimized `groupby().sum()`.", "confidence": 1.0, "instance_id": "dask__dask-6186", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path for `da.stack` when dealing with homogeneous `da.from_delayed(np.zeros/ones/empty)` arrays, bypassing general graph construction. The Expert, conversely, implements a systemic algorithmic refactor within `HighLevelGraph.from_collections` to efficiently handle any single-dependency graph construction, a more general improvement to Dask's core graph building.", "confidence": 1.0, "instance_id": "dask__dask-6293", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both optimizations aim to reduce overhead. The LM reduces scheduler overhead by increasing Dask array chunk sizes via a configuration change. The Expert, however, implements a deeper algorithmic refactor using `np.broadcast_to` to fundamentally reduce memory allocation and object creation during the construction of uniform Dask arrays, which is a more profound and systemic optimization for the array creation hotspot.", "confidence": 0.9, "instance_id": "dask__dask-6491", "repo": "dask/dask"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a systemic change (vectorization), while the Expert's is a micro-optimization (avoiding implicit type conversions). Although this aligns with the conceptual difference between 'systemic' and 'shortcut' optimizations, the specific conditions for 'Shortcut_vs_Systemic' and 'SameStrategy_DepthGap' in the rubric's mapping rules are not met, as the LM performs the more systemic/deeper change.", "confidence": 0.8, "instance_id": "dask__dask-6669", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert implement caching for the `Array.shape` property. However, the Expert's solution is deeper and broader by introducing a generic `cached_property` decorator (backported from `functools`) and modifying `__slots__` to enable its use, making the caching mechanism more robust and reusable compared to the LM's ad-hoc manual caching implementation.", "confidence": 0.9, "instance_id": "dask__dask-7023", "repo": "dask/dask"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["CacheInvalidation"], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces caching but fails to implement proper cache invalidation when the underlying `_chunks` attribute changes, which is a critical correctness issue highlighted by the workload. The Expert's patch correctly implements both caching and the necessary cache invalidation logic, preserving the array's semantic behavior.", "confidence": 1.0, "instance_id": "dask__dask-7104", "repo": "dask/dask"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization: replacing a Python-level iterator-based merge sort with vectorized NumPy operations (concatenate, argsort, take). The expert's explanation provides a slightly deeper analysis by explicitly noting that `tlz.merge_sorted` is most efficient for *already sorted* inputs, which was not the case in the workload, making the NumPy approach more robust and correct.", "confidence": 0.9, "instance_id": "dask__dask-7172", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization adds a specific fast-path for `np.sum` by configuring Dask's inlining mechanism. In contrast, the Expert performs a systemic algorithmic refactor of Dask's topological sort and optimizes fundamental set operations within graph processing, improving core graph mechanics rather than a specific function's handling.", "confidence": 0.9, "instance_id": "dask__dask-7403", "repo": "dask/dask"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes a specific, non-essential logging call, which is a narrow overhead removal. In contrast, the Expert's optimization involves an algorithmic refactor to the `StrCategoryFormatter` by introducing a batch `format_ticks` method, which structurally redesigns the tick formatting process to avoid redundant computation.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-13917", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism to skip redundant calls to `tight_layout`. The Expert, in contrast, implements an early-exit optimization within the `get_tightbbox` method, avoiding expensive computations for heavily clipped artists, which is a form of dead work removal rather than caching.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-14504", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization strategy of vectorizing a Python loop using NumPy. The Expert's implementation, while functionally equivalent, demonstrates slightly more idiomatic and compact NumPy usage (e.g., `np.divide(where=...)`, advanced indexing for `Rneg`), indicating a subtle depth in NumPy expertise.", "confidence": 0.8, "instance_id": "matplotlib__matplotlib-15346", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces memoization (caching) to avoid re-computation for identical inputs. In contrast, the Expert refactors the function's internal logic to eliminate unnecessary NumPy array allocations and conversions, thereby lowering the cost of the hot path itself for a broader range of inputs.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-15834", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by chunking the input to `textwrap.fill`, making the existing general-purpose function less costly for large data. The Expert, however, performs a more systemic algorithmic refactor by replacing `textwrap.fill` entirely with a specialized, more efficient string slicing and joining method tailored for the specific hexadecimal data.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17177", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces conditional logic (a fast path/guard) to bypass specific C++ object constructions for simple clip paths. The Expert introduces an algorithmic refactor by adding an early exit for degree 0/1 Bezier curves, fundamentally simplifying the mathematical computation for these common, simple cases.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17994", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch primarily enables path simplification for polygons via a condition change (a fast path enablement) and then re-architects the C++ path processing pipeline. The Expert's patch introduces a fast path for bounding box calculation that leverages NumPy's efficient vectorized operations, replacing Python-level loops.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-17995", "repo": "matplotlib/matplotlib"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch is not an optimization at all, but merely the workload script itself, making it entirely unaligned to any performance hotspot. The expert's patch, in contrast, directly targets a measured hotspot by introducing an LRU cache for `os.path.realpath` within Matplotlib's font management, which is repeatedly called by the workload.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-18018", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same core optimization: replacing Python-level iteration with a C-optimized NumPy `astype` conversion. However, the expert's patch and explanation demonstrate a deeper refactoring by completely removing the inefficient `np.vectorize`-based functions and unifying scalar and array input handling, making the overall solution more robust and cleaner.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-18756", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces global caching to avoid re-running expensive external TeX processes and DVI parsing for identical inputs. The Expert, instead of caching, optimizes the internal PostScript tokenizer's hot loop by reducing string allocations and regex overhead, thereby lowering the cost of each execution of the hot path.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-19564", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations that remove unnecessary work. However, the expert's optimization targets a more significant and broadly used source of overhead (expensive `inspect.Signature.bind()` calls within a common `@deprecated` decorator), making it a deeper and more impactful optimization within the same strategy family compared to the LM's removal of a single attribute assignment.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-19760", "repo": "matplotlib/matplotlib"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the FFMpeg encoding preset to 'ultrafast', which alters the output video's quality and file size, thus changing its behavior. The expert's optimization, however, removes dead work by skipping calculations for invisible 3D artists, which preserves the visual output and documented behavior.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-21564", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert apply the same core optimization strategy: replacing NumPy array creation and `np.dot` with direct, in-place scalar arithmetic to reduce overhead for small matrices. The difference lies in a minor implementation detail of how matrix elements are accessed (LM uses direct indexing, Expert uses `tolist()` then unpacking), indicating a depth gap within the same strategy family.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-22108", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization introduces caching for text layout to avoid recomputation. The Expert's optimization, however, refactors the underlying pyparsing grammar to reduce the inherent overhead of mathtext parsing, effectively lowering the cost of the hotspot itself rather than just caching its output.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-22875", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization (result caching) to avoid re-computation for identical inputs. The expert's optimization, however, lowers the cost of the hot path by replacing an inefficient regex-based string operation with a highly optimized, C-implemented `str.translate()` method, making the operation faster for all inputs, not just cached ones.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-23287", "repo": "matplotlib/matplotlib"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization comments out import statements, which risks altering the module's behavior or breaking functionality if the removed symbols are used. The expert's optimization uses memoization (lru_cache) to speed up expensive introspection calls, a purely performance-enhancing change that preserves all documented behavior.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-23759", "repo": "matplotlib/matplotlib"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a narrow guard (`if _title is not None`) that prevents an error and skips calls on `None` objects. The Expert's approach is a systemic refactor of the `Axis` and `Spine` initialization logic, introducing a `clear` parameter and removing redundant `clear()` calls to avoid significant unnecessary work.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-26164", "repo": "matplotlib/matplotlib"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization adds an unbounded cache to avoid re-computation for repeated inputs in the benchmark. The Expert's optimization, however, refactors the underlying grammar construction logic to make the parsing process itself inherently faster, lowering the cost of the hot path rather than just caching its results.", "confidence": 1.0, "instance_id": "matplotlib__matplotlib-26198", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations targeting Python interpreter overhead in the `savefig(bbox_inches='tight')` path. The LM reduces `lambda` object creation in a loop over axes, while the Expert inlines a list comprehension to remove function call overhead in the `get_tightbbox` method. The Expert's change is considered 'deeper' as it optimizes a more central and fundamental step (artist collection) within the core `get_tightbbox` logic, compared to the LM's optimization of a temporary attribute assignment.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-26899", "repo": "matplotlib/matplotlib"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same primary hotspot in `plot_wireframe` and propose the same core optimization strategy (NumPy vectorization). However, the Expert's solution is broader and deeper, also optimizing bounding box extent calculations by refactoring C++ code to use NumPy, which the LM does not address.", "confidence": 0.9, "instance_id": "matplotlib__matplotlib-29399", "repo": "matplotlib/matplotlib"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["factual_error", "inverted_logic"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation is based on a factual error: it misinterprets `len(operands)` for the workload, believing `einsum` was unoptimized. It claims its patch *enables* optimization. The expert correctly identifies that `einsum` was already optimizing and the patch *disables* the costly optimization algorithm. The LM's understanding of the problem (the hotspot) is fundamentally misdirected.", "confidence": 0.9, "instance_id": "numpy__numpy-11720", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path specific to the `numpy.hstack` function for a particular input pattern (list of 1D arrays). The Expert, however, optimizes a more systemic component, the `__array_function__` dispatch mechanism, by adding an early exit for the common case of `ndarray`-only arguments, which has a broader impact on NumPy's performance.", "confidence": 0.9, "instance_id": "numpy__numpy-12321", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactors. The LM optimizes a specific data flow by avoiding expensive string construction and parsing. The Expert, however, addresses a more fundamental O(N^2) algorithmic complexity in a utility function (`find_duplicate`), making its improvement deeper and more broadly applicable to any caller of that utility.", "confidence": 0.9, "instance_id": "numpy__numpy-12575", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same core optimization: avoiding an expensive string concatenation and parsing when constructing a numpy.dtype from a list of format strings. However, the Expert's patch is broader, also removing the redundant string join operation within the `fromarrays` function, making its application of the strategy deeper and more comprehensive.", "confidence": 0.9, "instance_id": "numpy__numpy-12596", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a brittle fast-path specifically for a function named 'pad_with', assuming it behaves like 'constant' mode and directly using a C-optimized `_pad_simple`. The Expert, however, implements a more general algorithmic refactor by replacing `np.apply_along_axis` with a manual, zero-copy iteration loop that benefits any in-place custom padding function, representing a systemic improvement.", "confidence": 0.9, "instance_id": "numpy__numpy-13250", "repo": "numpy/numpy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes extensive C-level optimizations for `np.clip`, which the LM's explanation explicitly states are irrelevant to the provided workload. The expert's patch, and its explanation, exclusively target the measured hotspot (`np.hstack` and `np.vstack`) with Python overhead reduction.", "confidence": 1.0, "instance_id": "numpy__numpy-13697", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both optimizations involve micro-overhead removal. The LM introduces a specialized fast-path with a distinct calculation for a specific input (median), while the Expert removes a redundant, always-executed function call (`np.moveaxis`) for a common input (`axis=0`), representing a deeper cleanup of general overhead in the function's setup.", "confidence": 0.9, "instance_id": "numpy__numpy-18203", "repo": "numpy/numpy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch deletes unrelated branding files, which the LM correctly identifies as having no impact on the `numpy.median` workload. In contrast, the expert's patch directly optimizes the `_median_nancheck` helper function, a measured hotspot within `np.median`, by replacing an inefficient two-step operation with a more direct `np.take` call.", "confidence": 1.0, "instance_id": "numpy__numpy-18324", "repo": "numpy/numpy"}
{"classification": "Unknown / Not Enough Information", "confidence": "low"}
{"classification": "Unknown / Not Enough Information", "confidence": "low"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a micro-optimization to string processing and tunes a chunk size parameter. The Expert, while also reducing micro-overhead, performs a deeper algorithmic refactor by pre-binding packing logic and introducing highly optimized, specialized packing functions (like `itemgetter(0)` or a no-op) for common data loading patterns, fundamentally improving the core data processing pipeline.", "confidence": 0.9, "instance_id": "numpy__numpy-19608", "repo": "numpy/numpy"}
{"classification": "Unknown / Not Enough Information", "confidence": "low"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch deletes static branding assets, which are entirely unrelated to the `numpy.loadtxt` workload, making it an unaligned optimization. The expert's patch, however, directly targets a measured hotspot within `numpy.loadtxt` by replacing an inefficient Python list comprehension with a C-optimized `operator.itemgetter` for column selection.", "confidence": 1.0, "instance_id": "numpy__numpy-19618", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe micro-optimizations to reduce Python overhead within `numpy.loadtxt`. However, the Expert's change is deeper, optimizing the fundamental string-to-type conversion logic that runs for every data point, while the LM's change optimizes the chunking mechanism, reducing overhead per chunk.", "confidence": 0.9, "instance_id": "numpy__numpy-19620", "repo": "numpy/numpy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch deletes static asset files (logos, documentation) that are entirely unrelated to the runtime performance of the `np.kron` function, which is the workload's hotspot. The Expert's patch, conversely, directly optimizes the `np.kron` function by refactoring its algorithm to use broadcasting, significantly reducing memory allocations and improving performance.", "confidence": 1.0, "instance_id": "numpy__numpy-21354", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations within the `norm` function. The LM introduces a specialized, native function (`vdot`) for complex L2 norm, while the Expert applies micro-optimizations (method call vs. global function, attribute caching) to both real and complex L2 norm paths, making the Expert's change broader in its application within the function.", "confidence": 0.9, "instance_id": "numpy__numpy-21394", "repo": "numpy/numpy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch deletes branding files, which it explicitly states have no impact on the `np.linspace` workload, making it unaligned. The Expert's patch, however, directly optimizes internal checks within the `np.linspace` function, which is the measured hotspot.", "confidence": 1.0, "instance_id": "numpy__numpy-21832", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes a conditional check that is never taken for the workload, yielding a minor reduction in Python interpreter overhead. The Expert's optimization, however, applies an algorithmic refactor by replacing operations that create expensive intermediate arrays with direct reduction operations, leading to a more systemic improvement in memory and cache efficiency for the core logic.", "confidence": 0.9, "instance_id": "numpy__numpy-24610", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a single, narrow fast path based on object identity (`a1 is a2`). The Expert, in addition to this, implements a more systemic optimization by introducing a mechanism to identify dtypes that cannot hold NaNs and uses this for an optimized, specialized path that avoids expensive `isnan` checks and masking for integer arrays, along with removing redundant `asarray` calls.", "confidence": 0.9, "instance_id": "numpy__numpy-24663", "repo": "numpy/numpy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a new early-exit condition (`any(not a for a in alist)`) that alters the function's behavior for inputs like `alist=[0]`, causing it to raise an error where the original code would proceed. The expert's patch refactors the existing `min()` check into an equivalent loop-based early-exit, strictly preserving the original semantics.", "confidence": 1.0, "instance_id": "numpy__numpy-25299", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path for a specific 2D array case of `tensordot` by dispatching to `matmul`. The Expert, however, makes a systemic improvement to the general `tensordot` implementation by replacing Python loops and NumPy ufunc reductions with the C-implemented `math.prod` for product calculations, which benefits all `tensordot` calls, not just a specific fast-path.", "confidence": 0.9, "instance_id": "numpy__numpy-25788", "repo": "numpy/numpy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to reduce overhead in `numpy.broadcast_shapes` by avoiding unnecessary memory allocations. The LM's approach involves an algorithmic refactor to rewrite the broadcasting logic, while the Expert's approach is a more minimal and safer change that uses a specific NumPy `dtype` trick to make `np.empty` allocate zero memory. Both target `Micro-OverheadRemoval`, but the Expert's solution is 'safer' due to its minimal invasiveness.", "confidence": 0.9, "instance_id": "numpy__numpy-26599", "repo": "numpy/numpy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, meaning it introduced no changes and therefore completely missed the hotspot. The expert, however, precisely targeted and optimized a micro-overhead within the hot loop of the `numpy.polynomial.legendre.legval` function, which was the measured bottleneck.", "confidence": 1.0, "instance_id": "numpy__numpy-27830", "repo": "numpy/numpy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for generating a cache key in a helper function. The Expert, in contrast, implements a systemic algorithmic refactor in the core `tz_localize_to_utc` function, allowing it to entirely bypass an O(N) loop for UTC timezones, and extends this optimization to other datetime accessors.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-23772", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's patch introduces a 'fast path' for scalar comparison by directly accessing the underlying engine, fitting the 'fast paths' aspect of the 'Shortcut' definition. The Expert's patch involves a 'structural redesign' by adding a fast path that reuses existing codes and categories during `Categorical` construction, aligning with the 'structural redesign' aspect of the 'Systemic' definition.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-23888", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization (an early-exit length check) is explicitly stated to be 'never met' by the workload, making it unaligned. The Expert's optimization, however, directly targets the workload's hotspot by specializing the comparison logic for `CategoricalIndex` objects, which is precisely what the workload performs.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-24023", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a specific fast-path that avoids a redundant sort only when the input is already sorted. The expert's optimization is a systemic improvement that fundamentally enhances the sorting performance of `PeriodArray` for all cases by exposing its underlying NumPy array for native, vectorized sorting.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-24083", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM introduces conditional checks and early exits (fast paths) to skip unnecessary Python-level operations. The Expert replaces a Python-level type inference function with a C-optimized equivalent, representing a systemic lowering of a hot path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-24308", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations that remove micro-overhead. The LM's approach is to avoid an expensive data conversion by directly accessing the underlying optimized array. The Expert's approach is deeper, vectorizing a critical `searchsorted` loop within Cython code, replacing many individual calls with a single, highly optimized array operation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-24491", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM adds a specific early-exit guard to `nanany` and `nanall` based on the *result* of a mask check (`not mask.any()`). The Expert, however, performs a systemic refactor by introducing a new helper function (`_maybe_get_mask`) that intelligently avoids computing a NaN mask altogether for dtypes (like boolean or integer) that *cannot* contain NaNs, and integrates this into the central `_get_values` utility, benefiting all `nanops` functions.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-25070", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations that remove unnecessary work. The LM removes a redundant type conversion for specific data types, while the Expert adds a conditional to avoid expensive Matplotlib tick creation calls. The Expert's explanation demonstrates a deeper understanding of the underlying library's performance bottleneck, making its optimization 'deeper' within the same strategy family.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-25665", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the semantic definition of `IntervalIndex.is_monotonic_increasing` by applying a stricter condition (both `left` and `right` bounds must individually be monotonic) which is not equivalent to the correct lexicographical monotonicity check. The expert's solution correctly implements the lexicographical check using highly optimized Cython and NumPy operations, preserving the original behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-25820", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target micro-overhead removal. The LM achieves this by enabling a pre-existing, highly optimized C-implemented library via a configuration flag. The Expert, however, performs a deeper refactoring of internal Python logic within a critical `groupby` function, eliminating redundant computations and associated Python overhead, demonstrating a more intricate code improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-25953", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path for `Series.map` only when both series are categorical and share identical categories. In contrast, the Expert's change is a more systemic algorithmic improvement, dispatching to a specialized `CategoricalDtype.map` that efficiently maps categories first, benefiting a broader range of categorical mapping scenarios.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-26015", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly uses `@cache_readonly` for the `IntervalArray.is_unique` method, indicating a caching strategy. The Expert's solution, however, focuses on a direct algorithmic refactor of `IntervalIndex.is_unique`, avoiding costly intermediate object creation and using targeted NumPy operations and early exits, without employing caching.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-26391", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert introduce a fast path for the `sep=\"\"` case. The Expert's solution is deeper because it identifies and removes logically redundant string concatenations and intermediate data structures, simplifying the core logic. The LM's solution primarily rewrites the existing concatenation logic in Cython.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26605", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations targeting `RangeIndex.get_loc` to reduce overhead. The LM replaces a built-in function call with direct arithmetic, a deeper re-implementation. The Expert adds a safe type conversion to optimize the input to the existing built-in call, making it a shallower but safer optimization, fitting the 'Expert is safer' criterion for SameStrategy_DepthGap.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26697", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations aim to enable a faster iteration path for `DatetimeIndex` by leveraging `DatetimeArray.__iter__`. However, the LM's patch only adds a `_fast_iter = True` flag to `DatetimeArray` and a minor `iter()` change, without showing the crucial `DatetimeIndex` modification that would consume this flag. The expert's patch directly assigns `DatetimeIndex.__iter__ = DatetimeArray.__iter__`, providing the complete and direct mechanism for the delegation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26702", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM performs a systemic refactor by replacing a Python loop with a C-optimized backend. The Expert adds a conditional fast path to select an existing, more efficient algorithm. While this represents a clear difference between systemic and shortcut approaches, the rubric's strict mapping rules for 'Shortcut_vs_Systemic' (LM must be the shortcut) and 'SameStrategy_DepthGap' (Expert must be deeper) are not met.", "confidence": 0.5, "instance_id": "pandas-dev__pandas-26711", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch unconditionally overrides the `verify_integrity` parameter, changing the documented behavior of `DataFrame.set_index` and risking silent data issues if users expected the check. The expert's patch, however, preserves semantics by optimizing internal `CategoricalIndex` creation to avoid redundant work without altering any user-facing behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-26721", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and aim to eliminate an expensive DataFrame transpose. However, the LM manually reconstructs the data using Python loops, while the Expert leverages the more specialized and internally optimized `DataFrame.from_dict(..., orient=\"index\")` constructor, also adding explicit sorting for full semantic equivalence.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26773", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": ["role_reversal"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM applies systemic algorithmic refactoring and vectorization to sparse data processing, a broad and fundamental improvement. The Expert, in contrast, implements a narrow guard (an `isinstance` check) for an error path, which acts as a fast path for a specific, potentially infrequent, type-checking scenario, and whose impact is explicitly doubted by the expert. This represents a reversal of the typical 'Shortcut_vs_Systemic' pattern, with the LM providing the systemic solution and the Expert a more localized, 'shortcut-like' optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-26776", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM directly adds the `shape` property to the `MultiIndex` class, providing a specific fix. The Expert, however, refactors the `shape` property to the base `Index` class, which is a more systemic structural redesign that benefits `MultiIndex` and all other `Index` subclasses through inheritance.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27384", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert introduce early-exit micro-optimizations. However, the Expert's optimization targets the fundamental `CategoricalDtype.__eq__` method, avoiding a potentially expensive `hash` computation on `pd.Index` objects, which is a broader and deeper optimization than the LM's specific type coercion bypass.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27448", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization explicitly pre-sets the `_sortorder` attribute, which serves as a cache for the MultiIndex's sorted status. The Expert's optimization, however, lowers the hotspot by introducing an early-exit path that operates directly on efficient integer `codes` using a C-level function (`libalgos.is_lexsorted`), avoiding Python object overhead and expensive `_get_level_values` calls without adding a cache.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27495", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the hotspot and the core optimization of avoiding intermediate object creation. However, the Expert's patch uses the more idiomatic and robust `Categorical.from_codes` constructor, indicating a deeper understanding of the API, while the LM's patch uses `Categorical(..., fastpath=True)`. The Expert also provides stronger contextual evidence with benchmark and `whatsnew` entries.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-27669", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its patch's modified code path is 'never executed' by the workload, making its optimization irrelevant for the benchmark. The expert's patch, however, introduces early-exit and scalar path optimizations that directly apply to and significantly speed up the provided workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-28099", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization focuses on reducing Python overhead and adding a fast-path (break statements) within the existing column-iteration loop. The Expert's approach is a systemic algorithmic refactor that avoids the per-column Python loop for core matching by first extracting unique dtypes and then using vectorized `isin` operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-28447", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization for the workload is a simple length check, a direct fast path. The Expert's solution, while also using early exits, applies a more robust and generalized structural check (nlevels with is_object_dtype) across both Index.equals and MultiIndex.equals, representing a more systemic refinement of the equality algorithm for different index types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-29134", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a scalar lookup cache (memoization) to avoid repeated computations for the same key. The Expert, conversely, optimizes the existing hot path by removing Python interpreter overhead (property access vs. direct attribute access), making the underlying computation itself faster without adding a cache.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-29469", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations targeting the same hotspot. The LM optimizes *how* NaN handling is performed by using a more vectorized NumPy idiom. The Expert's approach is deeper, optimizing *whether* NaN handling is performed at all by conditionally skipping redundant checks based on the specific comparison operator's semantics.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-29820", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for `range` objects directly within the `DataFrame` constructor's input handling. The Expert, while also using a fast path with `np.arange`, integrates this optimization as an algorithmic refactor within a lower-level, internal data preparation utility (`prep_ndarray`), making it a more systemic improvement to the data flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30171", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a micro-optimization by replacing a Python utility function call with a direct NumPy method for type casting. The Expert, in contrast, performs a more systemic optimization by converting the Python list indexer to a NumPy array early, enabling vectorized operations for the entire indexing process.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30747", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path to skip an expensive sort operation if the input is already sorted. The Expert, however, performs an algorithmic refactor to reduce object allocations and avoid an expensive append operation when constructing IntervalIndex objects, representing a more systemic improvement to the data structure's handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30768", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify caching as the primary optimization strategy for the `_ndarray_values` attribute. The LM adds a `cache_readonly` decorator to the `_ndarray_values` method on `IntervalArray`. The Expert, however, refactors `IntervalIndex`'s attribute inheritance mechanism to explicitly cache `_ndarray_values` directly on the `IntervalIndex` instance via `inherit_names(..., cache=True)`, which is a more integrated and potentially more efficient application of caching within the `IntervalIndex`'s attribute resolution system.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-30797", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism (`_cached_array`) to store the result of `_internal_get_values`. The Expert, in contrast, refactors the `Series.array` property to use polymorphic dispatch, eliminating runtime type checks and conditional branching, thereby lowering the inherent cost of the hot path rather than just caching its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-31037", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe adding conditional logic to skip unnecessary data copies in `fill_binop`. However, the LM's patch uses a single, broader condition (`mask.any()`) to skip both copies and the filling logic when no NaNs need to be filled. The Expert's patch uses more granular conditions (`left_mask.any()` and `right_mask.any()`) which would still perform copies in some cases where the LM's patch would not (e.g., when NaNs are present in both operands at identical positions, making `mask.any()` false). This indicates a deeper application of the same fast-path strategy by the LM.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-31300", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation includes an optimization that adds an `isinstance` fast-path guard for `is_float`, which is a specific type of shortcut. The expert's primary optimization for the workload focuses on replacing a Python-heavy float-to-int conversion and comparison with the more efficient, native `val.is_integer()` method, representing a more systemic lowering of the hot path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-31409", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations targeting the object creation/copying path for NumericIndex. The LM introduces a flag for a fast path by bypassing generic type inference, while the Expert directly reduces Python function call overhead by removing an unnecessary method indirection in the hot path, which is a deeper, more fundamental optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32130", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations describe the exact same optimization (bypassing redundant __init__ calls with object.__new__) with identical reasoning, scope, and impact. There is no discernible primary difference in strategy, depth, risk, or hotspot alignment between the two explanations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32821", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same hotspot and propose similar strategies (algorithmic refactor, micro-overhead removal, native code usage). However, the Expert's approach is deeper, involving a modification to the Cython `IntIndex` constructor to allow skipping integrity checks and explicitly adding a one-time `sort_indices()` call to ensure semantic preservation, which the LM did not fully detail.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32825", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized `SparseBlock` class, creating a fast-path for handling `SparseArray`s. The Expert, in contrast, performs a systemic algorithmic refactor by eliminating expensive string operations and attribute lookups within a critical `BlockManager` consolidation loop, making the general consolidation process more efficient.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32826", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path specifically for `SparseArray` inputs, bypassing a more general function. In contrast, the Expert implements a systemic optimization by reducing Python object creation and leveraging Cython for more efficient C-level handling of block placements, which benefits multiple block types.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-32856", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by passing a specific internal flag (`_set_identity=False`) to prevent an unnecessary and expensive internal data materialization during copy, which acts as a targeted bypass. The Expert, in contrast, performs an algorithmic refactor of the copy mechanism to ensure that the pre-computed internal cache is explicitly copied, avoiding redundant re-computation for subsequent operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-32883", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot (slow `_interleave()` for `iloc` with non-unique columns). The LM replaces the slow path with a custom, efficient loop. The Expert's solution is deeper, removing the entire conditional branch for non-unique columns, implying the general `fast_xs` logic is now sufficient and more unified.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-33032", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new `_fast_slice_block` method and a conditional check to create a specialized fast path for `slice` objects. The Expert, conversely, refines the internal data representation by changing a `range` object to a `slice` object for `placement`, which is a more systemic improvement in how internal block metadata is managed.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-33324", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces Python-level caching (`@cache_readonly`) for the `is_monotonic_increasing` property. The Expert, in contrast, optimizes the internal representation of the `Categorical` object by forcing its re-creation from raw components, which makes subsequent operations on it inherently faster without adding a cache.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-33540", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by switching the `sum` method to a specialized Cython-backed fast path, bypassing a more generic weighted sum. The Expert implements a systemic algorithmic refactor by reordering data for `RollingGroupby` objects to improve cache locality and introduces a specialized indexer, benefiting all subsequent rolling computations on grouped data.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34052", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["WhitespaceOnlyPatch"], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch consists solely of whitespace changes in Cython functions not invoked by the workload's `first()` aggregation, making it entirely misdirected and ineffective. The expert's patch, conversely, directly targets the workload's hotspot by optimizing the `first()` method for `ExtensionArray`-backed Series, avoiding expensive data materialization.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-34178", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the documented behavior of `Series.sort_index(inplace=False)` by returning the modified original object instead of a new copy, which is a semantic risk. The Expert's optimization removes an unnecessary internal copy in a helper function (`ensure_key_mapped`) without altering any public API semantics.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-34192", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new conditional fast-path for a specific input type (list of booleans) to use a more efficient NumPy conversion. The Expert, however, performs an algorithmic refactor by identifying and eliminating a redundant array conversion step in the core boolean indexing logic, addressing a systemic inefficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34199", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert introduce fast paths/micro-optimizations. However, the Expert's change is deeper and broader, optimizing a fundamental `MultiIndex.equals` method with a general early-exit condition, while the LM's change is a specialized fast path for a specific combination of arguments in DataFrame arithmetic.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-34354", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, highly vectorized fast path for a specific pattern of `DataFrame.replace` operations. In contrast, the Expert performs an algorithmic refactor within the `Block.putmask` method to avoid a redundant array copy, which is a more systemic improvement to resource management.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34737", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for `Series.map` when mapping with a dictionary, leveraging Cython for speed. The Expert, in contrast, performs an algorithmic refactor by optimizing the internal dictionary key/value extraction idiom within the `Series` constructor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-34948", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast-path based on a 'fragile heuristic' that inspects bytecode, explicitly noting it 'may break with different Python versions or different lambda structures,' indicating potential semantic risks. The Expert's optimization is a safe loop-invariant code motion that preserves all behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-35166", "repo": "pandas-dev/pandas"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a global build configuration change in `setup.py` to enable C/Cython extensions, which is an invasive, cross-module modification. The expert's optimization is a local, targeted refactor within a specific method (`CategoricalDtype.__eq__`), introducing early exits and an algorithmically more efficient comparison.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36280", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations that remove overhead. However, the LM's explanation is vague about the 'suboptimal early exit' and 'more optimized conversion path,' while the expert precisely identifies and avoids a specific, expensive `lib.infer_dtype` scan, demonstrating a deeper understanding of the true performance bottleneck.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36317", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe removing redundant validation during StringArray creation. The LM introduces a new `_simple_init` method for this fast path, while the Expert's approach is deeper, directly bypassing the `__init__` method call by using `object.__new__` and manual attribute assignment, thus avoiding more Python overhead.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36325", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path to skip redundant C-level type checks when the input array is already pure strings. The Expert, conversely, performs a more systemic refactor by replacing a generic NumPy type casting operation with a specialized, likely C-optimized Pandas function for converting object arrays to string dtypes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36432", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "BehaviorChanging"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes a global configuration option, altering the default behavior of `repr()` for large DataFrames from truncated data to metadata-only, thus changing the output semantics. The expert's optimization, however, preserves the original truncated representation behavior while significantly improving its performance by refactoring internal data copying and slicing logic.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-36638", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation details systemic optimizations including algorithmic refactoring, optimized data type handling, and improved Cython function dispatch. The expert's explanation, in contrast, focuses on removing a specific Python-level dynamic dispatch mechanism, which is a more localized overhead removal.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-36872", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism (a pattern-specific fast path) to avoid redundant data preparation. The Expert performs a systemic refactoring of the grouped window dispatch logic, eliminating Python overhead from `groupby.apply` through a structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37064", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation states the provided patch is empty and therefore offers no analysis of any optimization. This lack of technical content from the LM makes it impossible to classify its strategy or compare it meaningfully against the expert's detailed explanation.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-37118", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["broader coverage", "multiple operators"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert implement a fast-path for comparing identical `RangeIndex` objects by checking the underlying `_range` and returning a pre-filled NumPy array. However, the Expert's solution is broader, integrating this fast-path into the `_cmp_method` to handle all comparison operators (e.g., `==`, `!=`, `<=`, `>=`), while the LM's solution only addresses `__eq__`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37130", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized fast-path (using Cython and NumPy) for specific `fillna` methods (`ffill`/`bfill`), which is a pattern-specific optimization. The Expert, in contrast, applies an algorithmic refactor to a more general `groupby` reindexing logic, eliminating redundant work and unnecessary copies for a broader set of scenarios where the result index aligns.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37149", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific `elif` condition (a fast path/guard) to avoid float conversion for integer dtypes under certain conditions. The Expert, however, performs a more systemic `AlgorithmicRefactor` by removing dead code and simplifying conditional logic to prevent an inefficient and semantically inappropriate code path from being taken, which is a structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37426", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism for `Series.__dir__` to store the result of the first computation. The Expert's solution, for the given workload, avoids an expensive O(N) `unique()` computation entirely by introducing a conditional check based on the index type, effectively lowering the hot path by removing unnecessary work rather than just caching its result.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-37450", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation states it found no code changes to optimize, as its provided diff only contained the workload script. In contrast, the Expert correctly identified and explained a fast-path optimization in the pandas library that directly targets the workload's hotspot.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-37569", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, custom Cython function as a specialized fast path for a specific `fillna` pattern (float64 scalar). The Expert, however, refactors an existing internal method to leverage a more generally optimized and robust NumPy primitive (`np.putmask`), which is a systemic improvement in how the library uses its dependencies.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37945", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations aim to optimize `IntervalArray.argsort` by leveraging native NumPy sorting. However, the LM's approach involves an intermediate Python step (`list(zip(...))`) to construct a structured array, while the Expert's approach directly uses `np.lexsort` on the existing underlying NumPy arrays, making it a more direct and efficient application of the same native vectorization strategy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-37971", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path by adding a `mask_check=False` parameter to skip internal checks when the mask is known to be all `True`. The Expert, conversely, implements a `searchsorted` method for `ExtensionIndex` that systematically delegates to the underlying data's highly optimized native implementation, representing a broader algorithmic refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38103", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["LM_failed_to_identify_patch"], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM completely failed to identify the actual code changes in the pandas library, mistakenly believing the patch only added the workload script. Therefore, its analysis was entirely unaligned with any potential hotspot or optimization. The Expert correctly identified the patch, the hotspot (`DataFrame.__setitem__`), and explained the systemic, vectorized optimization.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-38148", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe a specialized, vectorized `isin` implementation for `IntervalArray`. However, the Expert's solution is deeper, using a clever `complex128` view of combined left/right bounds to enable a single `np.in1d` call, which is a more integrated and advanced vectorization technique compared to the LM's separate `lib.isin_object` calls for each bound.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38353", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes a conditional guard to always use a hash-table-based algorithm, which is a specific algorithmic choice. The expert's optimization introduces a new dispatch mechanism and a specialized `isin` method for `BaseMaskedArray` subclasses, representing a more systemic structural redesign to avoid costly intermediate conversions for a whole class of data types.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38379", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM adds a specific `isinstance` check and early return (a shortcut) within `RangeIndex.equals` for `MultiIndex`. The Expert refactors the general dispatch logic in the base `Index.equals` method to correctly route comparisons involving `MultiIndex` to its specialized implementation, which is a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-38560", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path within `get_indexer` to handle timezone-aware `DatetimeIndex` objects. The Expert, however, implements a more systemic algorithmic refactor by centralizing timezone standardization in the `_maybe_promote` utility method and removing redundant conversion logic from other methods, leading to a broader structural improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-39332", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for `_get_cov` introduces a conditional fast-path for specific `ddof` values (0 or 1), delegating to a Cython function while retaining the original Python path for other cases. In contrast, the Expert's patch performs a systemic algorithmic refactor, completely replacing the Python-level calculation for `cov` and `corr` with direct calls to low-level Cython aggregation functions for all cases.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-39388", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new Numba-jitted engine for EWM calculations, which is a systemic improvement. The Expert, while also leveraging native code (Cython), implements a deeper structural redesign by eliminating Python `groupby.apply` overhead and refactoring Cython functions to batch process groups, fundamentally optimizing the data flow for grouped operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-39664", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a boolean flag to create a conditional fast path, acting as a specific shortcut. The Expert, in contrast, implements a systemic optimization by refactoring the data iteration from slow Python `iloc` access to the C-backed `DataFrame.itertuples()` for a fundamental performance improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-39972", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactors to optimize `pd.json_normalize`. The LM optimizes the existing general-purpose flattening algorithm by removing expensive `deepcopy` and redundant `pop` operations. The Expert introduces a new, simpler algorithmic path for 'basic cases' of `json_normalize` via a conditional dispatch, representing a broader architectural change for a common subset of inputs.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40035", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an algorithmic refactor from O(N^2) to O(N) for time-weighted EWMA. However, the Expert's explanation details a broader and deeper structural refactoring, including the deletion of the O(N^2) function and unification of logic into an existing function, along with changes to the Python-level dispatch. The LM's explanation focuses on an in-place modification of the O(N^2) function.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40072", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization re-enables the use of the `bottleneck` library for `nansum` on float data, explicitly reversing a prior guard that was in place due to concerns about \"improper upcasting, overflow, and differing NaN preservation behavior,\" indicating a potential semantic risk. The expert's optimization, conversely, introduces `lru_cache` to memoize Cython function lookups, a purely performance-focused change that preserves existing behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40178", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a direct list comprehension to bypass a general-purpose `self.apply` method within `ArrayManager.isna`, acting as a specific fast path. The Expert, however, performs a structural refactoring of the core `_isna` utility, removing redundant Python overhead (getattr, isinstance checks) from the innermost function that processes raw NumPy arrays, which is a more systemic improvement to the missing data handling.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40254", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized `elif` block and leverages a `fastpath=True` argument for `Categorical` data within the `unstack` operation, which is a pattern-specific optimization. The Expert implements more systemic improvements by adding a Cython freelist for internal `BlockPlacement` objects, bypassing Python `__init__` for `Categorical` creation, and strengthening Cython type hints for low-level array operations, thereby optimizing fundamental internal mechanisms.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-40339", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation completely misidentifies the patch, stating it is the workload script itself and thus contains no code edit for performance. The expert, however, correctly identifies a significant optimization within the pandas library's `take` operation, which directly targets the workload's `groupby().agg('mean')` hotspot.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-40818", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization adds a narrow fast-path guard for 1-dimensional arrays to avoid object creation. In contrast, the expert's solution is systemic, introducing a new Cython base class and migrating core operations like `copy` and `T` to Cython with direct NumPy C API calls, fundamentally reducing Python overhead across the array system.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-40840", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is systemic, introducing a new Cython function to execute the hot loop in compiled C code. The Expert's optimization is a more specific micro-overhead removal, adding a conditional guard to skip redundant Python-level iteration that was a no-op for the specific data type.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41567", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation incorrectly states that the provided patch is merely the workload script itself and contains no performance optimizations. The expert, however, correctly identifies and explains a significant optimization in `pandas/core/nanops.py` that eliminates an unnecessary large memory allocation for the benchmarked `ser.all()` operation. The LM's analysis is completely misdirected from the actual optimization.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-41911", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific 'if' guard (fast path) to bypass existing logic for a narrow case. The Expert, in contrast, refactors the underlying mechanism for handling null masks for boolean/integer dtypes, avoiding unnecessary array allocations and sum operations at a more fundamental, systemic level.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41924", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for a specific `loc` indexing pattern (`series.loc[[integer]]` with `IntegerIndex`). The Expert, however, implements a systemic algorithmic refactor by optimizing type promotion logic in `_maybe_promote` for `UInt64Index` and non-negative `Int64Index` interactions, which is a more fundamental improvement to how pandas handles integer type compatibility.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-41972", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["SemanticCorrectness", "Robustness"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations propose using native code and specialized hash tables for deduplication. However, the LM's solution is 'deeper' in its correctness by explicitly incorporating all components of `IntervalArray` identity (left, right, closed) into its custom Cython hashing. The Expert's solution has a 'depth gap' in semantic correctness, as its `unique` method omits the `closed` property from the uniqueness check and contains a likely `IndexError` bug with `[:, 0]` on a 1D array.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42197", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new conditional fast path for `IntervalIndex.intersection` based on specific input characteristics (`is_non_overlapping_monotonic`). The Expert, conversely, makes a systemic improvement by disabling a suboptimal fast path in the base `Index` class for `IntervalIndex` and introducing an efficient intermediate data representation (tuples instead of `Interval` objects) for general intersection operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42268", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-overhead removal, fixing a specific Cython GIL thrashing pattern (a 'pattern-specific hack'). The Expert's optimization is a more systemic algorithmic refactor, introducing a fast path that leverages integer codes for significantly faster lookups in `CategoricalIndex`, fundamentally changing the lookup approach.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42270", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM completely failed to identify any code edit or optimization, stating that its provided diff was only the workload script and thus no optimization could be analyzed. The expert, however, correctly identified and explained a targeted optimization in the pandas library that directly impacts the benchmarked `union` operation, aligning with the workload's hotspot.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-42353", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization involves an algorithmic refactor using C-optimized block operations, while the Expert's is a micro-optimization of type checks. Although this represents a 'Systemic vs. Shortcut' difference, the rubric's specific mapping rules for 'Shortcut_vs_Systemic' and 'SameStrategy_DepthGap' do not apply in the specified direction (e.g., LM is not the 'shortcut' and Expert is not 'deeper').", "confidence": 0.6, "instance_id": "pandas-dev__pandas-42486", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for homogeneous DataFrames, returning an early copy. The Expert performs a systemic refactor of `select_dtypes` to delegate filtering to the internal `_get_data_subset` method, which is a more general algorithmic improvement to data management.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42611", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path to skip `ensure_index` calls based on `verify_integrity=False` and specific input types. The Expert, in contrast, performs more systemic optimizations by removing numerous runtime assertions in core `BlockManager` and `Block` creation paths, streamlining block instantiation, and caching a property, which are broader structural improvements.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42631", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both optimizations introduce a fast-path for dense MultiIndexes during unstacking. However, the LM optimizes the creation of an internal boolean mask, while the Expert propagates an `allow_fill` flag through the block management system to enable a faster `take` operation on ExtensionArray values, indicating a deeper architectural change and leveraging a more fundamental array operation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42704", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, indicating no optimization was made, thus its 'optimization' was completely misdirected. The expert, however, identified and optimized a specific hotspot in pandas' `isin` method for nullable dtypes, directly aligning with the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-42714", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized Cython function and a new conditional branch to handle a specific `transform` case for 2D data. In contrast, the Expert refactors the existing core Cython function to be 2D-aware and modifies the Python dispatch mechanism to process multi-column data in blocks, representing a more systemic change to the processing pipeline.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42841", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations optimize `DataFrame.insert` performance by improving internal data structure management. The LM's approach is a higher-level algorithmic refactor, changing the policy for when to automatically consolidate blocks. The Expert's approach is deeper, involving Cythonization of array manipulation within the `insert` method's inner loops and specialized fast paths, making the fundamental operation itself more efficient at a lower level.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-42998", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe systemic optimizations that reduce overhead. However, the LM's change is a specific algorithmic refactor for the `mad` calculation using NumPy, while the Expert's change is a broader and deeper structural improvement to the `BlockManager`'s data access, which can benefit many numeric operations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43010", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes the ability of the `ewma` function to handle multiple segments, fundamentally changing its behavior. The Expert's optimization introduces a conditional fast path for equally spaced data points, preserving the function's general behavior while optimizing a common, semantically equivalent scenario.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43052", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations to reduce Python overhead within `pd.read_stata`. The LM introduces a Cython function for string decoding, while the Expert optimizes NumPy array access and avoids data copies with `copy=False` for missing value handling and DataFrame construction. The Expert's approach of avoiding copies and direct NumPy array access can be seen as a broader and deeper optimization for memory and data flow within `read_stata` compared to the LM's string-specific Cythonization.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-43059", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional guard to skip a redundant deep copy operation in `Block.copy` under specific conditions, acting as a fast-path. The Expert, conversely, performs a systemic refactor of core dtype utility functions, replacing Python function call overhead and iterations with more direct and efficient C-level `isinstance` and `dtype.kind` checks.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43073", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM introduces a Cython-backed fast path specifically for `PeriodArray` conversion, which is a pattern-specific optimization. Expert implements a structural redesign within DataFrame internals (`_interleave` method) to create a fast path for *any* `ExtensionArray` when converting to `object` dtype, representing a more systemic improvement for a general case.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43160", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a micro-optimization by replacing a floating-point comparison idiom with an explicit `isnan()` call in Cython for potential compiler intrinsic benefits. The Expert, in contrast, performs a systemic refactoring of pandas' rolling window internals, shifting from generic `ArrayManager` block-wise processing to more direct column-wise iteration for single-column DataFrames, reducing abstraction overhead.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43171", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the default 'copy' behavior of the DataFrame constructor, which alters the semantics of data handling (sharing vs. copying). The expert's optimization, conversely, preserves the DataFrame's behavior by making an internal grouping mechanism more efficient without changing its output.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43237", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM introduces a highly specialized Cython implementation for a single operation (`groupby().skew()`), which can be seen as a pattern-specific optimization. Expert performs a structural redesign of a general aggregation helper (`_reduce`) by making redundant checks conditional, improving efficiency for a broader set of aggregations.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-43243", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM's explanation describes a micro-optimization that directly targets and improves a measured hotspot in the workload. In contrast, the Expert's explanation concludes that their own patch, while also a micro-optimization, is never executed by the specific workload due to short-circuiting, rendering it misdirected and ineffective for this benchmark. The primary difference is the hotspot alignment and effectiveness of the described optimizations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43274", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert apply systemic micro-optimizations to reduce Python overhead and improve efficiency within `pd.read_stata`. However, the Expert's changes are deeper, targeting the fundamental costs of DataFrame copies and re-creations during index assignment and column replacement, which often have a broader impact on performance and memory than the LM's element-wise vectorization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43277", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new Cythonized execution path for floor division, a systemic change. The Expert performs a micro-optimization by removing redundant array operations within an existing function. The rubric's categories do not directly capture this specific difference where the LM's optimization is arguably more systemic than the expert's, and no specific mapping rule is triggered.", "confidence": 0.6, "instance_id": "pandas-dev__pandas-43281", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations within the same method. However, the Expert's change provides a deeper, more fundamental improvement to the iteration mechanism by replacing inefficient DataFrame slicing and `itertuples()` with direct `Series.items()`, reducing object creation overhead for all processed cells. The LM's optimization, while effective for specific data patterns, relies on conditional fast paths and early exits.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43285", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided no optimization explanation, stating that the patch was empty and contained no code changes to analyze. This directly triggers the guardrail for short/empty explanations lacking technical mechanisms, leading to an 'Unclear' classification.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-43308", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a C-optimized implementation for the core cross-merge operation, representing a systemic algorithmic improvement. The Expert performs a micro-optimization by replacing a general `DataFrame.drop` call with a more direct `del` for a single column, which is a pattern-specific overhead removal.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43332", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM removes a specific, narrow `int32` overflow check, which is a micro-optimization. The Expert implements more systemic improvements by introducing caching for repeated computations and, more significantly, refactoring to avoid an expensive full DataFrame copy, which constitutes a structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43335", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations within the `df.unstack()` operation. The LM optimizes the handling of `Categorical` data by converting to integer codes for C-level processing and then reconstructing, which is an algorithmic refinement for that specific data type. The Expert, however, focuses on broader micro-optimizations within the core `BlockManager` and `Block` system, removing redundant integrity checks and array transpositions, which are deeper and more generally applicable to pandas' internal data structures.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43352", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path triggered by a function's `__name__` attribute, switching to an existing `transform` method. In contrast, the Expert performs a systemic optimization by Cythonizing a core internal `BlockManager` method and replacing inefficient Python/NumPy operations with C-level loops, improving the general case for DataFrame copies.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43353", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific fast-path triggered by a hardcoded function name and specific `groupby` parameters, acting as a pattern-specific hack. The expert, conversely, implements a more systemic algorithmic improvement by adding early-exit conditions to an internal `JoinUnit.is_na` property, reducing redundant work in a general case (no NAs) during block management.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43354", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for a narrow set of conditions, directly returning a pre-computed result. In contrast, the Expert performs a systemic refactor within the Cython engine, eliminating expensive Python object creation and iteration for a broader class of MultiIndex operations.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43370", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized Cython fast-path for the specific case of median (0.5 quantile with linear interpolation). In contrast, the expert performs an algorithmic refactor by hoisting the `np.lexsort` operation out of a per-column loop, providing a systemic improvement for general `groupby().quantile()` on wide DataFrames.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43510", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch and no optimization explanation, making it impossible to classify its approach or compare it meaningfully against the expert's detailed and effective optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43518", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path triggered by a brittle heuristic (inspecting function source code for 'return g.copy()') to enable a vectorized operation. The Expert, conversely, implements a systemic optimization within pandas' core BlockManager to avoid redundant recomputation of internal metadata during slicing and copying, which is a more fundamental improvement to the data structure itself.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43524", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific conditional fast-path to bypass a redundant `reindex` call for `RangeIndex` equality. The Expert, in contrast, performs a systemic refactor of `Series.to_frame()` to leverage internal manager methods for zero-copy data conversion and reduced overhead, fundamentally changing the data flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43558", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM removes a function call deemed redundant due to a specific behavior (`g.copy()`) in the workload's `apply` function. The Expert, conversely, performs a more systemic algorithmic refactor, replacing an inefficient high-level operation (`self.filter`) with direct access to pre-computed data and efficient array-oriented masking, improving the general `groupby().apply()` path for `dropna=True`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43578", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast path for identical MultiIndex objects, leveraging existing optimized comparisons for an early exit. The Expert, in contrast, implements a more systemic improvement by refactoring the comparison logic to dispatch to the specialized `ExtensionArray.equals` method, which is a more fundamental improvement for handling these types within `MultiIndex.equals`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43589", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies a superficial change of adding 'last' to an `elif` condition for dtype inference, interpreting it as a 'fast path' dispatch. The Expert correctly identifies the systemic change of explicitly converting `StringArray` to a NumPy `object` array within `_ea_wrap_cython_operation`, which is the true mechanism for enabling highly optimized Cython routines for string data.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43634", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation correctly states that its provided diff is the workload script itself and thus contains no optimization for it, making its 'optimization' non-existent or misdirected relative to the task. The expert, however, provides a concrete optimization that targets a measured hotspot within Pandas' `groupby` aggregation, replacing a Python list comprehension with `np.vectorize` for efficiency.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43675", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM completely failed to identify any optimization, mistakenly concluding the patch was the workload script itself and thus irrelevant to performance. The Expert correctly identified the patch as an optimization targeting the `df.dropna` hotspot by improving internal dispatch for boolean masks.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43683", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": ["Misdirected_vs_Hotspot"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly highlights a 'fundamental dtype mismatch' between its `object` dtype patch and the workload's `uint` column, making a 'strong assumption' that the patch would be called, thus implying a potential semantic risk of misapplication or irrelevance. The expert's patch, in contrast, directly targets the workload's hotspot and preserves documented behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-43694", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization replaces an internal function with NumPy's `np.partition`, which acts as a highly efficient, specialized fast path for k-th selection. The Expert's optimization is a structural redesign within `Index.drop` to avoid costly and redundant materialization of `RangeIndex` objects, improving data flow.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43696", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["micro-optimization", "algorithmic-refactor"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert identify and optimize the same two core issues: eliminating a redundant recursive call and avoiding unnecessary index creation/dropping for scalar quantiles. Their strategies are fundamentally the same (algorithmic refactor and micro-overhead removal). The difference lies in the specific implementation details of how the index overhead is avoided (LM passes a flag, Expert conditionally omits an argument), representing a subtle 'depth gap' or alternative approach within the same optimization family.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43725", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-overhead removal, replacing a redundant `np.asarray` call with direct attribute access. The Expert's optimization is a more systemic algorithmic refactor, changing how pandas handles data internally to avoid memory allocations and data copying by creating views instead of copies when dropping columns.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43760", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same bottleneck in `DatetimeIndex.tolist()` and aim to avoid an intermediate array conversion. However, the Expert's solution is deeper by removing the override to leverage the highly optimized, likely C-level `ndarray.tolist()` method, while the LM's solution directly modifies the override to `list(self._data)`, which might still involve more Python-level iteration.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-43823", "repo": "pandas-dev/pandas"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization globally changes the default parsing engine for `pandas.read_csv` to 'pyarrow', which is a broad, default-altering change. In contrast, the expert's optimization is a local, internal algorithmic fix within `c_parser_wrapper.py` that improves a specific O(N^2) bottleneck to O(N) without altering public API defaults.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44192", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch enables `bottleneck` for `nansum` on float data by removing a guard that explicitly preserved NaN behavior for all-NaN inputs, thus risking a change in semantic behavior. The Expert's patch, conversely, preserves documented behavior while optimizing by avoiding a performance anti-pattern for specific array shapes.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-44566", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization uses `dict.fromkeys` for efficient unique type identification and an early exit, which is a fast-path/micro-optimization. The Expert's approach is systemic, rewriting the hot loop in Cython to compile it to C, fundamentally lowering the execution cost rather than just finding a faster Python-level path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44594", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM introduces a fast path guarded by specific conditions (`index_col` is an integer and no leading columns) to use vectorized NumPy operations for index extraction. Expert applies a more general algorithmic refactor by filtering `na_values` based on data type to optimize an existing vectorized comparison, without such specific guards.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44610", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow early-exit fast path for an already-sorted data case. The Expert performs a systemic refactor by introducing a mask parameter to a core utility (`take_1d`) to avoid redundant computations of boolean masks across multiple callers and loops.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44666", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by batching multiple `take` calls into a single, larger call, a common micro-optimization pattern. The Expert performs an algorithmic refactor by making the `allow_fill` logic more granular, enabling the underlying `take` operation to skip expensive validation steps entirely when not needed, representing a more systemic improvement to the algorithm's efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44758", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for a specific data structure (homogeneous NumPy record arrays) by reinterpreting memory. The Expert performs an algorithmic refactor by simplifying the general process of creating a default RangeIndex, replacing a potentially complex inference with a direct, optimized call.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44827", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM's optimization is a fast-path that correctly targets the workload's hotspot. The expert's explanation analyzes a different patch, concluding it is unaligned to the workload's hotspot. However, the strict mapping rules for 'Misdirected_vs_Hotspot' require the LM to be unaligned, which is not the case here. No other primary category's rules are met.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44832", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new 'fast-path' guarded by specific parameters, which then delegates to a new, highly optimized internal method for direct block manipulation. The Expert, instead, refactors the existing logic for a specific 'how' condition by replacing a less efficient 'count' operation with a more direct and optimized 'notna().all()' call.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44857", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by tuning a batch size parameter in a Cython loop to reduce overhead, while the Expert optimizes by introducing caching for a property. These are distinct optimization strategies that do not align with the specific pairings defined in the primary categories of the rubric.", "confidence": 0.8, "instance_id": "pandas-dev__pandas-44908", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-overhead removal within an internal hash table's C implementation, a narrow change to a parameter. The Expert's optimization is a systemic algorithmic refactor that structurally modifies the MultiIndex object itself to be more efficient by removing unused levels before serialization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-44943", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, indicating no optimization was made and thus failing to address any hotspot. The Expert, however, identified a specific hotspot in `Block.where` for all-True masks and implemented an effective early-exit fast-path.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-45242", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a pattern-specific fast-path for `groupby().apply()` when used with built-in `max`, `min`, `sum` functions. The Expert, however, performs an algorithmic refactor of the `find_stack_level` utility function, which is a systemic improvement to the overhead of warning issuance.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45247", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a brittle shortcut by inspecting the source code of a lambda to convert it to a string literal, enabling an existing fast path. The Expert, conversely, performs a systemic algorithmic refactor of the `_choose_path` logic to correctly identify and enable an existing fast path for a broader, semantically valid class of user-defined functions.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45387", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the output type from `pandas.Timedelta` (or `datetime.timedelta`) to a generic Python `int` object, which is a semantic change. The expert's solution achieves performance by using a specialized C-extension function (`ints_to_pytimedelta`) that correctly preserves the `datetime.timedelta` object type.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-45571", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM implements a fast-path by using `inspect.getsource` to detect a specific `np.max` lambda and redirect it to an existing string-based optimized path. The expert, however, performs a systemic algorithmic refactor by replacing an inefficient `np.concatenate` pattern with the highly optimized `np.tile` for broadcasting UDF results, improving the general case.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-45708", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM introduces a specialized, vectorized path for handling `pd.NA` values during array coercion (a fast path for a specific data pattern). Expert performs an algorithmic refactor to avoid creating a large intermediate Python list when constructing arrays from scalars, which is a more general structural redesign.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45854", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, conditional fast path specifically for single scalar lookups. The Expert, conversely, implements a systemic refactor by deferring a large memory allocation and utilizing a more optimized (likely Cython-backed) search algorithm, which improves the general case for single or few-element lookups without adding a pattern-specific guard.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-45931", "repo": "pandas-dev/pandas"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces caching for string parsing and monotonicity checks. The expert's optimization, however, lowers the hotspot by replacing Python-level searchsorted calls with direct calls to a Cython-optimized `algos.searchsorted` to reduce Python overhead.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-46040", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM introduces a new, specialized Cython function (`group_last_int64`) for a specific data type (`Int64`). Expert refactors the existing, general `group_last` Cython function to leverage pre-computed null masks for all nullable dtypes, improving the core null-handling algorithm systemically.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46107", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explains the optimization as improving type-specific dispatch to select more efficient hash tables. The expert identifies the primary optimization as eliminating an unnecessary memory allocation and data copy (uint32 to uint64) during data preparation, which is a more systemic refactor of the data handling pipeline rather than just a better dispatch mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46109", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe creating a fast path for `DataFrame.corrwith` by replacing Python `apply` with NumPy-backed operations. The Expert's solution is deeper and safer by explicitly checking for 'pearson'/'spearman' methods, directly using `np.corrcoef` with explicit null handling and rank calculations, and falling back for other methods, whereas the LM relies on a more general `nanops.nancorr` call.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46174", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an algorithmic refactor to optimize MultiIndex alignment during reindexing. The LM's change refactors a helper function to avoid intermediate object creation. The Expert's change is deeper, occurring in the more central `_get_indexer` method and addressing the fundamental cost of `MultiIndex._values` materialization by leveraging a more efficient internal representation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46235", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM correctly identifies the performance bottleneck in the old `MultiIndex.values` implementation (excessive Python object creation) and infers a new, more optimized implementation. The expert, with access to the actual code changes, provides a much deeper explanation of the specific algorithmic refactor: applying `astype(object)` to unique levels before expanding with `take_nd`, which is a more precise description of the same optimization strategy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46288", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-optimization within a specific conditional branch, making internal array creation more explicit. In contrast, the expert's optimization involves a systemic refactor of MultiIndex indexing, replacing Python-object-based indexers with raw NumPy boolean arrays and leveraging vectorized C-implemented operations for fundamental performance gains.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-46330", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path by adding a conditional check to reuse an existing Index object, avoiding redundant Python-level reindexing and copying. The Expert, conversely, implements a more systemic optimization by modifying how StringArray data is exposed to the IndexEngine, allowing it to leverage highly optimized C/Cython code paths for NumPy arrays, which is a deeper, more fundamental change to the data access mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-46349", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is a narrow fast-path that specifically checks for an identity lambda function with `group_keys=False`. In contrast, the Expert's optimization is an algorithmic refactor that improves the general re-indexing process for non-unique, unsorted indices by pre-filtering unique values, a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-47234", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization enables a specific 'zero-copy' fast path by setting a flag (`self_destruct=True`). The Expert's optimization, however, involves a systemic refactor of the conversion algorithm, replacing an inefficient Python loop with a single, highly optimized call to PyArrow's C++-backed `concat_arrays` and a single conversion, fundamentally changing the underlying process.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-47781", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations aim to leverage compiled code for `GroupBy.var`. The LM's change is a default parameter modification to enable an external Numba JIT engine. In contrast, the Expert's change is a deeper refactor of the internal dispatch logic to ensure the existing Cython-optimized path is used for `ddof != 1` cases, which previously fell back to a slower Python loop, making it a more fundamental fix to the internal implementation.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48152", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a specific branch (`dropna=False`) within `value_counts` by leveraging a C/Cython-backed function, acting as a targeted fast path. The Expert, in contrast, performs a broader algorithmic refactor of `value_counts` to unconditionally use the optimized function and also introduces a separate fast path in the Series constructor, demonstrating a more systemic approach.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48338", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a fast path that its own explanation explicitly states is not triggered by the benchmarked workload, making it unaligned. The Expert's patch, however, directly targets a data preparation step (`_get_engine_target`) that is part of the workload's hot path, enabling a more optimized internal lookup mechanism.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48472", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations that reduce Python overhead and improve algorithms. However, the Expert's approach is significantly deeper, moving critical string handling logic into Cython and eliminating an entire Python-level post-processing pass, directly touching the core parsing loop. The LM's optimizations are valid but comparatively shallower micro-optimizations like function inlining and a local list-to-set conversion.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48502", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch and no optimization explanation, thus failing to address any hotspot. The expert, however, identified and optimized a specific hotspot in `MultiIndex` merge operations by refining the algorithmic path taken.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48504", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization targets code paths explicitly identified as 'dead code' for the given workload, meaning they were not exercised. The Expert's optimization, however, targets an actively executed type-checking operation within the hot path, making it more efficient for the workload.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48609", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a specialized, direct construction path for intermediate MultiIndex objects, bypassing the general-purpose `droplevel` method. The Expert's optimization, however, is a more systemic algorithmic improvement that removes redundant `algos.take_nd` calls when an identity mapping is implied, which is a fundamental removal of dead work.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48611", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path guard to avoid redundant object creation when the input is already a MultiIndex. The Expert, in contrast, performs a systemic algorithmic refactor by replacing a general comparison with a highly optimized `get_indexer` method, which leverages specialized lookup structures for membership testing.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48622", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch changes the fundamental behavior of `copy()` by returning the original object (`self`), which is a semantic risk. The expert's patch, however, optimizes the `size` property by changing its internal calculation to avoid expensive data materialization, while fully preserving its documented behavior.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48723", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes the evaluation of an `if` condition by removing a redundant O(N) check that is always false for the specific workload, acting as a pattern-specific hack. The Expert, in contrast, performs a systemic algorithmic refactor within the `else` branch, replacing a generic, Python-object-heavy set-difference implementation with a specialized, highly optimized `MultiIndex.difference` method.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-48752", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that no patch was provided, thus it offers no technical details or optimization strategy. This lack of information from the LM side makes it impossible to classify a difference, leading to 'Unclear' as per the rubric's guardrails.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-48976", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations for the `factorize` method, focusing on reducing overhead in data conversion and null handling. However, the Expert's approach is deeper, leveraging C++-backed PyArrow compute functions (`pyarrow.compute.fill_null`) for the hot path of null handling, whereas the LM's approach primarily involves more direct Python/NumPy operations for similar overhead reduction.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49177", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch removes the `unique()` operation from the `isin` logic, which was present in the original implementation via `algos.unique`. The expert's patch, while optimizing, explicitly retains the `values.unique()` call, thus preserving the original semantic behavior of checking against a set of unique values.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49577", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch for `grouper.py` directly assigns `cat.categories` as `uniques`, which would incorrectly return all categories when `observed=True` (a valid `groupby` option), thus altering behavior. The Expert's patch, in contrast, optimizes a category comparison within `reorder_categories` using more efficient `Index` methods, strictly preserving existing semantics.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49596", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a caching mechanism for column label lookups, acting as a pattern-specific fast path. The Expert, in contrast, implements a systemic algorithmic refactor by enabling in-place modification of underlying data arrays, eliminating repeated memory allocations and copies.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49772", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizing iteration over PyArrow-backed arrays by leveraging PyArrow's native capabilities. However, the Expert's solution is applied to the base class `ArrowExtensionArray`, making it broader, and directly yields converted scalars, potentially avoiding intermediate list allocations per chunk, indicating a deeper optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49825", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same early-exit fast-path optimization for empty inputs in `infer_dtype`. The expert's explanation, however, provides a deeper analysis by identifying the specific expensive function call avoided and places the optimization within a broader, more systemic context of addressing empty input performance regressions across the codebase (referencing `Series.isin` and `whatsnew`).", "confidence": 0.9, "instance_id": "pandas-dev__pandas-49839", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM incorrectly states the patch is empty, thus failing to identify any optimization or its alignment to the workload. The Expert correctly identifies a systemic optimization (fast path for `MaskedArray.__iter__`) that directly targets the measured hotspot in the workload (iteration over `pandas.Series` without NAs).", "confidence": 1.0, "instance_id": "pandas-dev__pandas-49851", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by replacing a general `where` call with a `copy` + `putmask` sequence within the generic `Block.fillna` method, which is a micro-optimization or a more direct 'shortcut' for the operation. The Expert implements a systemic change by enabling `ExtensionBlock` to override `fillna` and delegate to the underlying `ExtensionArray`'s specialized `fillna` method, allowing for type-specific, potentially native-code-backed, optimizations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50078", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation states that no patch was provided, indicating it failed to identify any optimization or hotspot. The expert, however, precisely identified the `Series.to_dict` method as the hotspot and applied a micro-optimization to remove redundant generator overhead.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-50089", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["LM_hallucination"], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM incorrectly states that the patch contains no code edits and only adds the workload script, thus completely missing the actual optimization. The Expert correctly identifies and explains a significant algorithmic refactor and vectorization targeting the workload's hotspot in `pd.to_datetime`.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-50168", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Unknown"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's 'patch' is merely the workload script itself and contains no actual code edits to optimize the system under test, thus being completely misdirected. The expert, in contrast, correctly identifies and optimizes a performance hotspot (an expensive `np.array_equal` check) within a core pandas function that the workload exercises.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-50306", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, offering no optimization and thus completely missing any hotspot. The expert's explanation details a systemic optimization targeting the measured `Index.union` and `intersection` operations by enabling C-level fast paths for specific data types and conditions.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-50310", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations aim to optimize the conversion from PyArrow to pandas BooleanArray. However, the expert's explanation provides a deeper understanding by explicitly identifying and solving the performance bottleneck of `object` dtype NumPy arrays when nulls are present, using specific PyArrow compute functions to create efficient `bool` dtype value and mask arrays. The LM's solution is a more general 'direct conversion' without this specific insight into the null-handling performance issue.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50524", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The Expert's optimization introduces a narrow guard (`isinstance` check) to create a fast path, avoiding an expensive `isna` call. The LM's optimization is a more systemic refactor, replacing Python-level list appends with C-optimized built-ins (`zip`, `list` constructors) for bulk data transformation, aligning with algorithmic refactoring and leveraging native code.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50620", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path (`if notna(vals).all():`) to use `astype(bool)` when no NAs are present, retaining the slower `np.vectorize` for other cases. The Expert, in contrast, performs a systemic refactor, completely removing the `np.vectorize` path and replacing it with a fully vectorized sequence of `isna` and `astype(bool)` operations, improving the general handling of `object` dtype boolean aggregations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-50623", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces new, specific early-exit guards based on direct type checks (`cnp.PyArray_Check`, `isinstance(IntegerDtype)`). The Expert, in contrast, performs an algorithmic refactor by reordering operations to call `_try_infer_map` earlier, thereby avoiding a potentially expensive `np.asarray` conversion for `pandas.Series` objects backed by NumPy dtypes, which is a more systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51054", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an O(log N) fast path for scalar lookups by leveraging an existing IntervalTree engine. The Expert performs a systemic structural redesign by removing redundant validation checks from the object creation path, which is a more general improvement to the internal logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51339", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe high-quality optimizations using similar techniques (vectorization, C/Cython-level operations) to improve performance. The LM's change is an algorithmic refactor of the core data re-indexing, while the Expert's is a micro-overhead removal for input processing. Neither fits the specific comparative criteria of the defined categories, particularly the directional nature of 'Shortcut_vs_Systemic' or 'SameStrategy_DepthGap'.", "confidence": 0.6, "instance_id": "pandas-dev__pandas-51344", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations (`Micro-OverheadRemoval`) targeting the same hotspot. The LM's change optimizes data conversion by leveraging a native PyArrow method and avoiding a redundant type conversion. The Expert's change optimizes by removing Python interpreter overhead (warning handling) from the hot path, which is a deeper form of Python performance optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51439", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "rationale": "The LM correctly identifies that the `extract_array` function is the bottleneck for `range` objects, as it inefficiently converts them to a Python list then a NumPy array. Its patch bypasses this by directly using `np.arange`. The Expert's patch, however, places its `np.arange` conversion *after* `extract_array` has already run, and checks `isinstance(rvalues, range)`, which will never be true because `extract_array` would have already converted the `range` to a `numpy.ndarray`. Thus, the Expert's patch is misdirected and will not optimize the identified hotspot.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51518", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactoring and micro-overhead removal. The LM optimizes the core numerical computation by replacing `argmax` with `np.nonzero`. The Expert's change is broader, refactoring the function's interface and data flow to specifically avoid overhead for Extension Arrays, a systemic concern in pandas.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51549", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both optimizations aim to leverage lower-level, compiled code (NumPy/numexpr). However, the Expert's approach involves a deeper algorithmic refactor within the `_where` method to explicitly convert extension dtype masks to efficient NumPy boolean arrays, ensuring optimal data representation for subsequent low-level processing. The LM's change is a configuration update to enable an existing external accelerator (`numexpr`) for a specific dtype.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51574", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unknown", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations involving overhead reduction. The LM avoids a specific redundant calculation by propagating a known sort order during MultiIndex creation. The Expert improves the effectiveness of an existing LRU cache by canonicalizing NaN/NaT inputs, which is a deeper improvement to a general utility's performance mechanism.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51592", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes module import overhead, which, while technically part of the workload, is likely to have a negligible impact on the overall `df.isna()` performance. The Expert, in contrast, directly targets the computational hotspot within the `ArrowExtensionArray.isna` method, introducing fast paths that significantly reduce work for common data patterns.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51630", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new Numba-accelerated execution path for the `GroupBy.quantile` method. The Expert, conversely, performs a deeper algorithmic refactor of the existing Cython implementation, optimizing the sorting strategy for improved cache locality and reduced global overhead. Both leverage compiled code, but the Expert's change is a more fundamental optimization of the core algorithm.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51722", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path (early-exit for `slice(None)`) to avoid object creation. The Expert implements a more systemic change by refactoring `__getitem__` to transfer pre-computed internal engine properties via Cython methods to newly created sliced `Index` objects, thereby avoiding expensive O(N) re-computations for any slice.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51738", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional early-exit (fast-path) that bypasses type conversions only when all aggregated results are `np.nan`. The Expert, conversely, implements a more systemic optimization by refining the internal metadata management of the core `pandas.Series` object, leading to general efficiency gains in attribute resolution.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-51784", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["Robustness", "SemanticPrecision"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same redundant copy optimization. However, the expert's solution uses `astype_is_view` for a more robust and semantically precise check to determine if a copy is truly avoidable, making its strategy deeper and safer than the LM's simpler `dtype != vdtype` comparison.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52054", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path guard for a particular datetime string format, which is a pattern-specific shortcut. The Expert, however, implements a more systemic optimization by preventing an unnecessary NumPy array copy, which is a general improvement in data handling efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52057", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch is a purely cosmetic change (adding a blank line) that the LM itself states has no technical mechanism to make the workload faster. The expert's patch, however, directly targets the measured hotspot (`get_block_type`) with concrete optimizations like removing unnecessary checks and adding early exits.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52109", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, highly specific fast path guarded by multiple conditions (timezone-naive, no NaT). The Expert, in contrast, refactors the existing comparison logic to avoid redundant memory allocations and a generalized comparison function when units are compatible, leading to a more systemic improvement in the general case of DatetimeArray vs Timestamp comparisons.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52111", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a specific Python implementation of `first()` by avoiding an unnecessary data copy (a micro-overhead removal). In contrast, the Expert's patch introduces a systemic change by enabling `min()` and `first()` for `Categorical` dtypes to use a highly efficient Cython-based implementation, fundamentally changing the execution strategy for these operations.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52120", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies a specific `fastpath=True` flag for Series construction, which is a narrow optimization. The Expert, while also including that `fastpath`, primarily implements a structural redesign of the `Series.__getitem__` method's dispatch logic, creating an early exit for slice indexing that significantly reduces overhead for a common operation. This is a more systemic improvement compared to the LM's narrower optimization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52145", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an early-exit fast-path for `DataFrame.T` when columns are `ArrowExtensionArray`, recognizing a specific case where the operation is a no-op. The Expert, however, optimizes the internal construction of `ArrowExtensionArray` by preventing a redundant `pyarrow.Array.cast` call, which is a more systemic removal of unnecessary work within a core component.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52256", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch is the workload script itself, not an optimization of any library code, thus it is completely misdirected. The expert's patch, however, directly targets the measured hotspot in `pandas.Series.any()` by removing overhead and streamlining internal logic.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52341", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization targets `BaseMaskedArray` (nullable dtypes), but the provided workload script creates a standard NumPy-backed boolean Series. The LM itself notes this discrepancy, making its patch misdirected for the literal workload. The expert's optimization, however, directly targets the literal workload by introducing a fast path for standard boolean/integer Series that delegates to highly optimized NumPy C code.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52381", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new early-exit fast-path to directly return the underlying array under specific conditions. The Expert, conversely, refactors the existing logic to conditionally avoid an unnecessary data copy and masked assignment, representing a more systemic removal of dead work.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52430", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is conditional on a `dtype` argument not present in the workload, making it irrelevant to the benchmark. The expert's optimization directly targets the `groupby().sum()` operation, which is the measured hotspot in the workload, by introducing an optimized path for Arrow-backed numeric arrays.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52469", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM failed to identify any code changes, stating the patch was empty, and thus provided no optimization analysis. In contrast, the expert precisely identified the hotspot (conversion of `null[pyarrow]` arrays) and explained how the patch optimizes this specific path using a highly optimized NumPy primitive.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52525", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactors and micro-overhead removals. The expert's patch introduces a deeper optimization by leveraging highly optimized `Index.append()` and `Index.unique()` methods for the core `union_indexes` operation, directly improving how fundamental data structures are combined. The LM's patch provides a set of improvements across different stages of the `concat` process (type inference, conversion, DataFrame construction), which are also systemic but not as singularly focused on a core data structure's internal efficiency.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52541", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific guard, explicitly checking for a column named 'a', to skip a redundant date conversion. The Expert, conversely, implements a more systemic algorithmic refactor in a core date processing function, preventing an unnecessary intermediate PyArrow-to-NumPy data conversion for any column already identified as a PyArrow date/timestamp.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52548", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["algorithmic detail", "implementation specificity"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify `pd.concat` as the hotspot and propose/describe similar high-level strategies (algorithmic refactoring, Cythonization) to optimize column alignment. However, the Expert's explanation provides a significantly deeper and more specific analysis of the exact algorithmic transformation (single-pass combined plan generation vs. iterative combination) and its Cython implementation details, which the LM's hypothetical explanation lacks.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52672", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, meaning no optimization was applied and thus no hotspot was targeted. The Expert, conversely, implemented a highly optimized fast-path for `pd.concat` with specific float dtypes, directly addressing the measured hotspot in the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-52685", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow, in-line fast path specifically for `IntegerDtype` within `DataFrame.transpose`. The Expert, however, implements a broader, more systemic solution by extracting the vectorized logic into a new, reusable helper function (`transpose_homogenous_masked_arrays`) in a separate module, applicable to all `BaseMaskedDtype`s.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52836", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies and removes a single redundant data copy operation within a loop. The Expert, in contrast, performs a systemic refactor by leveraging `pyarrow.ChunkedArray.combine_chunks()` to eliminate the entire Python loop, multiple intermediate allocations, and a final concatenation step, which is a more fundamental algorithmic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-52928", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that no patch was provided, and therefore, it could not analyze any code changes or explain performance improvements. As such, the LM provided no optimization strategy to compare against the expert's detailed explanation.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-53013", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes the overhead of a caching mechanism that was ineffective for the benchmark's specific access pattern, which can be seen as a pattern-specific hack. In contrast, the Expert's optimization performs a systemic algorithmic refactor, replacing an inefficient Python-level index construction with a highly optimized, vectorized `MultiIndex.from_arrays` call, fundamentally improving the core computation for multi-key grouping.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53088", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's first optimization introduces a conditional guard (`if pa.types.is_string`) to dispatch to a specific PyArrow function, which aligns with a 'FastPath/SpecialCase' strategy. The Expert's optimization, in contrast, is a more systemic micro-overhead removal, replacing an inefficient Python list creation with direct PyArrow scalar broadcasting, leveraging native vectorization.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53150", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch removes explicit bounds checks and conditional `start/stop/step` logic, always using `step=1` even for negative indices where the original code used `step=-1`. While the LM claims semantic preservation, this change in underlying parameters and reliance on implicit behavior of `pc.utf8_slice_codeunits` introduces potential semantic risk. The expert's patch, in contrast, preserves the original `if/else` structure and only optimizes the creation of null values, thus fully preserving documented behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53152", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a specific data normalization (forcing nanosecond unit for mismatched datetime dtypes) to enable an existing efficient comparison path. The Expert's optimization is a more systemic change, introducing a direct conversion of datetime keys to `np.int64` arrays for highly efficient, native integer comparisons when dtypes are identical, which fundamentally lowers the hot path.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53231", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a fast path by modifying `_engine_type` to select the appropriate specialized engine type. The Expert's patch implements a more systemic optimization by modifying `_engine` and `_get_engine_target` to explicitly convert PyArrow-backed data to native pandas arrays and expose their raw 64-bit integer views for direct, highly optimized C-level processing by the specialized engines, which is an algorithmic refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53368", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and propose replacing Python-level operations with PyArrow compute functions and vectorized operations. However, the Expert's solution is deeper and broader, including an additional optimization and a more fully vectorized approach to the main data transformation by leveraging `list_flatten` and NumPy's efficient reshape/transpose, which avoids a Python loop present in the LM's solution.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53585", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same hotspot and aim to reduce Python overhead. However, the LM optimizes the existing Python loop by reducing interop and using Python sets, while the Expert completely eliminates the Python loop, replacing it with a deeper, fully vectorized solution using PyArrow compute and NumPy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53655", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Parallelization", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization enables Numba's parallelization by changing default parameters, which is a configuration-level change. The Expert's optimization involves a fundamental algorithmic refactor, removing an O(N log N) sorting step, and introducing new, specialized Numba kernels for direct grouping, representing a deeper, systemic improvement.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53731", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes redundant array computations within an existing code path. The Expert's optimization introduces a specialized 'fast path' that employs a fundamentally different, vectorized algorithm (NumPy's cumsum) for already sorted data, replacing a more general hash-table approach. Both involve algorithmic refactoring, but the Expert's is a deeper change in the underlying method for a specific, common case.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53806", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization enables an existing Cython-backed fast path for `MultiIndex` by removing a restrictive `isinstance` check. The Expert's optimization, however, is a systemic algorithmic refactor within Cython, changing how `MultiIndex` levels are re-coded to avoid expensive value materialization and lookups, operating directly on integer codes.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-53955", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces a fast path that converts PyArrow data to Python lists, transposes them using `zip`, and converts back. In contrast, the Expert's solution also introduces a fast path but delegates the core transpose to a new function that leverages PyArrow's native, C++-optimized `take` operation for vectorized reordering, which is a more systemic and deeply optimized approach.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54224", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation explicitly states that no patch was provided, rendering it unable to analyze any code changes or optimization strategies. Therefore, a meaningful comparison with the expert's detailed explanation is not possible.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-54299", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the return type of `DataFrame.iloc[int]` from a `pandas.Series` to a `numpy.ndarray` for `SingleBlockManager` cases, which alters documented behavior. The Expert's optimization preserves the expected `Series` return type while improving internal construction efficiency for ExtensionDtypes.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-54508", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes a `FutureWarning`, which alters the documented behavior of the `sum()` method by suppressing a warning. In contrast, the Expert's optimization introduces caching for an expensive introspection call, a purely performance-driven change that fully preserves all documented behavior and outputs.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-54509", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces conditional C/Cython-backed fast paths for specific set operations on `Index` objects, acting as specialized shortcuts. The Expert, however, performs a systemic algorithmic refactor by replacing a complex internal `MultiIndex` sorting mechanism with a direct, highly optimized call to NumPy's `np.lexsort`, improving a fundamental utility.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54835", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path within `MultiIndex.sort_values` based on an internal `sortorder` flag. The Expert performs a more systemic refactor by moving a general `is_monotonic` check to an earlier, more central `get_indexer_indexer` utility function, making the early exit applicable more broadly across different index types and sorting contexts.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-54883", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized `_concat_same_type` method for `DatetimeIndex` objects, acting as a fast path for a specific type. The Expert, however, performs an algorithmic refactor of the general `_unique_indices` function, improving how index unions are computed for overlapping indexes by avoiding large intermediate objects and leveraging `get_indexer_for`. This aligns with the LM using a narrow fast path/special case and the Expert applying an algorithmic refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55084", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a micro-optimization by removing a redundant conditional check within a Numba kernel's hot loop. The Expert, in contrast, implements a systemic change by introducing type-specific dispatch for PyArrow-backed dtypes, allowing `groupby` operations to leverage highly optimized native pandas array implementations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55131", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": ["Whitespace_Only_Patch"], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch consists solely of whitespace changes, which the LM correctly identifies as having no performance impact, making its 'optimization' misdirected. In contrast, the expert's patch introduces multiple functional changes that directly target and optimize the measured hotspot in `pd.read_stata` for wide dataframes, significantly reducing computation and memory overhead.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-55515", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces dedicated Cython functions for specific string methods (upper, lower, find), which is a pattern-specific optimization. The Expert, however, refactors a core internal mapping utility (`map_infer_mask`) using Cython's fused types to systemically optimize the handling of boolean and integer return types for a wide range of `Series.str` methods, representing a more general algorithmic refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55736", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized Cython/NumPy-optimized fast path within `get_indexer_with_fill` for `MultiIndex` targets. The Expert, however, performs a systemic algorithmic refactor by removing the specialized `get_indexer_with_fill` method entirely and instead encoding `MultiIndex` values into integers, then delegating the problem to the already highly optimized single-level `Index` fill-indexer.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55839", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a narrow, pattern-specific optimization by memoizing a compiled regular expression to avoid repeated work. The Expert, in contrast, implements systemic improvements by moving complex timezone handling and object conversion to Cython, restructuring data flow, and eliminating Python-level loops and intermediate object arrays.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-55898", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch introduces a fast path for specific conditions and falls back to a generic aggregation for other cases, which does not address the general O(N log N) bottleneck. The expert's patch, in contrast, replaces the O(N log N) sort-based algorithm with a generally applicable O(N) hash-table-based algorithm, directly targeting the measured hotspot for all cases.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56061", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for `Index` inputs within `_reindex_non_unique` to avoid redundant superclass calls. The Expert, however, fixes a systemic bug in `is_bool_indexer` that was incorrectly classifying `MultiIndex` objects, thereby preventing an inefficient and semantically incorrect code path from being taken. The expert's change corrects a fundamental logical flaw, while the LM's is a specific guard.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56062", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["NumPy_optimization", "memory_layout"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization: replacing inefficient NumPy operations (`np.eye().take().T`) with a direct allocation and advanced indexing. The expert's explanation is slightly deeper by explicitly mentioning `order=\"F\"` for Fortran-contiguous memory layout, which is a crucial detail for performance and correctness in this context, making it a 'deeper' understanding of the same strategy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56089", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe leveraging PyArrow's native capabilities for `get_dummies` on `string[pyarrow]` Series. However, the LM's patch implements a hybrid approach with significant Python loops for populating the dummy matrix, while the Expert's patch fully delegates the core logic to an underlying PyArrow-native implementation, indicating a deeper and more complete offloading of the hotspot.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56110", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert implement an early-exit fast path for `Index.sort_values` when the index is already sorted. The Expert's solution is deeper and broader in its logic, using a single `reverse` flag to handle both ascending and descending sort requests based on the index's monotonic properties, rather than separate conditional blocks.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56128", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized `CategoricalIndex.join` method with an `isinstance` check, acting as a fast path. The Expert, conversely, applies an algorithmic refactor to the base `Index.join` method, enabling `CategoricalIndex` to utilize an existing, systemic `_join_monotonic` fast path by pre-aligning categories.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56345", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation fails to mention that its optimization changes the actual hash values, which is a significant semantic alteration. In contrast, the expert's explanation explicitly acknowledges and documents this change in the `whatsnew` section and the example output, thus preserving transparency and documented behavior.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56508", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert implement a fast-path for identity indexing in `Index.take`. However, the Expert's solution is broader and deeper by using the more general `lib.is_range_indexer` utility and applying the optimization to both `Index` and `MultiIndex`, whereas the LM's condition is specific to `np.arange` and only for `Index`.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56806", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a narrow change (adding an import) to enable an existing `StringDtype`-specific fast path. The expert's optimization is a more systemic refactoring of the `_join_monotonic` function's dispatch logic, allowing it to utilize a specialized `_left_indexer_unique` method for certain non-unique, monotonic join cases.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56841", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path by removing a redundant conditional check for a specific `limit` value within an existing Cython loop. The Expert, in contrast, performs a systemic algorithmic refactor, changing the core approach from an O(N log N) sort to an O(N) linear scan, fundamentally altering how grouped fill operations are processed.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-56902", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for `ArrowExtensionArray` to avoid a `to_numpy()` conversion when data is monotonic and complete. The Expert, conversely, applies an algorithmic refactor to the `_join_via_get_indexer` method, enhancing `sort_values` to return an indexer, thereby eliminating a redundant computation in the join algorithm.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56919", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an algorithmic refactor to avoid materializing values in `MultiIndex.equals` by comparing internal codes and levels. The expert's solution, however, introduces `recode_for_categories` and an additional type check, suggesting a more robust and comprehensive approach to comparing levels and codes, making it a deeper implementation of the same strategy.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56990", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path within an existing method, leveraging an external vectorized PyArrow function for a specific data representation. The Expert, conversely, implements a systemic change by introducing a new, specialized `IndexEngine` and `HashTable` for string dtypes, and integrates it into the core engine dispatch mechanism, representing a deeper architectural refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-56997", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM performs an algorithmic refactor using vectorized NumPy, while the Expert adds conditional fast-paths. Although this is a clear difference between systemic and shortcut approaches, the specific mapping rule for 'Shortcut_vs_Systemic' (LM=Shortcut, Expert=Systemic) is not met, nor are the conditions for 'SameStrategy_DepthGap'.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57034", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization: a fast path for appending identical RangeIndex objects using `np.tile`. The Expert's patch, however, integrates this optimization more deeply into the `_concat` method, applying `np.tile` in multiple conditional branches and using a more robust `equals` check, indicating a broader and more thorough application of the same core tactic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57252", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by calling an existing utility (`_consolidate_inplace()`) to fix a specific data fragmentation pattern, which acts as a pattern-specific hack. The Expert implements a systemic optimization by modifying core library code to ensure new data blocks are created with an optimal Fortran-contiguous memory layout, representing a structural redesign for pandas' internal architecture.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57459", "repo": "pandas-dev/pandas"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations involve algorithmic changes. The LM changes the default sorting algorithm for a high-level function. The Expert, however, performs a deeper algorithmic refactor by replacing a less efficient C-level iteration with highly optimized vectorized NumPy operations within a critical internal index creation check, making the implementation more efficient and robust.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57534", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, meaning no optimization was performed and thus no hotspot was addressed. The expert, however, identified and optimized a specific micro-overhead in a hot path related to `RangeIndex` inference, which is directly triggered by the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-57560", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a specific attribute lookup by adding it to an internal set, creating a narrow fast path. The Expert, in contrast, introduces a new Cython function and refactors a core utility to efficiently detect arithmetic sequences, representing a more systemic algorithmic improvement leveraging native code and reducing allocations.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57812", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces an early-exit fast path for a specific input pattern (empty DataFrames in an inner join), bypassing the main merge algorithm. The Expert, conversely, refines an existing hot path within `RangeIndex` by removing a redundant object creation, which is a more systemic improvement to the underlying index join logic.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-57855", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Neither the LM nor the Expert explanation triggered any of the specific mapping rules for the defined categories. The LM's strategy is systemic (vectorization, algorithmic refactor), while the Expert's is a fast-path micro-optimization, but the rules for 'Shortcut_vs_Systemic' did not apply as written.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-58027", "repo": "pandas-dev/pandas"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its patch targets `ExtensionDtype` but the workload uses `int64` (NumPy dtype), meaning the patched code path would not be taken, making it unaligned. The Expert's patch, conversely, directly addresses the measured hotspot of datetime tick calculation during plotting, which is aligned with the workload.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-58992", "repo": "pandas-dev/pandas"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch and no explanation of an optimization, making it impossible to classify its approach or compare it meaningfully to the expert's detailed and effective optimization. Therefore, the difference is unclear.", "confidence": 0.4, "instance_id": "pandas-dev__pandas-59608", "repo": "pandas-dev/pandas"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization correctly applies an early-exit fast-path only when `self` is a generic `CategoricalDtype` and `dtype` is fully specified, preserving original semantics. The Expert's optimization, however, applies the early-exit solely based on `dtype` being fully specified, which risks altering behavior by returning `dtype` even when `self` is not generic and a merge operation would normally be required.", "confidence": 1.0, "instance_id": "pandas-dev__pandas-59647", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a new, specialized fast path within `_from_sequence` for NumPy float arrays. The Expert, conversely, optimizes an existing, more general utility function (`_coerce_to_data_and_mask`) by replacing a less efficient NaN-checking function with a highly optimized NumPy equivalent for float types, representing a systemic improvement to core machinery.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-60121", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a simple parameter change (lowering `_MIN_ELEMENTS`) that acts as a 'shortcut' to enable an existing, highly optimized backend (`numexpr`). The expert's optimization is a 'structural redesign' of an internal type-checking loop, replacing an expensive `cond.dtypes` iteration with an efficient `cond._mgr.blocks` iteration, which is an algorithmic refactor.", "confidence": 0.9, "instance_id": "pandas-dev__pandas-61014", "repo": "pandas-dev/pandas"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a narrow micro-optimization by replacing a pandas `get_loc` call with `get_indexer` to reduce Python function overhead. The Expert, in contrast, performs a systemic algorithmic refactor by hoisting redundant computations out of a loop and optimizing Dask array handling, changing the complexity of key operations from O(N) to O(1).", "confidence": 1.0, "instance_id": "pydata__xarray-4740", "repo": "pydata/xarray"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation states there is no code change, thus no optimization, making its 'optimization' completely unaligned with any performance improvement. The expert, however, identifies a specific hotspot (`__repr__` for large datasets) and implements a targeted optimization to reduce Python object allocations.", "confidence": 1.0, "instance_id": "pydata__xarray-5661", "repo": "pydata/xarray"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path in a single `Variable` constructor method to bypass dimension parsing. The expert also uses fast-path/early-exit optimizations but applies them more broadly across multiple `VariableCoder` subclasses, avoiding more significant overheads like dictionary copies and new object allocations in the decoding pipeline. This represents a deeper and broader application of a similar optimization strategy.", "confidence": 0.9, "instance_id": "pydata__xarray-7374", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path to use `numpy.logical_not` for boolean `~` operations, which is a micro-optimization. The Expert, however, implements a more systemic algorithmic refactor by adding an identity-based fast-path to `indexes_all_equal`, avoiding an expensive `O(N)` comparison of large `MultiIndex` objects with an `O(1)` check.", "confidence": 0.9, "instance_id": "pydata__xarray-7382", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by tuning a Dask chunking parameter (`limit='128 MiB'`) for an already-Dask array, which is a specific micro-optimization. The Expert implements a more systemic change by converting NumPy-backed coordinate variables to Dask arrays to prevent large, eager in-memory broadcasting, fundamentally altering the data flow and avoiding a major memory allocation.", "confidence": 0.9, "instance_id": "pydata__xarray-7472", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a 'fastpath' that bypasses xarray's general group indexing and iteration mechanisms specifically for flox-backed operations, acting as a specialized shortcut. The expert, conversely, applies a systemic improvement by adding a guard to a utility function to prevent redundant CFTimeIndex object creation, making the index handling algorithm more robust and efficient in general.", "confidence": 0.9, "instance_id": "pydata__xarray-7735", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a specific data conversion step using `np.fromiter` for a narrow set of fields, avoiding an intermediate Python list. The Expert implements a systemic change by redesigning the `dt` accessor's interaction with `CFTimeIndex` to avoid redundant and expensive `CFTimeIndex` object creation entirely, which is a more fundamental algorithmic improvement.", "confidence": 0.9, "instance_id": "pydata__xarray-7796", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a micro-optimization, replacing a less efficient Python idiom (`pd.unique`) with a more efficient one (`dict.fromkeys`) for finding unique elements in small lists. The Expert's optimization involves a systemic refactor of the core concatenation logic, primarily by replacing Python list operations with vectorized NumPy operations for index creation, significantly reducing Python overhead.", "confidence": 1.0, "instance_id": "pydata__xarray-7824", "repo": "pydata/xarray"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations that remove Python overhead in a hot path. The LM optimizes dictionary operations by avoiding temporary objects and `dict.update()`. The Expert's optimization is deeper by identifying and removing a redundant function call (`_maybe_wrap_data`) that was effectively dead work for already compatible data in the hot path.", "confidence": 0.9, "instance_id": "pydata__xarray-9001", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces specific `isinstance` checks and conditional logic to create a fast path for accessing datetime components from `IndexVariable`s. The Expert, however, applies a more systemic change by modifying internal `DataArray.copy()` calls within the `groupby` mechanism to use `deep=False`, thereby avoiding expensive deep copies of non-dimension coordinates containing Python objects, which is an algorithmic refinement.", "confidence": 0.9, "instance_id": "pydata__xarray-9429", "repo": "pydata/xarray"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's change acts as a fast-path enabler by fixing a default parameter to allow the underlying Zarr library to use consolidated metadata for Zarr V3. The Expert's change is a systemic algorithmic refactor, introducing caching and micro-optimizations to avoid redundant computations.", "confidence": 0.9, "instance_id": "pydata__xarray-9808", "repo": "pydata/xarray"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "Both explanations describe micro-optimizations within Cython code. The LM's optimization is a basic loop-invariant code motion, moving a constant calculation. The Expert's optimization is deeper, introducing a conditional fast path that leverages mathematical equivalence to avoid an expensive floating-point power operation for a common case (`dof=1`), resulting in a more significant performance improvement.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-10610", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for a specific configuration (`degree=2`). The Expert, in contrast, implements a systemic algorithmic refactor for the general dense input case, leveraging in-place NumPy operations and reusing intermediate computations for all degrees, which is a more fundamental improvement.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-13290", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Parallelization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert identify the need to switch to thread-based parallelism. However, the Expert's solution is deeper, not only changing the `joblib` backend but also refactoring the data collection to pre-allocate the result matrix and write in-place, eliminating the overhead of `np.hstack` and further reducing memory operations.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-13310", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["completeness", "parallelization", "preprocessing"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "Parallelization", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the core algorithmic refactor in Cython from a dense-array approach to a sparse-aware merge. However, the Expert's explanation is deeper and broader, additionally identifying the crucial `X.sum_duplicates()` preprocessing in the Python wrapper and the `prange` parallelization, which the LM misses.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-15049", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["MemoryOptimization", "AlgorithmicChoice"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations target the same function and preserve semantics. The LM's approach uses a highly optimized dense matrix multiplication (BLAS) and advanced indexing, which is a deeper algorithmic change. The Expert's approach introduces batching to reduce peak memory allocation for the original element-wise computation, making it 'safer' for memory scalability, which fits the 'Expert's is safer' criterion for SameStrategy_DepthGap.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-15257", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["NumPy_idiom_optimization", "Cython_rewrite"], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactoring and micro-overhead removal. The LM's approach is a full re-implementation of the core logic in Cython, while the expert's approach demonstrates a deeper understanding of NumPy's performance by refactoring less efficient masked operations into more optimized full-array operations within the existing Python/NumPy framework.", "confidence": 0.7, "instance_id": "scikit-learn__scikit-learn-15615", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe valid, systemic optimizations that preserve semantics, are aligned with the hotspot, and are local in scope. The LM uses Cython compilation to speed up a hot function, while the Expert uses an algorithmic refactor by reordering operations to reduce the input size for a costly step. No specific rule in the rubric covers this type of difference where both are strong, but distinct, systemic improvements.", "confidence": 0.8, "instance_id": "scikit-learn__scikit-learn-15834", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, indicating it failed to identify or address any hotspot, thus being unaligned/irrelevant. The expert, conversely, precisely identified and optimized a specific hotspot (repeated context manager overhead) within the KMeans 'lloyd' algorithm for small datasets, directly aligning with the workload.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-17235", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactors that improve performance. However, the LM's optimization is a deeper mathematical transformation that reduces the asymptotic computational complexity from O(N^3) to O(N^2). The Expert's optimization uses `np.linalg.multi_dot` to optimize the execution of existing matrix chain products, primarily by reducing temporary memory and finding optimal parenthesization, which improves constant factors and memory usage but does not change the asymptotic complexity of the underlying mathematical expression.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-17737", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM's explanation focuses on reducing the number of expensive KDTree constructions by hoisting them out of a loop in `_compute_mi_cd`. Expert's explanation focuses on optimizing the KDTree query itself by using `count_only=True` to reduce memory allocations and Python overhead, which is a deeper optimization of the neighbor counting mechanism within the query.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-17878", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the default convergence tolerance, which results in a less precise model (BehaviorChanging semantics). The Expert's optimization, however, removes unnecessary variance calculations without altering the model's output or behavior (Preserving semantics).", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-19606", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert explanations identify the same core optimization strategy: leveraging sparse matrix representations for the one-hot encoded target variable to reduce memory and computational overhead. Both provide detailed, accurate analyses of the patch's impact on the workload, including semantic preservation. The difference is minimal, primarily in which specific aspects of the optimization (e.g., computational vs. memory efficiency) they elaborate on more deeply.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-21837", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-overhead removal in parallel execution. The LM focuses on ensuring correct `joblib` configuration to avoid thread-nesting, while the Expert identifies and directly reduces inter-process communication (IPC) serialization overhead by passing minimal arguments, which is a deeper optimization of data flow.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-22106", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["data_representation", "redundant_conversion"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations leverage sparse matrix representations for the 'highs' solver. However, the LM's approach converts the entire `A_eq` matrix, including the input `X`, to sparse. The Expert's approach demonstrates a deeper understanding by specifically ensuring auxiliary matrices (`eye`, `ones`) are constructed sparsely earlier to avoid redundant internal conversions by the solver, rather than a wholesale conversion of `X`.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-22206", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations propose the same strategy of early type conversion for boolean arrays to improve performance. However, the expert's choice to convert to floating-point types is a deeper optimization, specifically targeting the highly optimized floating-point arithmetic paths (e.g., BLAS/LAPACK via `safe_sparse_dot`) that are most efficient for the numerical computations within `chi2`.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-22235", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes `X.sort_indices()` calls, which are a safety mechanism, relying on the specific workload pre-sorting the data. This introduces a potentially risky semantic change if the input is not pre-sorted. The expert's optimization, however, safely skips redundant input validation checks for base estimators after the main `IsolationForest` has already validated the data, preserving documented behavior.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-23149", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization for the workload is a fast-path that conditionally skips calculations when monotonic constraints are not used. The Expert's optimization is a systemic algorithmic refactor that significantly reduces the number of features for which histograms are computed at each node, fundamentally changing the computational complexity for specific interaction constraints.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-24856", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes the existing `predict` hot path by combining two tree traversals into a single, more efficient Cython function. The Expert, however, implements a deeper algorithmic refactor by precomputing node depths during the `fit` phase, thereby removing the path length calculation entirely from the `predict` hot path and replacing it with fast array lookups. Both use similar strategies (algorithmic refactor, Cythonization), but the Expert's approach is a more fundamental restructuring of the data flow.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25186", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a 'shortcut' by changing a default algorithm parameter, a high-level configuration choice. The expert's optimization is 'systemic,' involving a structural redesign and refactoring of internal functions to eliminate redundant input validations in a hot loop.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25490", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the core optimization of replacing large NumPy array operations with scalar Cython calculations for loop bounds. However, the Expert explanation provides a deeper analysis by also detailing the use of Cython memory views to further reduce Python overhead for array access within the loops, an additional significant optimization present in the patch.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-25713", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe vectorization and Python loop removal. However, the Expert's approach is broader and deeper by introducing and leveraging a dedicated `resample` utility function, which is then used in multiple parts of the codebase, making it a more systemic refactor compared to the LM's direct vectorization within a single method.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-27344", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning", "FastPath/SpecialCase"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Parallelization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization reduces the number of samples used for learning binning thresholds, which is a heuristic change that could alter the learned bins and thus the model's behavior or accuracy. In contrast, the Expert's optimization introduces parallelism to the binning process, performing the exact same computations but concurrently, thereby preserving the original semantics and output.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-28064", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by avoiding an unnecessary data copy (a micro-overhead removal). The Expert performs dead work removal by refining the logic for identifying rows needing imputation, which is a more systemic algorithmic improvement.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-29060", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["completeness", "cross-module-refactor"], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same core optimization strategy: pre-indexing data before parallel dispatch to reduce serialization overhead. However, the Expert's explanation and diff show a broader and deeper implementation, including removing the now-redundant indexing logic from `sklearn/pipeline.py`, which the LM's explanation and diff omit.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-29330", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Heuristic/ParamTuning"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization reduces default iteration and trial counts (e.g., `n_iter` from 30 to 2, `n_trials_tot` from 500 to 100), which risks altering the quality or accuracy of the robust estimate by performing less thorough computations. The expert's optimizations, however, strictly preserve the original algorithm's behavior and output quality while making the same work faster.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-29835", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is systemic, replacing a multi-step sparse matrix conversion with a direct, highly optimized NumPy `np.add.at` operation. The Expert's optimization introduces conditional fast-paths to skip Python-level overhead and unnecessary array slicing when input labels are already in an optimal, pre-indexed form.", "confidence": 0.9, "instance_id": "scikit-learn__scikit-learn-9843", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the convergence tolerance of an inner solver, leading to a 'looser convergence criterion' and 'fewer iterations,' which implies a potential change in the precision of the output. The Expert's optimization, however, focuses on reducing memory allocations and copies through in-place updates, explicitly preserving the algorithm's correctness and behavior.", "confidence": 1.0, "instance_id": "scikit-learn__scikit-learn-9858", "repo": "scikit-learn/scikit-learn"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an algorithmic refactor. The LM's approach replaces the entire iterative Householder algorithm with a single call to a highly optimized, compiled QR decomposition routine, representing a broader change in the fundamental mathematical method. The Expert's approach optimizes the implementation details of the *existing* Householder algorithm by reducing intermediate memory allocations and replacing expensive matrix multiplications with more efficient operations within the loop, representing a deeper optimization of the original algorithm's steps.", "confidence": 0.9, "instance_id": "scipy__scipy-10064", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes a specific, redundant complex division loop in a C function, addressing a narrow inefficiency. The Expert's optimization introduces a systemic change by implementing FFT plan caching in the underlying C++ library, which broadly improves performance for repeated FFT calls of the same size.", "confidence": 0.9, "instance_id": "scipy__scipy-10393", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a specific NumPy array slicing operation by replacing `np.delete` with more efficient direct indexing, which is a micro-optimization or pattern-specific hack. The Expert, however, performs a systemic algorithmic refactor, replacing an O(N^2) pairwise distance calculation with an O(N log N) KD-tree based approach for duplicate detection.", "confidence": 0.9, "instance_id": "scipy__scipy-10467", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply vectorization and micro-optimizations to replace less efficient operations with more performant NumPy equivalents. However, the Expert's change involves a deeper algorithmic refactor, transforming a Python-heavy grouping logic into a fully vectorized NumPy pipeline using a combination of functions, whereas the LM's changes are more direct replacements of individual function calls.", "confidence": 0.9, "instance_id": "scipy__scipy-10477", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["custom_hashing", "robustness"], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations propose memoization. However, the LM uses `functools.lru_cache` which fails to cache calls involving unhashable NumPy arrays in the workload. The Expert implements a custom memoization decorator that correctly generates hashable keys from NumPy array properties, making the caching effective for all relevant calls in the workload and broader in its application.", "confidence": 0.9, "instance_id": "scipy__scipy-10564", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a specific step (list flattening) using a C-optimized `itertools` function, but still builds a large intermediate Python list. The Expert performs a systemic refactor by pre-allocating NumPy arrays and directly populating them via slice assignment, eliminating the creation of large intermediate Python lists and their associated memory and Python overhead.", "confidence": 0.9, "instance_id": "scipy__scipy-10921", "repo": "scipy/scipy"}
{"primary_category": "Invasive_vs_Minimal", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "CrossModule/Global", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is invasive, introducing a new Cython module, modifying the project's build system (`cythonize.py`, `setup.py`), and adding a dispatcher. In contrast, the Expert's optimization is minimal, refactoring the Python code within a single method in `lil.py` to use existing NumPy primitives and conditional logic.", "confidence": 0.9, "instance_id": "scipy__scipy-10939", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a pattern-specific optimization for zero-row detection using `csr_matrix.indptr`. The Expert, while including similar format conversion optimizations, applies a more systemic algorithmic refactor by consistently switching all internal sparse matrix operations and constructions (e.g., `hstack`, `vstack`, `zeros`, new row additions) to use the CSR format throughout the relevant functions.", "confidence": 0.9, "instance_id": "scipy__scipy-11358", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow early-exit fast-path for the specific case of multiplying by an empty sparse matrix. The Expert, however, performs a systemic refactoring of the underlying C++ sparse matrix multiplication routines and their Python wrappers, improving memory allocation and Python-C API interactions for the general case.", "confidence": 1.0, "instance_id": "scipy__scipy-11478", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by replacing a Python-level nested generator with a C-optimized `itertools.chain.from_iterable` function, which is a pattern-specific micro-optimization. The Expert, in contrast, implements new Cython functions to offload entire hot loops for calculating lengths and flattening data, representing a systemic shift to compiled C code for the core logic.", "confidence": 0.9, "instance_id": "scipy__scipy-11517", "repo": "scipy/scipy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a systemic algorithmic refactor using vectorization, while the Expert's is a narrow fast-path guard. Conceptually, this aligns with 'Shortcut_vs_Systemic', but the rubric's rule for this category is directional (LM as shortcut, Expert as systemic) and does not apply to this inverse scenario. No other rule fits.", "confidence": 0.9, "instance_id": "scipy__scipy-11757", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations correctly identify the hotspot and propose the same highly effective vectorized solution using `cdist` to replace Python loops for distance calculation. The expert's explanation is slightly broader by also mentioning the related benchmark file changes, indicating a more comprehensive understanding of the project context.", "confidence": 0.9, "instance_id": "scipy__scipy-11982", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Heuristic/ParamTuning"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization changes the behavior of `maxwell.fit` by fixing the `loc` parameter to 0, even when the input data has a different `loc`, thus altering the fitting semantics. The expert's optimization, however, preserves the exact mathematical behavior of the `maxwell` distribution's log-PDF while making its calculation more efficient.", "confidence": 1.0, "instance_id": "scipy__scipy-12001", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is a parameter tuning (increasing `blocksize`), which is a pattern-specific heuristic. The expert's optimization is a systemic change, involving Cythonizing a performance-critical nested Python loop into highly optimized C code, which is a form of compilation and micro-overhead removal.", "confidence": 0.9, "instance_id": "scipy__scipy-12474", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast path for specific parameters (a=1.5, c=1.0) using a specialized algorithm. The Expert, however, implements a general algorithmic refactor for `gengamma.rvs` that applies to all parameters, leveraging NumPy's optimized `standard_gamma` for a systemic improvement.", "confidence": 0.9, "instance_id": "scipy__scipy-12587", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations involve micro-overhead removal. However, the Expert's approach is broader and deeper, refactoring multiple Python-level operations (NaN checks, array creation) to C, thereby significantly reducing Python interpreter overhead and Python-C boundary crossings, which is a more systemic change than the LM's single C++ micro-optimization.", "confidence": 0.9, "instance_id": "scipy__scipy-13107", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe removing redundant computations within `skew` and `kurtosis`. However, the LM's patch introduces a helper that computes the mean, deviations, and powers of deviations once to derive all required central moments. The Expert's patch, while also removing redundant mean calculations, still recomputes deviations from the mean for each moment order, making the LM's approach deeper in avoiding more array-wide operations.", "confidence": 0.9, "instance_id": "scipy__scipy-13388", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["memory_efficiency", "vectorization_approach"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations aim to optimize the O(n^2) calculation by leveraging NumPy's vectorized operations and reducing Python overhead. The LM achieves this by pre-computing an O(n^2) jackknife samples matrix and performing a single matrix-vector multiplication. The Expert, however, optimizes the calculation *within* the existing O(n) loop by using efficient slice-based dot products, thereby avoiding the O(n^2) memory allocation of the intermediate matrix, making it a deeper and more memory-efficient optimization of the same core strategy.", "confidence": 0.9, "instance_id": "scipy__scipy-13566", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization preserves the output shape for scalar inputs (an array of size `np.sum(cond)`), while the Expert's optimization explicitly changes this behavior, returning a 1-element array for scalar inputs, which is a semantic change from the original behavior.", "confidence": 1.0, "instance_id": "scipy__scipy-13611", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation correctly identifies that its proposed optimization is not exercised by the workload, classifying it as unaligned. In contrast, the Expert's explanation claims its optimization is directly exercised by the workload, classifying it as aligned. This highlights a key difference in the accuracy of hotspot identification between the two explanations.", "confidence": 0.9, "instance_id": "scipy__scipy-13759", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch includes specific Python-level changes to ensure the weighted Chebyshev metric correctly dispatches to an existing C implementation (a 'fast path' enabler) and a micro-optimization in the C loop. The Expert's patch, however, performs a systemic refactoring of the entire metric dispatch registry in Python, replacing dynamic checks with a more direct, class-based approach, which is a structural redesign.", "confidence": 0.9, "instance_id": "scipy__scipy-13786", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe implementing a specialized `_add_sparse` method for `dia_matrix` to avoid costly conversions. However, the Expert's implementation leverages existing `dia_matrix` methods like `diagonal()` and `setdiag()` for combining diagonals, which are likely optimized and robust, whereas the LM's approach involves more manual array padding and indexing, indicating a difference in implementation depth and integration with the existing API.", "confidence": 0.9, "instance_id": "scipy__scipy-14004", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert correctly identify and explain the core optimization strategy of offloading Canberra distance calculation to optimized C++ code. The expert's explanation provides a slightly deeper technical detail by explicitly mentioning a 'branchless replacement' for handling division by zero within the C++ implementation, indicating a minor depth advantage.", "confidence": 0.9, "instance_id": "scipy__scipy-14085", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states its primary optimization (precomputing `full_bin_map` for `Vdim > 1`) is not directly realized by the workload and notes a potential redundancy. In contrast, the expert's patch directly targets and vectorizes the specific statistics (`min`, `max`, `median`) that constitute the workload's hotspot.", "confidence": 0.9, "instance_id": "scipy__scipy-14625", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized fast path for the `truncnorm` distribution when the upper bound `b` is infinite, using inverse transform sampling. In contrast, the Expert performs a systemic algorithmic refactor of the general `_ppf` method, replacing iterative scalar calculations and Python loops with a fully vectorized, analytical approach.", "confidence": 0.9, "instance_id": "scipy__scipy-16599", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an algorithmic refactor for the PPF calculation. However, the Expert's approach is deeper and broader, moving the computation to highly optimized native C++ code via Cython ufuncs, integrating a new module, and including numerical stability considerations, whereas the LM implements the analytical formula directly in Python.", "confidence": 0.9, "instance_id": "scipy__scipy-16790", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "LM applies a localized micro-optimization by replacing a `np.arange` call with a Cython loop within the hot function. Expert performs a more systemic refactor, moving precomputation and allocation out of the hot loop into the Python caller and redesigning the data flow for sparse matrix construction.", "confidence": 0.9, "instance_id": "scipy__scipy-16840", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Dataflow/GraphRestructure", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM implements a detailed, element-wise Python loop for `__iadd__`, which is a pattern-specific approach to in-place addition. The Expert performs a structural redesign of `__setitem__`'s dispatch logic to ensure efficient sparse-aware assignment, avoiding a systemic `O(N^2)` densification.", "confidence": 0.9, "instance_id": "scipy__scipy-18211", "repo": "scipy/scipy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces `lru_cache` to memoize a repeatedly calculated constant. The Expert's optimization, however, replaces a composite calculation with a single, more efficient `sc.beta` function call, effectively lowering the computational cost of the hot path itself rather than just caching its result.", "confidence": 1.0, "instance_id": "scipy__scipy-18799", "repo": "scipy/scipy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided no code changes or optimization explanation, explicitly stating the patch was empty. The expert, however, provided a detailed explanation of an algorithmic refactor that improves performance by using more efficient NumPy operations. Due to the LM's lack of content, a direct comparison of optimization strategies is not possible.", "confidence": 0.4, "instance_id": "scipy__scipy-18850", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations aim to move computationally intensive loops to native code. The LM achieves this by directly implementing the logic in new Cython functions. The Expert achieves this by refactoring the problem to use existing, highly optimized SciPy digital filtering primitives (`lfilter`, `sosfilt`), which represents a deeper, more idiomatic, and potentially more robust solution within the SciPy ecosystem.", "confidence": 0.9, "instance_id": "scipy__scipy-18917", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM explanation incorrectly states that the patch is empty and makes no changes, thus completely missing the actual optimization. The Expert explanation correctly identifies the hotspot and details how the patch removes redundant `np.all` comparisons in a hot loop, directly aligning with the workload.", "confidence": 1.0, "instance_id": "scipy__scipy-18996", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a highly specific, hardcoded Cython implementation for a function named 'f', guarded by a name check, making it a benchmark-specific shortcut. The expert, in contrast, implements a general micro-optimization by replacing `np.real/imag()` calls with direct attribute access (`.real/.imag`), which systemically improves the performance for all complex integrands without special casing.", "confidence": 0.9, "instance_id": "scipy__scipy-19324", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization for `cosine` removes a clamping operation, which its explanation explicitly states is a 'semantic change'. The expert's optimization for `correlation` focuses on replacing less efficient NumPy operations with mathematically equivalent, highly optimized alternatives (e.g., `np.average` with `np.dot`) while preserving the function's documented behavior.", "confidence": 0.9, "instance_id": "scipy__scipy-19583", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both LM and Expert apply micro-optimizations by replacing `np.average` with more direct NumPy operations. The expert's patch is slightly 'deeper' by using an in-place division (`w /= w.sum()`) to avoid an intermediate array allocation for normalized weights, a detail not present in the LM's version. While the expert's change introduces a side-effect (modifying input `w`), the rubric's `SemanticsRisk_vs_Preserving` category is defined for when the LM introduces the risk, not the expert.", "confidence": 0.9, "instance_id": "scipy__scipy-19589", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation incorrectly identifies `_broadcast_concatenate` as a bottleneck for the workload, when it was dead code not called by `mannwhitneyu`. The expert correctly identifies and optimizes the true hotspot, which is the redundant computation of tie information via `np.unique`.", "confidence": 0.9, "instance_id": "scipy__scipy-19749", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "rationale": "The LM applies a narrow, pattern-specific change by forcing `mergesort` for `np.argsort` to address performance issues with tied data. The expert, in contrast, performs a systemic refactor of the `rankdata` function, leveraging multiple highly optimized NumPy primitives like `np.repeat` and `np.put_along_axis` to fundamentally improve tie handling and rank reordering.", "confidence": 0.9, "instance_id": "scipy__scipy-19776", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for the specific conditions of setting the main diagonal of an empty matrix. The Expert, however, performs a more systemic refactoring by introducing a helper function (`_coo_to_compressed`) and removing `_set_self`, which generally reduces Python object overhead and intermediate object creation during sparse matrix conversions and attribute assignments across the codebase.", "confidence": 0.9, "instance_id": "scipy__scipy-19962", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations. The LM introduces a highly specialized C fast-path for a narrow case, which is a form of micro-overhead removal for that specific pattern. The Expert, however, applies broader, generally applicable Python-level micro-optimizations (using `asarray` and `.size`) that improve common NumPy API usage patterns, making the expert's solution broader in its generalizability.", "confidence": 0.9, "instance_id": "scipy__scipy-20325", "repo": "scipy/scipy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path for a specific lambda function (`lambda x: x*x`) using a brittle heuristic (`func(2)==4 and func(3)==9`) that risks misidentifying functions or failing to identify the target, thus potentially altering semantics. The expert, conversely, preserves the exact behavior of the general algorithm by offloading its hot loops to Pythran-compiled native code.", "confidence": 0.9, "instance_id": "scipy__scipy-21440", "repo": "scipy/scipy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation focuses on a blank line addition, correctly concluding it has no performance impact, which means its 'optimization' is misdirected. The Expert, however, identifies and optimizes a true hotspot by hoisting attribute lookups out of a tight loop, significantly reducing Python interpreter overhead.", "confidence": 1.0, "instance_id": "scipy__scipy-22660", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast path for 1D non-negative integer arrays using `np.bincount` wrapped in Cython, which is a pattern-specific optimization. The Expert, in contrast, implements a systemic, fully vectorized NumPy algorithm for the general case of multi-dimensional arrays, improving the core logic for a broader set of inputs.", "confidence": 0.9, "instance_id": "scipy__scipy-22676", "repo": "scipy/scipy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe algorithmic refactoring and micro-overhead removal targeting the same hotspot. However, the LM's approach is deeper as it completely removes the Python `for` loop by fully vectorizing the computation, whereas the Expert's approach optimizes the operations *within* the existing Python loop.", "confidence": 0.9, "instance_id": "scipy__scipy-8558", "repo": "scipy/scipy"}
{"classification": "Unknown / Not Enough Information", "confidence": "low"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["AlgorithmicRefactor", "Vectorization"], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations identify the same hotspot and optimize it by replacing `numpy.polynomial.Polynomial` objects with vectorized NumPy operations. The LM uses a direct recurrence relation for Hermite polynomials, while the Expert employs a more general linear algebra approach by constructing operator matrices for polynomial differentiation and multiplication, which is a deeper application of vectorized principles for polynomial algebra.", "confidence": 0.9, "instance_id": "scipy__scipy-9766", "repo": "scipy/scipy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces caching to helper functions, which acts as a pattern-specific hack for repeated calls. The Expert, conversely, integrates a C-level optimized library (`gmpy`) for factorial computation, representing a systemic improvement through compilation.", "confidence": 0.9, "instance_id": "sympy__sympy-10621", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a micro-optimization (loop-invariant code motion), which is a pattern-specific hack, to a single division operation within a loop. The Expert, in contrast, completely rewrites the `_a` function with a new number-theoretic algorithm, including precomputation and specialized modular arithmetic, representing a systemic algorithmic refactor.", "confidence": 0.9, "instance_id": "sympy__sympy-10919", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization via `lru_cache` to reuse previously computed results. The Expert's optimization, in contrast, implements a specialized, faster algorithm for a specific input range, effectively lowering the computational cost of the hotspot rather than just caching its output.", "confidence": 1.0, "instance_id": "sympy__sympy-11675", "repo": "sympy/sympy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch only adds the benchmark script and explicitly states it makes no changes to the codebase that would improve performance, thus it is unaligned to any hotspot. The expert's patch, however, directly targets the measured hotspot by implementing significant algorithmic and object-creation optimizations within the `sympy.physics.vector` module, which is heavily used by the benchmarked function.", "confidence": 1.0, "instance_id": "sympy__sympy-11676", "repo": "sympy/sympy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch, meaning no optimization was performed, rendering its approach entirely misdirected relative to any performance goal. The expert, conversely, implemented a systemic refactoring of the SAT solving process, directly targeting and optimizing the measured hotspot by avoiding redundant CNF conversions and streamlining data flow.", "confidence": 1.0, "instance_id": "sympy__sympy-11789", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional fast-path that offloads numerical matrix operations to NumPy, a C-implemented library, but only for matrices containing pure numbers. The Expert, in contrast, applies algorithmic refactoring and micro-optimizations to the internal Python implementation of DenseMatrix operations, improving their general efficiency without relying on external libraries or specific element-type checks.", "confidence": 0.9, "instance_id": "sympy__sympy-12640", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's patch explicitly adds a `@cacheit` decorator, introducing caching as an optimization strategy. The expert's patch optimizes the hot path by replacing an inefficient two-step modular exponentiation with Python's C-optimized three-argument `pow` function, which directly lowers the computational hotspot.", "confidence": 1.0, "instance_id": "sympy__sympy-14772", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": ["micro-optimization", "applicability"], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both optimizations target micro-overhead within the `_print_Function` method. The LM introduces a specialized fast path (algorithmic refactor) for a very specific, deeply nested pattern. The Expert, however, identifies and removes a more general and fundamental source of overhead: a redundant `try...except TypeError` block that was always triggered for string-mapped functions, making its solution broader and deeper.", "confidence": 0.9, "instance_id": "sympy__sympy-15379", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Native/Vectorized/Cython/Pythran", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM applies a micro-optimization by replacing `try...except KeyError` with `dict.get()` for cache lookups, a pattern-specific hack to reduce Python overhead. The Expert, in contrast, implements a systemic improvement by replacing the entire pure-Python caching mechanism with a C-extension-based LRU cache (`fastcache.clru_cache`), fundamentally lowering the overhead of caching itself through native code.", "confidence": 0.9, "instance_id": "sympy__sympy-15453", "repo": "sympy/sympy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM incorrectly states that the patch introduces no code changes to the SymPy library and thus no performance improvement, claiming it only adds a benchmark. In contrast, the expert correctly identifies a refactoring of `matrix_multiply_elementwise` that delegates to a more optimized internal method, directly targeting the workload's hotspot.", "confidence": 1.0, "instance_id": "sympy__sympy-15736", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a fast-path specifically for a narrow, pattern-specific input (`3 * 2**x`). The Expert, however, implements a more systemic algorithmic refactor by changing the core trailing zero counting method from bit-by-bit to byte-by-byte processing, which is a general improvement for a broader range of inputs.", "confidence": 0.9, "instance_id": "sympy__sympy-15909", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path for a specific input pattern (Or/And of distinct literals) and adds caching. The Expert implements a systemic algorithmic change by adding a complexity-based early-exit, preventing exponential time computation for expressions exceeding a variable count threshold.", "confidence": 0.9, "instance_id": "sympy__sympy-16134", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe the same core optimization strategy: replacing a Python function call with a C-optimized built-in `pow` function to implement Euler's criterion for the Legendre symbol. The LM's patch is slightly more direct by returning the result of `pow` directly, which inherently yields 0, 1, or -1, while the Expert's patch retains an `if/else` structure to map the `pow` result.", "confidence": 0.9, "instance_id": "sympy__sympy-17916", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM improves the initial guess for the Python `integer_nthroot` algorithm using arbitrary-precision floats from `mpmath`, reducing iterations of a Python loop. The Expert replaces the entire Python `integer_nthroot` implementation with a direct call to the highly optimized C-language `gmpy.iroot` function, representing a deeper, native-code optimization for the same task.", "confidence": 0.9, "instance_id": "sympy__sympy-18276", "repo": "sympy/sympy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "BehaviorChanging", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly states that its refactoring of `is_perfect` introduces a semantic change, causing it to return `False` for an input that the original code would return `True`. The expert's optimization, conversely, introduces caching while preserving the correct behavior.", "confidence": 1.0, "instance_id": "sympy__sympy-18591", "repo": "sympy/sympy"}
{"primary_category": "Misdirected_vs_Hotspot", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unaligned/Irrelevant", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation correctly states that its provided patch is not an optimization to the system under test, but merely the workload script itself, thus offering no performance improvement. In contrast, the expert's explanation details several aligned optimizations to the `sympy.Poly` class, a measured hotspot for the given workload.", "confidence": 1.0, "instance_id": "sympy__sympy-19270", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a memoization cache, which is a pattern-specific hack for identical repeated inputs. The Expert performs a structural redesign of the `sign` function's evaluation logic, moving an expensive `im(a)` call inside a conditional to avoid dead work in the general case, which is a more systemic improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-20228", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Native/Vectorized/Cython/Pythran", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary optimization is a pattern-specific fast path for handling negative terms within `_print_Add`, reducing object creation and redundant calls. The Expert's optimization is a systemic refactor of a core utility function (`line_width`) by replacing a Python loop with a C-optimized `str.translate()` operation.", "confidence": 0.9, "instance_id": "sympy__sympy-20384", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "AlgorithmicRefactor", "Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a conditional pre-simplification step (`powdenest`) for definite integrals, acting as a specific shortcut for certain expression patterns. The expert, in contrast, implements systemic improvements to core symbolic utilities, such as optimizing symbol dependency checks using set operations and memoizing expensive `convert` function calls in polynomial solvers, which benefit the general case of symbolic integration.", "confidence": 0.9, "instance_id": "sympy__sympy-20989", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "Native/Vectorized/Cython/Pythran"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both the LM and Expert apply the same core strategy of replacing Python-level iteration and function calls with C-optimized list operations and avoiding data copies. However, the Expert's solution is broader, applying the optimization to both `Matrix.eye` and `Matrix.zeros` (both identified as hotspots), and uses more specialized C-level list operations (multiplication and slice assignment) for `Matrix.eye` compared to the LM's general list comprehension.", "confidence": 0.9, "instance_id": "sympy__sympy-21006", "repo": "sympy/sympy"}
{"primary_category": "SemanticsRisk_vs_Preserving", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "PotentiallyRisky", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's explanation explicitly notes a 'potential correctness issue' in its optimization for `is_Mul` expressions, indicating a risk to semantic preservation. In contrast, the expert's optimization clearly preserves documented behavior while significantly reducing function calls and object allocations during pretty-printing.", "confidence": 0.9, "instance_id": "sympy__sympy-21169", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe micro-optimizations, with 'Micro-OverheadRemoval' being a common strategy. The Expert's optimization is deeper, targeting the fundamental Python object instantiation mechanism (`__new__` vs `__init__`) for a frequently created element, directly removing a method call from the object creation path. The LM's optimization, while also removing overhead, includes a broader algorithmic refactor (batch processing) and dataflow change.", "confidence": 0.9, "instance_id": "sympy__sympy-21391", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization introduces memoization (caching) to avoid re-computing results for identical `ask` calls. The expert's optimization, however, fundamentally refactors the assumption system's knowledge base by pre-computing logical implications, transforming multi-step inferences into direct, faster lookups, thus lowering the cost of the hotspot itself rather than just caching its output.", "confidence": 1.0, "instance_id": "sympy__sympy-21455", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Heuristic/ParamTuning"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by changing a default parameter to use a dense matrix representation, which acts as a fast path for small matrices. The Expert, however, implements a systemic algorithmic refactor by replacing fraction-free Gaussian elimination with the Bareiss algorithm, fundamentally improving symbolic expression handling.", "confidence": 1.0, "instance_id": "sympy__sympy-21501", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specialized pattern-matching and algorithmic transformation for a very specific type of integral. In contrast, the Expert optimizes fundamental arithmetic operations (`__add__`, `__sub__`, `__mul__`) by adding early-exit checks for zero operands and direct numerical multiplication, thereby reducing redundant symbolic computations and avoiding expensive simplification calls across the entire system.", "confidence": 0.9, "instance_id": "sympy__sympy-21543", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization removes overhead from an `lru_cache` that was rendered ineffective by the benchmark's specific `setup` routine, addressing a benchmark-specific anti-pattern. The Expert's optimization performs a structural redesign within the `Rational` constructor to avoid redundant object creation for common integer inputs, representing a more general algorithmic improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-21954", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Caching/Memoization", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a narrow fast-path (early exit) for a specific, simple input pattern (`integrand == symbol`). The Expert performs a systemic optimization by structurally redesigning the `special_function_rule` to lazily initialize and cache expensive symbolic patterns and Wild objects at the module level, significantly reducing repeated object creation overhead for all subsequent calls to that rule.", "confidence": 0.9, "instance_id": "sympy__sympy-23696", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM identifies an algorithmic improvement for a sub-problem (canonicalization from O(N^2) to O(N)) and infers its use. The Expert identifies a more fundamental algorithmic change, replacing a combinatorial 'generate and filter' approach (O(k^n)) with a direct, efficient generation algorithm (FKM), which has a much deeper impact on the overall problem's complexity.", "confidence": 0.9, "instance_id": "sympy__sympy-24313", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes by replacing a slightly more expensive property check with a cheaper, logically equivalent one within an existing loop, a micro-optimization. The Expert, however, performs an algorithmic refactor that introduces an early-exit mechanism, reducing the complexity of the hot path from O(N) to O(1) for the given workload.", "confidence": 0.9, "instance_id": "sympy__sympy-24485", "repo": "sympy/sympy"}
{"primary_category": "Cache_vs_LoweredHotPath", "secondary_tags": [], "lm_attributes": {"StrategyType": ["Caching/Memoization", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's primary strategy involves extensive caching and memoization of computed values, alongside algorithmic improvements to graph traversal. The Expert's optimization, however, fundamentally refactors a core calculation by replacing an expensive symbolic substitution with more efficient direct matrix algebra, effectively lowering the computational cost of the hotspot rather than just caching its result.", "confidence": 0.9, "instance_id": "sympy__sympy-24792", "repo": "sympy/sympy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM's optimization is an algorithmic refactor and significant micro-overhead removal in a core numerical loop. The Expert's is a subtle micro-overhead removal by reordering boolean conditions. None of the specific classification rules strictly apply, as the LM's change is arguably more 'systemic' or 'deeper' than the Expert's, which is the inverse of the typical pattern for categories like 'Shortcut_vs_Systemic' or 'SameStrategy_DepthGap'.", "confidence": 0.6, "instance_id": "sympy__sympy-24884", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Unknown", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for 2x2 matrices by switching to the 'ADJ' method. The Expert, conversely, implements a more systemic change by introducing a new 'DomainMatrix' based inversion method and making it the default, leveraging a more specialized internal representation for broader applicability.", "confidence": 0.9, "instance_id": "sympy__sympy-25452", "repo": "sympy/sympy"}
{"primary_category": "Unclear", "secondary_tags": [], "lm_attributes": {"StrategyType": [], "SemanticsImpact": "Unknown", "Scope": "Unknown", "HotspotAlignment": "Unknown", "Generalizability": "Unknown"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM provided an empty patch and explicitly stated it could not analyze any code changes or explain performance improvements. Therefore, no optimization strategy or explanation was provided by the LM, making it impossible to classify a difference.", "confidence": 0.4, "instance_id": "sympy__sympy-25591", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe an algorithmic refactor to correctly and efficiently compute Euler's totient function. The LM introduces a new, dedicated sieve method and refactors `totientrange` to use it, representing a structural redesign. The Expert refines the existing sieve loops in-place by adding prime checks and correcting the update formula, demonstrating a deeper, more surgical understanding of the existing algorithm's flaws.", "confidence": 0.9, "instance_id": "sympy__sympy-25631", "repo": "sympy/sympy"}
{"primary_category": "SameStrategy_DepthGap", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Dataflow/GraphRestructure"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "Both explanations describe optimizations for sparse matrices. The LM's change is a structural redesign, ensuring `randMatrix` returns a SparseMatrix, which enables sparse algorithms. The expert's change provides deeper algorithmic optimizations by refactoring core methods (`_eval_atoms`, `uniquely_named_symbol`) to efficiently process sparse matrix elements, directly targeting computational bottlenecks within the matrix operations.", "confidence": 0.9, "instance_id": "sympy__sympy-26057", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a specific fast-path for identity matrices, which is a narrow guard. The Expert, however, fixes a systemic inefficiency in a symbol generation utility function by correcting argument passing, which drastically reduces overhead for large matrices in the general case, representing a more fundamental improvement.", "confidence": 0.9, "instance_id": "sympy__sympy-26063", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM optimizes a specific symbolic pattern within the `Vector.diff` method by reordering `diff` and `express` operations for a special case. The Expert performs a more systemic algorithmic refactor in `partial_velocity`, replacing a loop of generic `diff` calls with a specialized `linear_eq_to_matrix` function, which is a more fundamental change to the overall algorithm.", "confidence": 0.9, "instance_id": "sympy__sympy-26367", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["AlgorithmicRefactor", "FastPath/SpecialCase"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "expert_attributes": {"StrategyType": ["AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM replaces a complex, general algorithm with a simpler Sieve, which acts as a specialized fast path for the specific input range (n <= 10^7) and workload conditions. The Expert, conversely, applies deeper algorithmic refinements (odd-number processing, composite skipping) to the existing, more general Meissel-Lehmer variant, improving its systemic efficiency.", "confidence": 0.9, "instance_id": "sympy__sympy-26710", "repo": "sympy/sympy"}
{"primary_category": "Shortcut_vs_Systemic", "secondary_tags": [], "lm_attributes": {"StrategyType": ["FastPath/SpecialCase", "Caching/Memoization", "AlgorithmicRefactor"], "SemanticsImpact": "Preserving", "Scope": "Subsystem/Broad", "HotspotAlignment": "Aligned", "Generalizability": "BenchmarkSpecific"}, "expert_attributes": {"StrategyType": ["FastPath/SpecialCase", "AlgorithmicRefactor", "Micro-OverheadRemoval"], "SemanticsImpact": "Preserving", "Scope": "Local/Narrow", "HotspotAlignment": "Aligned", "Generalizability": "General"}, "rationale": "The LM introduces a hardcoded list of small primes, acting as a 'pattern-specific hack' or 'narrow guard' for very small `n`. The expert, in contrast, applies an 'algorithmic refactor' by introducing a fast path that uses the existing sieve mechanism more efficiently for a broader range of small `n` (up to 1000), avoiding expensive symbolic computations.", "confidence": 0.9, "instance_id": "sympy__sympy-27051", "repo": "sympy/sympy"}
